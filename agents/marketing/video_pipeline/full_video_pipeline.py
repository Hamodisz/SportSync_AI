from analysis.analysis_layers_1_40 import apply_layers_1_40
from analysis.analysis_layers_41_80 import apply_layers_41_80
from analysis.analysis_layers_81_100 import apply_layers_81_100
from analysis.analysis_layers_101_141 import apply_layers_101_141
from core.brand_signature import add_brand_signature

from agents.marketing.video_pipeline.image_generator import generate_images
from agents.marketing.video_pipeline.voice_generator import generate_voiceover
from agents.marketing.video_pipeline.video_composer import compose_final_video

# âœ… Ø­Ù„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠ
def import_script_generator():
    from agents.marketing.video_pipeline.script_writer import generate_script_from_traits
    return generate_script_from_traits

def generate_ai_video(user_data: dict, lang: str = "en") -> str:
    """
    ØªÙˆÙ„ÙŠØ¯ ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ù…Ù„ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù†ÙØ³ÙŠ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
    """
    # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù…Ø§Øª
    traits = {}
    traits.update(apply_layers_1_40(user_data))
    traits.update(apply_layers_41_80(user_data))
    traits.update(apply_layers_81_100(user_data))
    traits.update(apply_layers_101_141(user_data))

    user_data["traits"] = traits

    # 2. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù…Ø¹ ØªÙ…Ø±ÙŠØ± video_type
    generate_script_from_traits = import_script_generator()
    script_text = generate_script_from_traits(
        user_data,
        lang=lang,
        video_type=user_data.get("video_type", "ğŸ Ù…Ù‚Ø·Ø¹ Ø·ÙˆÙŠÙ„")  # ğŸ†• Ø¯Ø¹Ù… Ù†ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    )

    # 3. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±
    images = generate_images(script_text)

    # 4. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª
    voice_path = generate_voiceover(script_text, lang=lang)

    # 5. ØªØ±ÙƒÙŠØ¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    final_video_path = compose_final_video(images, voice_path)

    # 6. ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯
    signed_video = add_brand_signature(final_video_path)

    print(f"\nâœ… Final signed video ready: {signed_video}")
    return signed_video
