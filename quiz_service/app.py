# -*- coding: utf-8 -*-
import os, sys, json, time, uuid
from pathlib import Path
from typing import List
import streamlit as st

# =========================
# Ø¶Ø¨Ø· ØµÙØ­Ø© Ø³ØªØ±ÙŠÙ…Ù„Øª (Ù…Ø±Ù‘Ø© ÙˆØ­Ø¯Ø©)
# =========================
if "page_configured" not in st.session_state:
    st.set_page_config(page_title="SportSync â€” Quiz", page_icon="ğŸ¯", layout="centered")
    st.session_state["page_configured"] = True

# =========================
# Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø±Ù†Ø© (Ù…Ø­Ù„ÙŠ + Render)
# =========================
try:
    HERE = Path(__file__).resolve().parent
except NameError:
    HERE = Path.cwd()

ROOT = HERE.parent if HERE.name in ("quiz_service",) else HERE
for p in (ROOT, ROOT / "core", ROOT / "analysis"):
    sp = str(p.resolve())
    if sp not in sys.path:
        sys.path.insert(0, sp)

# =========================
# Helpers
# =========================
def _safe_str(x) -> str:
    """ÙŠØ­ÙˆÙ‘Ù„ Ø£ÙŠ Ù†ÙˆØ¹ Ù†Øµ/Ù‚Ø§Ø¦Ù…Ø©/Ø¯ÙŠÙƒØª Ø¥Ù„Ù‰ Ù†Øµ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø¹Ø±Ø¶."""
    if x is None:
        return ""
    if isinstance(x, str):
        return x
    if isinstance(x, (list, tuple, set)):
        flat = []
        for item in x:
            if isinstance(item, (list, tuple, set)):
                flat.append(_safe_str(list(item)))
            elif isinstance(item, dict):
                for k in ("text", "desc", "value", "answer", "label", "title"):
                    if k in item and isinstance(item[k], str) and item[k].strip():
                        flat.append(item[k].strip())
                        break
                else:
                    try:
                        flat.append(json.dumps(item, ensure_ascii=False))
                    except Exception:
                        flat.append(str(item))
            else:
                flat.append(str(item))
        return "ØŒ ".join([s for s in (str(i).strip() for i in flat) if s])
    if isinstance(x, dict):
        for k in ("text", "desc", "value", "answer", "label", "title"):
            if k in x and isinstance(x[k], str):
                return x[k]
        try:
            return json.dumps(x, ensure_ascii=False)
        except Exception:
            return str(x)
    return str(x)

def _is_followup_cards(recs_list):
    """Ù†Ø­Ø¯Ø¯ Ù‡Ù„ Ø§Ù„Ù„ÙŠ Ø¸Ù‡Ø± Ù‡Ùˆ Ø¨Ø·Ø§Ù‚Ø© Ù…ØªØ§Ø¨Ø¹Ø© (Evidence Gate)."""
    if not isinstance(recs_list, (list, tuple)) or not recs_list:
        return False
    head = _safe_str(recs_list[0]).strip().lower()
    return ("ğŸ§­" in _safe_str(recs_list[0])) or ("need a few quick answers" in head) or ("Ù†Ø­ØªØ§Ø¬ Ø¥Ø¬Ø§Ø¨Ø§Øª" in head) or (len(recs_list) >= 2 and _safe_str(recs_list[1]).strip() == "â€”")

# =========================
# Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø¹ Ø¨Ø¯Ø§Ø¦Ù„ Ø¢Ù…Ù†Ø©
# =========================
try:
    from core.backend_gpt import generate_sport_recommendation
except Exception:
    def generate_sport_recommendation(answers, lang="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"):
        return [
            "âŒ Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Ø§Ù„Ù€ LLM ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù€ Quiz (ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© ÙˆØ§Ù„Ù†Ø´Ø±).",
            "â€”",
            "â€”",
        ]

try:
    from core.dynamic_chat import start_dynamic_chat
except Exception:
    def start_dynamic_chat(**kwargs):
        user_msg = kwargs.get("user_message", "")
        return f"ÙÙ‡Ù…Øª: {_safe_str(user_msg)}\nØ³Ù†Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ø®Ø·Ø© ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ ÙˆÙ†Ø±Ø§Ø¹ÙŠ ØªÙØ¶ÙŠÙ„Ø§ØªÙƒ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©."

try:
    # Ø³ØªØ±ÙŠÙ… Ø­Ù‚ÙŠÙ‚ÙŠ Ø¥Ù† ÙˆÙÙ‘Ø±ØªÙ‡ Ù„Ø§Ø­Ù‚Ù‹Ø§
    from core.dynamic_chat import start_dynamic_chat_stream  # generator
except Exception:
    start_dynamic_chat_stream = None

# Layer Z Ù‚Ø¯ ØªÙƒÙˆÙ† ÙÙŠ core Ø£Ùˆ analysis
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers, lang="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"):
            return ["ØªØ­ÙÙŠØ² Ù‚ØµÙŠØ± Ø§Ù„Ù…Ø¯Ù‰", "Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø³Ø±ÙŠØ¹Ø©", "ØªÙØ¶ÙŠÙ„ ØªØ¯Ø±ÙŠØ¨Ø§Øª ÙØ±Ø¯ÙŠØ©"]

# (ØªØ´Ø®ÙŠØµ) Ù…Ø¹Ø±ÙØ© Ø­Ø§Ù„Ø© LLM â€” Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù…ÙŠÙ„Ùƒ Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯
try:
    from core.llm_client import get_client_and_models, get_models_cached
    _LLM_CLIENT_FOR_DIAG, _MAIN_CHAIN, _FB_MODEL = get_client_and_models()
except Exception:
    _LLM_CLIENT_FOR_DIAG = None
    _MAIN_CHAIN = os.getenv("CHAT_MODEL", "gpt-4o")
    _FB_MODEL = os.getenv("CHAT_MODEL_FALLBACK", "gpt-4o-mini")

# âœ… User Logger (ØµØ§Ù…Øª Ø¹Ù†Ø¯ ØºÙŠØ§Ø¨Ù‡)
try:
    from core.user_logger import (
        log_quiz_submission, log_rating, log_chat_message, log_event
    )
except Exception:
    def log_quiz_submission(**kw): return kw.get("session_id") or "nosession"
    def log_rating(**kw): pass
    def log_chat_message(**kw): pass
    def log_event(**kw): pass

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ø¬Ù‡Ø© + Ù„ØºØ©
# =========================
lang = st.sidebar.radio("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© / Choose Language", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"], index=0)
is_ar = (lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
T = (lambda ar, en: ar if is_ar else en)

# âœ… ØªØ­ÙƒÙ… Ø¨Ø§Ù„ØªØ¬Ø±Ø¨Ø©
with st.sidebar.expander(T("âš™ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶", "âš™ Display Settings"), expanded=True):
    LIVE_TYPING = st.checkbox(T("Ø¥Ø¸Ù‡Ø§Ø± ÙƒØªØ§Ø¨Ø© Ø­ÙŠÙ‘Ø© (typewriter)", "Show live typing (typewriter)"), value=True)
    SHOW_THINKING = st.checkbox(T("Ø¥Ø¸Ù‡Ø§Ø± Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªÙÙƒÙŠØ±", "Show thinking stages"), value=True)
    TYPE_SPEED_MS = st.slider(T("Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒØªØ§Ø¨Ø© (Ù…Ù„Ù‘ÙŠ Ø«Ø§Ù†ÙŠØ©/Ø­Ø±Ù)", "Typing speed (ms/char)"), 1, 30, value=6)

# ğŸ§ª Diagnostics (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
with st.sidebar.expander("ğŸ§ª Diagnostics", expanded=False):
    st.write("Model chain (main):", _MAIN_CHAIN)
    st.write("Model (fallback):", _FB_MODEL)
    st.write("LLM ready:", bool(_LLM_CLIENT_FOR_DIAG))
    st.write("GROQ key set:", bool(os.getenv("GROQ_API_KEY")))
    st.write("OPENAI key set:", bool(os.getenv("OPENAI_API_KEY")))
    st.write("OPENROUTER key set:", bool(os.getenv("OPENROUTER_API_KEY")))
    st.write(
        "Base URL:",
        os.getenv("OPENAI_BASE_URL")
        or os.getenv("OPENROUTER_BASE_URL")
        or os.getenv("AZURE_OPENAI_ENDPOINT")
        or "default",
    )
    try:
        from core.memory_cache import get_cache_stats, clear_cache
        stats = get_cache_stats()
        st.write("Cache hits:", stats.get("hits"))
        st.write("Cache misses:", stats.get("misses"))
        st.write("Cache size:", stats.get("size"))
        st.write("Last action:", stats.get("last_action"))
        st.write("Last get (ms):", stats.get("last_get_ms"))
        if st.button("ğŸ§¹ Clear cache"):
            clear_cache()
            st.rerun()
    except Exception:
        pass

# =========================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
# =========================
QUESTIONS_DIR = (ROOT / "questions")
if not QUESTIONS_DIR.exists():
    QUESTIONS_DIR = HERE / "questions"

ar_path = QUESTIONS_DIR / "arabic_questions.json"
en_path = QUESTIONS_DIR / "english_questions.json"
q_path = ar_path if is_ar or not en_path.exists() else en_path

if not q_path.exists():
    st.error(T("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.", "âŒ Questions file not found."))
    st.stop()

with q_path.open("r", encoding="utf-8") as f:
    questions = json.load(f)

# =========================
# Helpers: ÙƒØªØ§Ø¨Ø© Ø­ÙŠÙ‘Ø© + Ø³ØªØ§ØªØ³
# =========================
def typewriter_write(container, text: str, ms_per_char: int = 6):
    """ÙƒØªØ§Ø¨Ø© Ø­ÙŠÙ‘Ø© Ø¯Ø§Ø®Ù„ Ù†ÙØ³ Ø§Ù„ÙˆØ¹Ø§Ø¡."""
    text = _safe_str(text)
    if not LIVE_TYPING:
        container.markdown(text)
        return
    buf = []
    for ch in text:
        buf.append(ch)
        container.markdown("".join(str(x) for x in buf))
        time.sleep(max(ms_per_char, 1) / 1000.0)

def typewriter_chat(role: str, text: str, ms_per_char: int = 6):
    """Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø´Ø§Øª Ø¨ÙƒØªØ§Ø¨Ø© Ø­ÙŠÙ‘Ø©."""
    with st.chat_message(role):
        ph = st.empty()
        typewriter_write(ph, text, ms_per_char)

def status_steps(enabled: bool):
    """Context manager Ø¨Ø³ÙŠØ· Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªÙÙƒÙŠØ±."""
    class _Dummy:
        def __enter__(self):
            return self
        def __exit__(self, *exc):
            return False
        def write(self, *a, **k): pass
        def update(self, *a, **k): pass
        def info(self, *a, **k): pass
        def warning(self, *a, **k): pass
        def success(self, *a, **k): pass

    if not enabled:
        return _Dummy()

    try:
        # Streamlit >= 1.25
        return st.status(T("ğŸ¤– ÙŠÙÙƒÙ‘Ø± Ø§Ù„Ø¢Ù†â€¦", "ğŸ¤– Thinkingâ€¦"), expanded=True)
    except Exception:
        class _Alt:
            def __init__(self):
                self.box = st.empty()
                self.lines = []
                self.box.write("\n".join(_safe_str(x) for x in self.lines))
            def __enter__(self):
                return self
            def __exit__(self, *exc):
                return False
            def write(self, text):
                self.lines.append(_safe_str(text))
                self.box.write("\n".join(_safe_str(x) for x in self.lines))
            def info(self, text): self.write("â„¹ " + _safe_str(text))
            def warning(self, text): self.write("âš  " + _safe_str(text))
            def success(self, text): self.write("âœ… " + _safe_str(text))
            def update(self, **kwargs): pass
        return _Alt()

# =========================
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
# =========================
st.title(T("ğŸ¯ ØªÙˆØµÙŠØªÙƒ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©", "ğŸ¯ Your Smart Sport Recommendation"))

answers = {}
for q in questions:
    q_key = q.get("key", f"q_{len(answers)+1}")
    text_ar = q.get("question_ar", "")
    text_en = q.get("question_en", text_ar)
    text = text_ar if is_ar else text_en

    choices = q.get("multiple_choices")
    allow_custom = bool(q.get("allow_custom", False))

    if choices and isinstance(choices, list):
        sel = st.multiselect(text, [str(c) for c in choices], key=q_key)
        if allow_custom:
            custom = st.text_input(T("âœ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ø®Ø§ØµØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", "âœ Your own answer (optional)"),
                                   key=f"{q_key}_custom")
            if custom:
                sel.append(custom)
        answers[q_key] = {"question": _safe_str(text), "answer": sel}
    else:
        t = st.text_input(text, key=q_key)
        answers[q_key] = {"question": _safe_str(text), "answer": _safe_str(t)}

st.divider()

# =========================
# Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØ­ÙƒÙ…
# =========================
c1, c2, c3 = st.columns([1,1,1])
go  = c1.button(T("ğŸ” Ø§Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª", "ğŸ” Show Recommendations"))
rst = c2.button(T("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±", "ğŸ”„ Restart"))
dl  = c3.button(T("â¬‡ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù†ØµÙŠÙ‹Ø§", "â¬‡ Download Recommendations as text"))

if rst:
    st.session_state.clear()
    st.rerun()

# Ø­Ø§Ù„Ø© Ø¹Ø§Ù…Ø©
st.session_state.setdefault("recs", [])
st.session_state.setdefault("ratings", [4, 4, 4])
st.session_state.setdefault("chat_open", False)
st.session_state.setdefault("chat_history", [])
st.session_state.setdefault("z_drivers", [])
st.session_state.setdefault("session_id", uuid.uuid4().hex)

# =========================
# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª + Layer Z (Ù…Ø¹ Ù…Ø±Ø§Ø­Ù„ ØªÙÙƒÙŠØ±)
# =========================
if go:
    user_id = "web_user"

    # Ø§Ø±Ø¨Ø· Ø§Ù„Ù€session_id Ø¨Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù„ÙŠØ³Ø­Ø¨Ù‡Ø§ backend_gpt Ù„Ù„Ù‘ÙˆÙ‚
    answers["_session_id"] = st.session_state["session_id"]
    # Ø³Ø¬Ù‘Ù„ submission
    try:
        log_quiz_submission(
            user_id=user_id,
            answers=answers,
            lang=lang,
            session_id=st.session_state["session_id"],
            meta={"source": "quiz_ui"}
        )
    except Exception:
        pass

    with status_steps(SHOW_THINKING) as stat:
        try:
            if SHOW_THINKING: stat.info(T("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øªâ€¦", "Analyzing answersâ€¦"))
            # âŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            raw_recs = generate_sport_recommendation(answers, lang=lang)
            cleaned = []
            if isinstance(raw_recs, (list, tuple)):
                for r in list(raw_recs)[:3]:
                    cleaned.append(_safe_str(r))
            else:
                cleaned = [_safe_str(raw_recs)]
            st.session_state["recs"] = cleaned[:3]
            # ğŸ”” Ø§ÙØªØ­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Follow-ups
            if _is_followup_cards(st.session_state["recs"]):
                st.session_state["chat_open"] = True
                try:
                    log_event(
                        user_id=user_id,
                        session_id=st.session_state["session_id"],
                        name="open_chat",
                        payload={"reason": "followups_auto"},
                        lang=lang
                    )
                except Exception:
                    pass
            if SHOW_THINKING: stat.info(T("Ù…ÙˆØ§Ø¡Ù…Ø© Ù…Ø¹ Ù…Ø­Ø§ÙˆØ± Zâ€¦", "Aligning with Z-axesâ€¦"))
        except Exception as e:
            st.error(T("Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª: ", "Error generating recommendations: ") + _safe_str(e))
            st.session_state["recs"] = []

        # â‹ Layer Z
        try:
            z = analyze_silent_drivers(answers, lang=lang) or []
        except Exception:
            z = []
        st.session_state["z_drivers"] = [ _safe_str(i) for i in (z or []) ]

        if SHOW_THINKING:
            if z:
                stat.info(T("ØªØ«Ø¨ÙŠØª Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© (Z)â€¦", "Locking psycho-metrics (Z)â€¦"))
            stat.success(T("Ø¬Ø§Ù‡Ø²Ø© âœ…", "Ready âœ…"))

# =========================
# Ø¹Ø±Ø¶ Layer Z
# =========================
z = st.session_state.get("z_drivers", [])
if z:
    st.subheader(T("ğŸ§­ Ù…Ø§ ÙŠØ­Ø±ÙƒÙƒ Ø¯ÙˆÙ† Ø£Ù† ØªØ¯Ø±ÙŠ", "ğŸ§­ Your Silent Drivers"))
    for item in z:
        st.write("â€¢ " + _safe_str(item))
    st.divider()

# =========================
# Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª (Ø«Ù„Ø§Ø«Ø©) + Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
# =========================
recs = st.session_state.get("recs", [])
if recs:
    headers_ar = ["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1", "ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2", "ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    headers_en = ["ğŸŸ¢ Recommendation #1", "ğŸŒ¿ Recommendation #2", "ğŸ”® Recommendation #3 (Creative)"]

    for i, rec_md in enumerate(recs[:3]):
        st.subheader(headers_ar[i] if is_ar else headers_en[i])
        ph = st.empty()
        ph.markdown(_safe_str(rec_md))

        old_val = st.session_state["ratings"][i]
        new_rating = st.slider(
            "â­ " + T("Ù‚ÙŠÙ‘Ù… Ù‡Ø°Ù‡ Ø§Ù„ØªÙˆØµÙŠØ©", "Rate this recommendation"),
            1, 5, value=old_val, key=f"rating_{i}"
        )
        if new_rating != old_val:
            st.session_state["ratings"][i] = new_rating
            try:
                log_rating(
                    user_id="web_user",
                    session_id=st.session_state["session_id"],
                    index=i,
                    rating=int(new_rating),
                    lang=lang
                )
            except Exception:
                pass

    st.divider()
    cA, cB = st.columns([1,1])

    open_label = T(
        "ğŸ™…â€â™‚ Ù„Ù… ØªØ¹Ø¬Ø¨Ù†ÙŠ â€” Ø§ÙØªØ­ Ù…Ø­Ø§Ø¯Ø«Ø©" if not _is_followup_cards(recs) else "ğŸ§­ Ø£ÙƒÙ…Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª â€” Ø§ÙØªØ­ Ù…Ø­Ø§Ø¯Ø«Ø©",
        "ğŸ™…â€â™‚ Not satisfied â€” open chat" if not _is_followup_cards(recs) else "ğŸ§­ Complete quick answers â€” open chat"
    )
    if cA.button(open_label):
        st.session_state["chat_open"] = True
        try:
            log_event(
                user_id="web_user",
                session_id=st.session_state["session_id"],
                name="open_chat",
                payload={"reason": "manual_click", "followups": bool(_is_followup_cards(recs))},
                lang=lang
            )
        except Exception:
            pass

    if dl:
        joined = "\n\n".join(_safe_str(x) for x in recs[:3])
        st.download_button(
            label=T("â¬‡ ØªÙ†Ø²ÙŠÙ„ ÙƒÙ…Ù„Ù TXT", "â¬‡ Download as TXT"),
            data=joined.encode("utf-8"),
            file_name="sportsync_recommendations.txt",
            mime="text/plain"
        )

# =========================
# ÙˆØ§Ø¬Ù‡Ø© Ù…Ø­Ø§Ø¯Ø«Ø© Ø´Ø¨ÙŠÙ‡Ø© Ø¨Ø§Ù„Ø´Ø§Øª (chat UI)
# =========================
if st.session_state.get("chat_open", False):
    # Ø²Ø± Ø¥ØºÙ„Ø§Ù‚ Ø³Ø±ÙŠØ¹
    top_c1, top_c2 = st.columns([1,6])
    if top_c1.button(T("âœ– Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", "âœ– Close Chat")):
        try:
            log_event(
                user_id="web_user",
                session_id=st.session_state["session_id"],
                name="close_chat",
                payload={},
                lang=lang
            )
        except Exception:
            pass
        st.session_state["chat_open"] = False
        st.rerun()

    st.subheader(T("ğŸ§  Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø§Ù„Ø°ÙƒÙŠ", "ğŸ§  AI Coach Chat"))

    # Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…
    for msg in st.session_state["chat_history"]:
        with st.chat_message("user" if msg["role"] == "user" else "assistant"):
            st.markdown(_safe_str(msg["content"]))

    # ØªÙ†Ø¨ÙŠÙ‡ ØµØºÙŠØ± Ù„Ùˆ Ø§Ù„Ø­Ø§Ù„Ø© Follow-ups
    if _is_followup_cards(st.session_state.get("recs", [])):
        st.info(T(
            "ğŸ§­ Ø¹Ù†Ø¯Ù†Ø§ Ø£Ø³Ø¦Ù„Ø© Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ Ù‚Ø¨Ù„ Ù…Ø§ Ù†Ø¶Ø¨Ø· Ø§Ù„Ù‡ÙˆÙŠØ©. Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØªØµØ±Ø© Ù‡Ù†Ø§.",
            "ğŸ§­ I need a couple of quick answers before I lock the identity. Reply here."
        ))

    user_msg = st.chat_input(
        T("Ø§ÙƒØªØ¨ Ù…Ø§ Ø§Ù„Ø°ÙŠ Ù„Ù… ÙŠØ¹Ø¬Ø¨Ùƒ Ø£Ùˆ Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„Ù‡â€¦", "Tell me what you didnâ€™t like or what to adjustâ€¦")
    )

    if user_msg:
        # Ø£Ø¶Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø³Ø¬Ù„ + Ù„ÙˆÙ‚
        user_text = _safe_str(user_msg)
        st.session_state["chat_history"].append({"role": "user", "content": user_text})
        try:
            log_chat_message(
                user_id="web_user",
                session_id=st.session_state["session_id"],
                role="user",
                content=user_text,
                lang=lang,
                extra={"where": "quiz_ui"}
            )
        except Exception:
            pass
        typewriter_chat("user", user_text, TYPE_SPEED_MS)

        # Ø­Ø¶Ù‘Ø± Ù…Ø¹Ø·ÙŠØ§Øª Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø©
        recs_for_chat = [ _safe_str(r) for r in st.session_state.get("recs", [])[:3] ]
        ratings = [st.session_state.get(f"rating_{i}", st.session_state["ratings"][i]) for i in range(3)]

        # Ø±Ø¯Ù‘ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ â€” Ø³ØªØ±ÙŠÙ… Ø­Ù‚ÙŠÙ‚ÙŠ Ø¥Ù† ØªÙˆÙØ±ØŒ ÙˆØ¥Ù„Ø§ ÙƒØªØ§Ø¨Ø© Ø­ÙŠÙ‘Ø© Ù„Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if start_dynamic_chat_stream is not None:
            with st.chat_message("assistant"):
                ph = st.empty()
                buf = []
                try:
                    for chunk in start_dynamic_chat_stream(
                        answers=answers,
                        previous_recommendation=recs_for_chat,
                        ratings=ratings,
                        user_id="web_user",
                        lang=lang,
                        chat_history=st.session_state["chat_history"],
                        user_message=user_text
                    ):
                        buf.append(_safe_str(chunk))
                        # Ø¹Ø±Ø¶ ÙÙˆØ±ÙŠ Ù„ÙƒÙ„ chunk - Ø¨Ø¯ÙˆÙ† Ø§Ù†ØªØ¸Ø§Ø±
                        ph.markdown("".join(_safe_str(x) for x in buf))
                    reply = "".join(_safe_str(x) for x in buf).strip()
                except Exception:
                    reply = T("ØªÙ…! Ø³Ù†Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ø®Ø·Ø© Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¬ Ø­Ø³Ø¨ Ù…Ù„Ø§Ø­Ø¸ØªÙƒ.",
                              "Got it! Weâ€™ll adjust the plan gradually based on your feedback.")
                st.session_state["chat_history"].append({"role": "assistant", "content": _safe_str(reply)})
                # Ù„ÙˆÙ‚ Ø±Ø¯Ù‘ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
                try:
                    log_chat_message(
                        user_id="web_user",
                        session_id=st.session_state["session_id"],
                        role="assistant",
                        content=_safe_str(reply),
                        lang=lang,
                        extra={"where": "quiz_ui"}
                    )
                except Exception:
                    pass
        else:
            try:
                reply = start_dynamic_chat(
                    answers=answers,
                    previous_recommendation=recs_for_chat,
                    ratings=ratings,
                    user_id="web_user",
                    lang=lang,
                    chat_history=st.session_state["chat_history"],
                    user_message=user_text
                )
            except Exception:
                reply = T("ØªÙ…! Ø³Ù†Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ø®Ø·Ø© Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¬ Ø­Ø³Ø¨ Ù…Ù„Ø§Ø­Ø¸ØªÙƒ.",
                          "Got it! Weâ€™ll adjust the plan gradually based on your feedback.")
            st.session_state["chat_history"].append({"role": "assistant", "content": _safe_str(reply)})
            # Ù„ÙˆÙ‚ Ø±Ø¯Ù‘ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
            try:
                log_chat_message(
                    user_id="web_user",
                    session_id=st.session_state["session_id"],
                    role="assistant",
                    content=_safe_str(reply),
                    lang=lang,
                    extra={"where": "quiz_ui"}
                )
            except Exception:
                pass
            typewriter_chat("assistant", _safe_str(reply), TYPE_SPEED_MS)

    st.caption("ğŸ’¬ " + T("ØªÙ‚Ø¯Ø± ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù„ÙŠÙ† ØªÙˆØµÙ‘Ù„ Ù„Ù‡ÙˆÙŠØªÙƒ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù„ÙŠ ØªØ­Ø³Ù‡Ø§ Ù…Ù„ÙƒÙƒ.",
                          "Keep chatting until the plan feels like yours."))

st.caption("ğŸš€ Powered by SportSync AI â€” Your identity deserves its own sport.")
