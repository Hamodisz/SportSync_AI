# -*- coding: utf-8 -*-
"""
analysis/layer_z_enhanced.py
-----------------------------
Ù†Ø¸Ø§Ù… Layer-Z Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹:
- Confidence scores Ù„ÙƒÙ„ Ù…Ø­ÙˆØ±
- ØªÙƒØ§Ù…Ù„ Ù…Ø¹ weighted_layers
- ØªØ­Ù„ÙŠÙ„ Flow State
- ØªØ­Ù„ÙŠÙ„ Risk Profile
- 9 Ù…Ø­Ø§ÙˆØ± (6 Ø£Ø³Ø§Ø³ÙŠØ© + 3 Ø¬Ø¯ÙŠØ¯Ø©)
- Pattern matching Ù…Ø­Ø³Ù‘Ù†
- Context awareness

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0.0
Ø§Ù„ØªØ§Ø±ÙŠØ®: 11 Ù†ÙˆÙÙ…Ø¨Ø± 2025
"""

from __future__ import annotations
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import re

# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class ZAxisScore:
    """Ù†ØªÙŠØ¬Ø© Ù…Ø­ÙˆØ± Z Ù…Ø¹ confidence"""
    axis_name: str
    score: float  # -1.0 to +1.0
    confidence: float  # 0.0 to 1.0
    description: str
    
    def __repr__(self):
        return f"{self.axis_name}: {self.score:+.2f} (Ø«Ù‚Ø© {self.confidence:.0%})"

@dataclass
class FlowIndicators:
    """Ù…Ø¤Ø´Ø±Ø§Øª Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¯ÙÙ‚"""
    flow_potential: float  # 0-1
    focus_depth: str  # "Ø¹Ù…ÙŠÙ‚" | "Ù…ØªÙˆØ³Ø·" | "Ø³Ø·Ø­ÙŠ"
    immersion_likelihood: float  # 0-1
    distraction_resistance: float  # 0-1

@dataclass
class RiskAssessment:
    """ØªÙ‚ÙŠÙŠÙ… Ù…Ù„Ù Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©"""
    risk_level: float  # 0-1
    category: str  # "Ù…Ù†Ø®ÙØ¶" | "Ù…ØªÙˆØ³Ø·" | "Ø¹Ø§Ù„ÙŠ"
    comfort_zone_width: str  # "Ø¶ÙŠÙ‚" | "Ù…ØªÙˆØ³Ø·" | "ÙˆØ§Ø³Ø¹"
    novelty_seeking: float  # 0-1

# ============================================================================
# Enhanced Layer-Z Analyzer
# ============================================================================

class EnhancedLayerZ:
    """Ù…Ø­Ù„Ù„ Layer-Z Ù…Ø­Ø³Ù‘Ù†"""
    
    def __init__(self):
        self._ar_pattern = re.compile(r"[\u0600-\u06FF]")
        self._init_patterns()
    
    def _init_patterns(self):
        """ØªÙ‡ÙŠØ¦Ø© patterns Ù„Ù„ÙƒØ´Ù"""
        
        # Technical/Intuitive patterns
        self.technical_ar = [
            "Ø¯Ù‚ÙŠÙ‚", "ØªÙ‚Ù†ÙŠ", "ØªÙØ§ØµÙŠÙ„", "ØªØ­Ù„ÙŠÙ„", "Ù…Ù†Ù‡Ø¬ÙŠ", "Ù†Ø¸Ø§Ù…",
            "Ø®Ø·Ø©", "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„", "Ù‚ÙŠØ§Ø³", "Ø¥Ø­ØµØ§Ø¡", "Ø¨ÙŠØ§Ù†Ø§Øª"
        ]
        self.intuitive_ar = [
            "Ø­Ø¯Ø³ÙŠ", "Ù„Ø­Ø¸ÙŠ", "Ø´Ø¹ÙˆØ±", "Ø¥Ø­Ø³Ø§Ø³", "Ø¹ÙÙˆÙŠ", "Ø·Ø¨ÙŠØ¹ÙŠ",
            "ØªÙ„Ù‚Ø§Ø¦ÙŠ", "Ø³Ø±ÙŠØ¹", "Ù…Ø¨Ø§Ø´Ø±", "Ø¨Ø¯ÙŠÙ‡ÙŠ"
        ]
        
        # Calm/Adrenaline patterns
        self.calm_ar = [
            "Ù‡Ø¯ÙˆØ¡", "Ù‡Ø§Ø¯Ø¦", "Ø§Ø³ØªØ±Ø®Ø§Ø¡", "ØªØ£Ù…Ù„", "Ø³ÙƒÙŠÙ†Ø©", "Ø±Ø§Ø­Ø©",
            "Ø¨Ø·ÙŠØ¡", "Ù…Ù†Ø¸Ù…", "ØªÙ†ÙØ³", "Ø³Ù„Ø§Ù…"
        ]
        self.adrenaline_ar = [
            "Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†", "Ø¥Ø«Ø§Ø±Ø©", "Ø³Ø±Ø¹Ø©", "Ø®Ø·Ø±", "Ù…ØºØ§Ù…Ø±Ø©", "Ø§Ù†Ø¯ÙØ§Ø¹",
            "Ø­Ù…Ø§Ø³", "Ø·Ø§Ù‚Ø©", "Ù†Ø´Ø§Ø·", "Ù‚ÙˆØ©"
        ]
        
        # Solo/Group patterns
        self.solo_ar = [
            "Ù„ÙˆØ­Ø¯ÙŠ", "ÙØ±Ø¯ÙŠ", "ÙˆØ­ÙŠØ¯", "Ù…Ù†ÙØ±Ø¯", "Ø®Ø§Øµ", "Ù…Ø³ØªÙ‚Ù„",
            "Ø¨Ù†ÙØ³ÙŠ", "Ø°Ø§ØªÙŠ"
        ]
        self.group_ar = [
            "Ø¬Ù…Ø§Ø¹ÙŠ", "ÙØ±ÙŠÙ‚", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù†Ø§Ø³", "Ø£ØµØ¯Ù‚Ø§Ø¡", "Ù…Ø¹Ø§Ù‹",
            "ØªØ¹Ø§ÙˆÙ†", "Ø´Ø±Ø§ÙƒØ©", "Ø¬Ù…Ø§Ø¹Ø©"
        ]
        
        # Control/Freedom patterns
        self.control_ar = [
            "Ø³ÙŠØ·Ø±Ø©", "ØªØ­ÙƒÙ…", "Ø¶Ø¨Ø·", "Ø§Ù†Ø¶Ø¨Ø§Ø·", "Ù†Ø¸Ø§Ù…", "Ù‚ÙˆØ§Ø¹Ø¯",
            "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„", "ØªØ±ØªÙŠØ¨", "ØªÙ†Ø¸ÙŠÙ…"
        ]
        self.freedom_ar = [
            "Ø­Ø±ÙŠØ©", "Ø§Ù†Ø³ÙŠØ§Ø¨", "Ù…Ø±ÙˆÙ†Ø©", "Ø¹ÙÙˆÙŠØ©", "ØªÙ„Ù‚Ø§Ø¦ÙŠØ©", "Ø§Ù†Ø·Ù„Ø§Ù‚",
            "Ø¨Ø¯ÙˆÙ† Ù‚ÙŠÙˆØ¯", "Ø­Ø±"
        ]
        
        # Repeat/Variety patterns
        self.repeat_ar = [
            "ØªÙƒØ±Ø§Ø±", "Ø±ÙˆØªÙŠÙ†", "Ø¥ØªÙ‚Ø§Ù†", "ØªÙ…Ø±ÙŠÙ†", "Ù…Ù‡Ø§Ø±Ø©", "Ø¥Ø¹Ø§Ø¯Ø©",
            "Ù…Ù…Ø§Ø±Ø³Ø©", "ØªØ¯Ø±ÙŠØ¨"
        ]
        self.variety_ar = [
            "ØªÙ†ÙˆÙŠØ¹", "ØªØºÙŠÙŠØ±", "Ø¬Ø¯ÙŠØ¯", "Ù…Ø®ØªÙ„Ù", "Ù…ØªÙ†ÙˆØ¹", "Ù…Ù„Ù„",
            "Ø±ØªØ§Ø¨Ø©", "ØªØ¬Ø¯ÙŠØ¯"
        ]
        
        # Compete/Enjoy patterns
        self.compete_ar = [
            "Ù…Ù†Ø§ÙØ³Ø©", "ØªØ­Ø¯ÙŠ", "ÙÙˆØ²", "ØªÙÙˆÙ‚", "Ø£ÙØ¶Ù„", "Ø±Ù‚Ù… Ù‚ÙŠØ§Ø³ÙŠ",
            "Ø¥Ù†Ø¬Ø§Ø²", "Ù‡Ø¯Ù"
        ]
        self.enjoy_ar = [
            "Ù…ØªØ¹Ø©", "Ø§Ø³ØªÙ…ØªØ§Ø¹", "Ù…Ø±Ø­", "Ù„Ø¹Ø¨", "ØªØ¬Ø±Ø¨Ø©", "Ø´Ø¹ÙˆØ±",
            "Ø¥Ø­Ø³Ø§Ø³ Ø¬Ù…ÙŠÙ„"
        ]
        
        # Flow state indicators
        self.flow_ar = [
            "ØªØ¯ÙÙ‚", "Ø§Ù†ØºÙ…Ø§Ø³", "ØªØ±ÙƒÙŠØ² Ø¹Ù…ÙŠÙ‚", "Ø§Ù„ÙˆÙ‚Øª ÙŠØ·ÙŠØ±", "Ù†Ø³ÙŠØ§Ù† Ø§Ù„Ø°Ø§Øª",
            "Ø§Ø³ØªØºØ±Ø§Ù‚", "Ø°ÙˆØ¨Ø§Ù† ÙÙŠ"
        ]
        
        # Risk indicators
        self.risk_seeking_ar = [
            "Ø®Ø·Ø±", "Ù…ØºØ§Ù…Ø±Ø©", "ØªØ¬Ø±Ø¨Ø© Ø¬Ø¯ÙŠØ¯Ø©", "ØºÙŠØ± Ù…Ø£Ù„ÙˆÙ", "ØªØ­Ø¯ÙŠ ÙƒØ¨ÙŠØ±"
        ]
        self.risk_averse_ar = [
            "Ø£Ù…Ø§Ù†", "ØªØ£ÙƒØ¯", "Ù…Ø£Ù„ÙˆÙ", "ØªØ¯Ø±ÙŠØ¬ÙŠ", "Ø­Ø°Ø±"
        ]
    
    def _is_arabic(self, text: str) -> bool:
        """ÙƒØ´Ù Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
        return bool(self._ar_pattern.search(text or ""))
    
    def _count_patterns(self, text: str, patterns: List[str]) -> int:
        """Ø¹Ø¯ ØªØ·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        if not text:
            return 0
        text_lower = text.lower()
        return sum(1 for p in patterns if p in text_lower)
    
    def _calculate_confidence(self, positive_count: int, negative_count: int, 
                             total_words: int) -> float:
        """Ø­Ø³Ø§Ø¨ confidence Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ù„Ø©"""
        total_matches = positive_count + negative_count
        if total_matches == 0:
            return 0.0
        
        # Confidence ÙŠØ²ÙŠØ¯ Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¯Ù„Ø©
        base_confidence = min(total_matches / 5, 1.0)
        
        # ÙŠÙ‚Ù„ Ù…Ø¹ Ø§Ù„ØºÙ…ÙˆØ¶ (positive â‰ˆ negative)
        if positive_count > 0 and negative_count > 0:
            ratio = min(positive_count, negative_count) / max(positive_count, negative_count)
            ambiguity_penalty = ratio * 0.5
            base_confidence *= (1 - ambiguity_penalty)
        
        return round(base_confidence, 2)
    
    def analyze_axis(self, text: str, positive_patterns: List[str],
                    negative_patterns: List[str], axis_name: str,
                    description: str) -> ZAxisScore:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ÙˆØ± ÙˆØ§Ø­Ø¯"""
        pos_count = self._count_patterns(text, positive_patterns)
        neg_count = self._count_patterns(text, negative_patterns)
        
        total_words = len(text.split())
        confidence = self._calculate_confidence(pos_count, neg_count, total_words)
        
        # Ø­Ø³Ø§Ø¨ Score
        if pos_count == 0 and neg_count == 0:
            score = 0.0
        else:
            score = (pos_count - neg_count) / max(pos_count + neg_count, 1)
            score = max(-1.0, min(1.0, score))
        
        return ZAxisScore(
            axis_name=axis_name,
            score=score,
            confidence=confidence,
            description=description
        )
    
    def analyze_all_axes(self, text: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, ZAxisScore]:
        """ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ù€ 9"""
        if lang != "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            # Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù†Ø³ØªØ®Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ø­Ø§Ù„ÙŠØ§Ù‹
            return self._analyze_english_simple(text)
        
        results = {}
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (6)
        results["technical_intuitive"] = self.analyze_axis(
            text, self.technical_ar, self.intuitive_ar,
            "technical_intuitive", "ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ"
        )
        
        results["calm_adrenaline"] = self.analyze_axis(
            text, self.adrenaline_ar, self.calm_ar,
            "calm_adrenaline", "Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†"
        )
        
        results["solo_group"] = self.analyze_axis(
            text, self.solo_ar, self.group_ar,
            "solo_group", "ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ"
        )
        
        results["control_freedom"] = self.analyze_axis(
            text, self.control_ar, self.freedom_ar,
            "control_freedom", "Ø³ÙŠØ·Ø±Ø©/Ø­Ø±ÙŠØ©"
        )
        
        results["repeat_variety"] = self.analyze_axis(
            text, self.repeat_ar, self.variety_ar,
            "repeat_variety", "ØªÙƒØ±Ø§Ø±/ØªÙ†ÙˆÙŠØ¹"
        )
        
        results["compete_enjoy"] = self.analyze_axis(
            text, self.compete_ar, self.enjoy_ar,
            "compete_enjoy", "Ù…Ù†Ø§ÙØ³Ø©/Ù…ØªØ¹Ø©"
        )
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (3)
        flow_count = self._count_patterns(text, self.flow_ar)
        results["flow_state"] = ZAxisScore(
            axis_name="flow_state",
            score=min(flow_count / 3, 1.0),
            confidence=min(flow_count / 2, 1.0),
            description="Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¯ÙÙ‚"
        )
        
        # Focus mode (Ù…Ù† technical + calm)
        tech_score = results["technical_intuitive"].score
        calm_score = results["calm_adrenaline"].score
        focus_score = (tech_score - calm_score) / 2
        results["focus_mode"] = ZAxisScore(
            axis_name="focus_mode",
            score=focus_score,
            confidence=(results["technical_intuitive"].confidence + 
                       results["calm_adrenaline"].confidence) / 2,
            description="Ù†Ù…Ø· Ø§Ù„ØªØ±ÙƒÙŠØ²"
        )
        
        # Risk profile
        risk_seeking = self._count_patterns(text, self.risk_seeking_ar)
        risk_averse = self._count_patterns(text, self.risk_averse_ar)
        risk_score = (risk_seeking - risk_averse) / max(risk_seeking + risk_averse, 1)
        results["risk_profile"] = ZAxisScore(
            axis_name="risk_profile",
            score=risk_score,
            confidence=min((risk_seeking + risk_averse) / 3, 1.0),
            description="Ù…Ù„Ù Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©"
        )
        
        return results
    
    def _analyze_english_simple(self, text: str) -> Dict[str, ZAxisScore]:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"""
        # Ù†Ø¸Ø§Ù… Ø¨Ø³ÙŠØ· Ø­Ø§Ù„ÙŠØ§Ù‹
        return {
            "technical_intuitive": ZAxisScore("technical_intuitive", 0.0, 0.3, "technical/intuitive"),
            "calm_adrenaline": ZAxisScore("calm_adrenaline", 0.0, 0.3, "calm/adrenaline"),
            "solo_group": ZAxisScore("solo_group", 0.0, 0.3, "solo/group"),
            "control_freedom": ZAxisScore("control_freedom", 0.0, 0.3, "control/freedom"),
            "repeat_variety": ZAxisScore("repeat_variety", 0.0, 0.3, "repeat/variety"),
            "compete_enjoy": ZAxisScore("compete_enjoy", 0.0, 0.3, "compete/enjoy"),
            "flow_state": ZAxisScore("flow_state", 0.0, 0.2, "flow state"),
            "focus_mode": ZAxisScore("focus_mode", 0.0, 0.2, "focus mode"),
            "risk_profile": ZAxisScore("risk_profile", 0.0, 0.2, "risk profile"),
        }
    
    def analyze_flow_indicators(self, text: str, z_scores: Dict[str, ZAxisScore]) -> FlowIndicators:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¯ÙÙ‚"""
        flow_score = z_scores.get("flow_state", ZAxisScore("", 0, 0, "")).score
        focus_score = z_scores.get("focus_mode", ZAxisScore("", 0, 0, "")).score
        
        # Flow potential
        flow_potential = (flow_score + abs(focus_score)) / 2
        
        # Focus depth
        if abs(focus_score) > 0.6:
            focus_depth = "Ø¹Ù…ÙŠÙ‚"
        elif abs(focus_score) > 0.3:
            focus_depth = "Ù…ØªÙˆØ³Ø·"
        else:
            focus_depth = "Ø³Ø·Ø­ÙŠ"
        
        # Immersion likelihood
        immersion = flow_potential * 0.8 + (1 - z_scores.get("repeat_variety", ZAxisScore("", 0, 0, "")).score) * 0.2
        
        # Distraction resistance
        distraction = abs(focus_score) * 0.7 + flow_score * 0.3
        
        return FlowIndicators(
            flow_potential=round(flow_potential, 2),
            focus_depth=focus_depth,
            immersion_likelihood=round(immersion, 2),
            distraction_resistance=round(distraction, 2)
        )
    
    def analyze_risk_assessment(self, text: str, z_scores: Dict[str, ZAxisScore]) -> RiskAssessment:
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ù„Ù Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©"""
        risk_score = z_scores.get("risk_profile", ZAxisScore("", 0, 0, "")).score
        adrenaline_score = z_scores.get("calm_adrenaline", ZAxisScore("", 0, 0, "")).score
        variety_score = z_scores.get("repeat_variety", ZAxisScore("", 0, 0, "")).score
        
        # Risk level (0-1)
        risk_level = (risk_score + adrenaline_score + abs(variety_score)) / 3
        risk_level = (risk_level + 1) / 2  # ØªØ­ÙˆÙŠÙ„ Ù…Ù† [-1,1] Ø¥Ù„Ù‰ [0,1]
        
        # Category
        if risk_level > 0.6:
            category = "Ø¹Ø§Ù„ÙŠ"
        elif risk_level > 0.35:
            category = "Ù…ØªÙˆØ³Ø·"
        else:
            category = "Ù…Ù†Ø®ÙØ¶"
        
        # Comfort zone width
        if abs(variety_score) > 0.5:
            comfort_zone = "ÙˆØ§Ø³Ø¹"
        elif abs(variety_score) > 0.25:
            comfort_zone = "Ù…ØªÙˆØ³Ø·"
        else:
            comfort_zone = "Ø¶ÙŠÙ‚"
        
        # Novelty seeking
        novelty = (abs(variety_score) + risk_level) / 2
        
        return RiskAssessment(
            risk_level=round(risk_level, 2),
            category=category,
            comfort_zone_width=comfort_zone,
            novelty_seeking=round(novelty, 2)
        )
    
    def generate_z_drivers(self, z_scores: Dict[str, ZAxisScore], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…Ù„ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        ar = (lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
        drivers = []
        
        for axis_name, z_score in z_scores.items():
            if z_score.confidence < 0.3:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©
                continue
            
            score = z_score.score
            
            if axis_name == "technical_intuitive":
                if score > 0.4:
                    drivers.append("Ù…ÙŠÙ„ ØªÙ‚Ù†ÙŠ ÙˆÙ…Ù†Ù‡Ø¬ÙŠ" if ar else "Technical & methodical bias")
                elif score < -0.4:
                    drivers.append("Ù…ÙŠÙ„ Ø­Ø¯Ø³ÙŠ ÙˆÙ„Ø­Ø¸ÙŠ" if ar else "Intuitive & instinctive bias")
            
            elif axis_name == "calm_adrenaline":
                if score > 0.4:
                    drivers.append("ÙŠÙ†Ø¬Ø°Ø¨ Ù„Ù„Ø¥Ø«Ø§Ø±Ø© ÙˆØ§Ù„Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†" if ar else "Adrenaline/thrill seeking")
                elif score < -0.4:
                    drivers.append("ÙŠÙ…ÙŠÙ„ Ù„Ù„Ù‡Ø¯ÙˆØ¡ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¹ØµØ¨ÙŠ" if ar else "Calm/parasympathetic regulation")
            
            elif axis_name == "solo_group":
                if score > 0.4:
                    drivers.append("ØªÙØ¶ÙŠÙ„ Ù‚ÙˆÙŠ Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„ÙØ±Ø¯ÙŠ" if ar else "Strong solo preference")
                elif score < -0.4:
                    drivers.append("ÙŠÙ†Ø¬Ø­ Ø£ÙƒØ«Ø± ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©" if ar else "Thrives in group settings")
            
            elif axis_name == "control_freedom":
                if score > 0.4:
                    drivers.append("ÙŠØ­ØªØ§Ø¬ Ù„Ù„Ø³ÙŠØ·Ø±Ø© ÙˆØ§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„" if ar else "Needs control & protocol")
                elif score < -0.4:
                    drivers.append("ÙŠÙØ¶Ù„ Ø§Ù„Ø­Ø±ÙŠØ© ÙˆØ§Ù„Ø§Ù†Ø³ÙŠØ§Ø¨" if ar else "Prefers freedom & flow")
            
            elif axis_name == "repeat_variety":
                if score > 0.4:
                    drivers.append("ÙŠØ±ØªØ§Ø­ Ù„Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ø¥ØªÙ‚Ø§Ù†" if ar else "Comfortable with repetition & mastery")
                elif score < -0.4:
                    drivers.append("ÙŠÙƒØ±Ù‡ Ø§Ù„Ø±ØªØ§Ø¨Ø© ÙˆÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙ†ÙˆÙŠØ¹" if ar else "Boredom-averse, seeks variety")
            
            elif axis_name == "compete_enjoy":
                if score > 0.4:
                    drivers.append("Ù…Ø­ÙÙÙ‘Ø² Ø¨Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© ÙˆØ§Ù„ØªÙÙˆÙ‚" if ar else "Competition/dominance driven")
                elif score < -0.4:
                    drivers.append("Ù…Ø­ÙÙÙ‘Ø² Ø¨Ø§Ù„Ù…ØªØ¹Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø©" if ar else "Enjoyment/experience driven")
            
            elif axis_name == "flow_state":
                if score > 0.5:
                    drivers.append("Ù‚Ø¯Ø±Ø© Ø¹Ø§Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¯ÙÙ‚" if ar else "High flow state capacity")
            
            elif axis_name == "risk_profile":
                if score > 0.5:
                    drivers.append("Ù…ÙŠÙ„ Ù„Ù„Ù…Ø®Ø§Ø·Ø±Ø© ÙˆØ§Ù„Ù…ØºØ§Ù…Ø±Ø©" if ar else "Risk-taking tendency")
                elif score < -0.5:
                    drivers.append("ÙŠÙØ¶Ù„ Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ¯Ø±Ø¬" if ar else "Safety-oriented approach")
        
        return drivers
    
    def analyze_complete(self, text: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                        answers: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ - Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        
        Returns:
            {
                "z_scores": Dict[str, ZAxisScore],
                "z_drivers": List[str],
                "flow_indicators": FlowIndicators,
                "risk_assessment": RiskAssessment,
                "summary": Dict[str, Any]
            }
        """
        # Ø¬Ù…Ø¹ Ø§Ù„Ù†Øµ Ù…Ù† answers Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹
        if answers and not text:
            text = self._flatten_answers(answers)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆØ±
        z_scores = self.analyze_all_axes(text, lang)
        
        # ØªØ­Ù„ÙŠÙ„ Flow
        flow_indicators = self.analyze_flow_indicators(text, z_scores)
        
        # ØªØ­Ù„ÙŠÙ„ Risk
        risk_assessment = self.analyze_risk_assessment(text, z_scores)
        
        # ØªÙˆÙ„ÙŠØ¯ Drivers
        z_drivers = self.generate_z_drivers(z_scores, lang)
        
        # Summary
        summary = self._create_summary(z_scores, flow_indicators, risk_assessment, lang)
        
        return {
            "z_scores": z_scores,
            "z_drivers": z_drivers,
            "flow_indicators": flow_indicators,
            "risk_assessment": risk_assessment,
            "summary": summary
        }
    
    def _flatten_answers(self, answers: Dict[str, Any]) -> str:
        """ØªØ­ÙˆÙŠÙ„ answers Ø¥Ù„Ù‰ Ù†Øµ Ù…ÙˆØ­Ø¯"""
        texts = []
        for k, v in answers.items():
            if k == "_session_id":
                continue
            if isinstance(v, dict):
                answer = v.get("answer", "")
                if isinstance(answer, (list, tuple)):
                    texts.extend([str(item) for item in answer])
                else:
                    texts.append(str(answer))
            else:
                texts.append(str(v))
        return " ".join(texts)
    
    def _create_summary(self, z_scores: Dict[str, ZAxisScore],
                       flow_indicators: FlowIndicators,
                       risk_assessment: RiskAssessment,
                       lang: str) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„"""
        ar = (lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
        
        # Ø£Ù‚ÙˆÙ‰ Ù…Ø­ÙˆØ±
        strongest_axis = max(z_scores.values(), 
                           key=lambda x: abs(x.score) * x.confidence)
        
        # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
        avg_confidence = sum(z.confidence for z in z_scores.values()) / len(z_scores)
        
        return {
            "strongest_axis": {
                "name": strongest_axis.axis_name,
                "score": strongest_axis.score,
                "confidence": strongest_axis.confidence,
                "description": strongest_axis.description
            },
            "average_confidence": round(avg_confidence, 2),
            "flow_potential": flow_indicators.flow_potential,
            "risk_category": risk_assessment.category,
            "profile_clarity": "ÙˆØ§Ø¶Ø­" if avg_confidence > 0.6 else "Ù…ØªÙˆØ³Ø·" if avg_confidence > 0.35 else "ØºØ§Ù…Ø¶"
        }

# ============================================================================
# Backward Compatible Functions
# ============================================================================

def analyze_silent_drivers_enhanced(answers: Dict[str, Any], 
                                   lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                                   encoded: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…
    
    Args:
        answers: Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        lang: Ø§Ù„Ù„ØºØ©
        encoded: Ù†ØªØ§Ø¦Ø¬ weighted_layers (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    
    Returns:
        {
            "z_scores": dict,
            "z_drivers": list,
            "profile": dict
        }
    """
    analyzer = EnhancedLayerZ()
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… encoded Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹
    if encoded and "z_scores" in encoded:
        # ØªØ­ÙˆÙŠÙ„ z_scores Ù…Ù† dict Ø¹Ø§Ø¯ÙŠ Ø¥Ù„Ù‰ ZAxisScore objects
        z_scores_dict = {}
        for axis_name, score in encoded["z_scores"].items():
            z_scores_dict[axis_name] = ZAxisScore(
                axis_name=axis_name,
                score=score,
                confidence=0.7,  # Ø«Ù‚Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù† weighted_layers
                description=axis_name
            )
    else:
        # ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯
        result = analyzer.analyze_complete("", lang, answers)
        z_scores_dict = result["z_scores"]
    
    # ØªÙˆÙ„ÙŠØ¯ drivers
    z_drivers = analyzer.generate_z_drivers(z_scores_dict, lang)
    
    # ØªØ­ÙˆÙŠÙ„ z_scores Ø¥Ù„Ù‰ dict Ø¨Ø³ÙŠØ· Ù„Ù„ØªÙˆØ§ÙÙ‚
    z_scores_simple = {k: v.score for k, v in z_scores_dict.items()}
    
    return {
        "z_scores": z_scores_simple,
        "z_drivers": z_drivers,
        "profile": {
            "axes": z_scores_simple
        }
    }


def analyze_user_from_answers(answers: Dict[str, Any],
                              lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                              user_id: Optional[str] = None,
                              **kwargs) -> Dict[str, Any]:
    """
    ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ Ù…Ø¹ layer_z_engine.py Ø§Ù„Ù‚Ø¯ÙŠÙ…
    
    Args:
        answers: Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        lang: Ø§Ù„Ù„ØºØ©
        user_id: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù„Ù„ØªÙˆØ§ÙÙ‚)
        **kwargs: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    
    Returns:
        {
            "z_drivers": list,
            "profile": dict
        }
    """
    result = analyze_silent_drivers_enhanced(answers, lang)
    return {
        "z_drivers": result["z_drivers"],
        "profile": result["profile"]
    }

# ============================================================================
# Helper Functions
# ============================================================================

def get_z_scores_dict(result: Dict[str, Any]) -> Dict[str, float]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ z_scores ÙƒÙ€ dict Ø¨Ø³ÙŠØ·"""
    if "z_scores" not in result:
        return {}
    
    z_scores = result["z_scores"]
    if isinstance(list(z_scores.values())[0], ZAxisScore):
        return {k: v.score for k, v in z_scores.items()}
    return z_scores

def format_z_report(result: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> str:
    """ØªÙ†Ø³ÙŠÙ‚ ØªÙ‚Ø±ÙŠØ± Layer-Z Ù„Ù„Ø¹Ø±Ø¶"""
    ar = (lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    lines = []
    
    lines.append("=" * 50)
    lines.append("ØªÙ‚Ø±ÙŠØ± Layer-Z Ø§Ù„Ù…Ø­Ø³Ù‘Ù†" if ar else "Enhanced Layer-Z Report")
    lines.append("=" * 50)
    
    # Z-Scores
    lines.append("\nğŸ“Š Ù…Ø­Ø§ÙˆØ± Z:" if ar else "\nğŸ“Š Z-Axes:")
    z_scores = result.get("z_scores", {})
    for axis_name, z_score in z_scores.items():
        if isinstance(z_score, ZAxisScore):
            lines.append(f"  â€¢ {z_score}")
    
    # Drivers
    lines.append("\nğŸ¯ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:" if ar else "\nğŸ¯ Key Drivers:")
    for driver in result.get("z_drivers", []):
        lines.append(f"  â€¢ {driver}")
    
    # Flow Indicators
    if "flow_indicators" in result:
        flow = result["flow_indicators"]
        lines.append("\nğŸŒŠ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¯ÙÙ‚:" if ar else "\nğŸŒŠ Flow Indicators:")
        lines.append(f"  â€¢ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ¯ÙÙ‚: {flow.flow_potential:.0%}" if ar 
                    else f"  â€¢ Flow potential: {flow.flow_potential:.0%}")
        lines.append(f"  â€¢ Ø¹Ù…Ù‚ Ø§Ù„ØªØ±ÙƒÙŠØ²: {flow.focus_depth}" if ar
                    else f"  â€¢ Focus depth: {flow.focus_depth}")
    
    # Risk Assessment
    if "risk_assessment" in result:
        risk = result["risk_assessment"]
        lines.append("\nâš¡ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©:" if ar else "\nâš¡ Risk Assessment:")
        lines.append(f"  â€¢ Ø§Ù„Ù…Ø³ØªÙˆÙ‰: {risk.category}" if ar
                    else f"  â€¢ Level: {risk.category}")
        lines.append(f"  â€¢ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ø§Ø­Ø©: {risk.comfort_zone_width}" if ar
                    else f"  â€¢ Comfort zone: {risk.comfort_zone_width}")
    
    # Summary
    if "summary" in result:
        summary = result["summary"]
        lines.append("\nğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ:" if ar else "\nğŸ“ Summary:")
        lines.append(f"  â€¢ ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ù„Ù: {summary['profile_clarity']}" if ar
                    else f"  â€¢ Profile clarity: {summary['profile_clarity']}")
        lines.append(f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {summary['average_confidence']:.0%}" if ar
                    else f"  â€¢ Avg confidence: {summary['average_confidence']:.0%}")
    
    lines.append("\n" + "=" * 50)
    
    return "\n".join(lines)

# ============================================================================
# Examples & Testing
# ============================================================================

if __name__ == "__main__":
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Layer-Z Enhanced...\n")
    
    # Test 1: Ù‡Ø§Ø¯Ø¦ ØªÙƒØªÙŠÙƒÙŠ ÙØ±Ø¯ÙŠ
    test1 = """
    Ø£Ø­Ø¨ Ø§Ù„Ù‡Ø¯ÙˆØ¡ ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø¹Ù…ÙŠÙ‚. Ø£ÙØ¶Ù„ Ø§Ù„Ø¹Ù…Ù„ Ù„ÙˆØ­Ø¯ÙŠ.
    Ø£Ø­ØªØ§Ø¬ Ù„Ù„Ø³ÙŠØ·Ø±Ø© ÙˆØ§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø¯Ù‚ÙŠÙ‚. Ø£ÙƒØ±Ù‡ Ø§Ù„Ø±ØªØ§Ø¨Ø©.
    """
    
    analyzer = EnhancedLayerZ()
    result1 = analyzer.analyze_complete(test1, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    
    print("=" * 60)
    print("Test 1: Ù‡Ø§Ø¯Ø¦ ØªÙƒØªÙŠÙƒÙŠ ÙØ±Ø¯ÙŠ")
    print("=" * 60)
    print(format_z_report(result1, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"))
    
    # Test 2: Ù…ØºØ§Ù…Ø± Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ
    test2 = """
    Ø£Ø­Ø¨ Ø§Ù„Ø¥Ø«Ø§Ø±Ø© ÙˆØ§Ù„Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†! Ø£Ø­Ø¨ Ø§Ù„Ù…ØºØ§Ù…Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.
    Ø£Ø³ØªÙ…ØªØ¹ Ø¨Ø§Ù„Ù„Ø¹Ø¨ Ù…Ø¹ Ø§Ù„Ø£ØµØ¯Ù‚Ø§Ø¡ ÙˆØ§Ù„ÙØ±ÙŠÙ‚. Ø£ÙƒØ±Ù‡ Ø§Ù„Ø±ÙˆØªÙŠÙ†.
    """
    
    result2 = analyzer.analyze_complete(test2, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    
    print("\n" + "=" * 60)
    print("Test 2: Ù…ØºØ§Ù…Ø± Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ")
    print("=" * 60)
    print(format_z_report(result2, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"))
    
    # Test 3: Backward compatibility
    print("\n" + "=" * 60)
    print("Test 3: Backward Compatibility")
    print("=" * 60)
    
    answers = {
        "q1": {"answer": "Ø£Ø­Ø¨ Ø§Ù„Ù‡Ø¯ÙˆØ¡ ÙˆØ§Ù„ØªØ£Ù…Ù„"},
        "q2": {"answer": "Ø£ÙØ¶Ù„ Ø§Ù„Ø¹Ù…Ù„ Ù„ÙˆØ­Ø¯ÙŠ"},
        "q3": {"answer": "Ø£Ø­ØªØ§Ø¬ Ù„Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø¯Ù‚ÙŠÙ‚"}
    }
    
    result3 = analyze_silent_drivers_enhanced(answers, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("\nZ-Scores:")
    for axis, score in result3["z_scores"].items():
        print(f"  {axis}: {score:+.2f}")
    
    print("\nZ-Drivers:")
    for driver in result3["z_drivers"]:
        print(f"  â€¢ {driver}")
    
    print("\nâœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª!")
