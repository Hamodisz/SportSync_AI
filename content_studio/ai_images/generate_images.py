# content_studio/ai_images/generate_images.py
# -- coding: utf-8 --

from _future_ import annotations

import os
import re
import time
import base64
import logging
from pathlib import Path
from typing import List, Optional

# ========= Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬ÙŠÙ†Øº =========
logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s | %(asctime)s | ai_images | %(message)s"
)

# ========= Ù…Ø³Ø§Ø±Ø§Øª Ø«Ø§Ø¨ØªØ© =========
OUTPUT_DIR = Path("content_studio/ai_images/outputs/")
SAMPLE_DIR = Path("generated_images")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ========= Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© =========
USE_OPENAI = False
client = None
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

try:
    # ÙˆØ§Ø¬Ù‡Ø© OpenAI Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
    from openai import OpenAI  # type: ignore
    if OPENAI_API_KEY:
        client = OpenAI(api_key=OPENAI_API_KEY)
        USE_OPENAI = True
except Exception as e:
    logging.warning(f"OpenAI client not available, will use fallbacks. ({e})")
    USE_OPENAI = False
    client = None

# PIL Ù„Ù„ÙÙˆÙ„Ø¨Ø§Ùƒ Ø§Ù„Ù…Ø­Ù„ÙŠ
from PIL import Image, ImageDraw, ImageFont  # type: ignore


# ========= Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =========
def extract_scenes(script_text: str) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ù…Ù† Ø³ÙƒØ±Ø¨Øª Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ:
      - Scene #1: ... / Scene: ...
      - Ù…Ø´Ù‡Ø¯ 1: ... / Ù…Ø´Ù‡Ø¯: ...
      - Ø£Ùˆ ØªÙ‚Ø³ÙŠÙ… Ø¹Ù„Ù‰ ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©
    """
    chunks = re.split(r"(?:Scene\s*#?\d*[:\-]?\s*)|(?:Ù…Ø´Ù‡Ø¯\s*#?\d*[:\-]?\s*)",
                      script_text, flags=re.IGNORECASE)
    scenes = [c.strip() for c in chunks if c and c.strip()]
    if not scenes:
        scenes = [p.strip() for p in re.split(r"\n\s*\n", script_text) if p.strip()]
    # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 6 Ù…Ø´Ø§Ù‡Ø¯ Ø¹Ø´Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù‚ØµÙŠØ±
    return scenes[:6] if scenes else [script_text.strip()[:140]]


def _save_png_from_b64(b64_data: str, out_path: Path) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_bytes(base64.b64decode(b64_data))


def _copy_from_samples(idx: int) -> Optional[str]:
    """Ù†Ø³Ø® ØµÙˆØ±Ø© Ù…Ù† generated_images ÙƒØ­Ù„ Ø³Ø±ÙŠØ¹ Ø¥Ù† ÙˆÙØ¬Ø¯Øª."""
    if not SAMPLE_DIR.exists():
        return None
    candidates = sorted(list(SAMPLE_DIR.glob(".png")) + list(SAMPLE_DIR.glob(".jpg")))
    if not candidates:
        return None
    src = candidates[idx % len(candidates)]
    dst = OUTPUT_DIR / f"scene_{idx+1}{src.suffix.lower()}"
    # Ø§ÙØªØ­ ÙˆØ§Ø­ÙØ¸ Ù„Ø¶Ù…Ø§Ù† ØµØ­Ø© Ø§Ù„ØµÙŠØºØ©
    Image.open(src).save(dst)
    return str(dst)


def _make_text_image(text: str, idx: int, size=(1024, 1024)) -> str:
    """
    ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù†ØµÙ‘ÙŠØ© Ù…Ø­Ù„ÙŠÙ‹Ø§ (fallback Ù†Ù‡Ø§Ø¦ÙŠ).
    Ù…Ù†Ø§Ø³Ø¨Ø© Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ÙŠØªÙˆÙØ± API ÙˆÙ„Ø§ ØµÙˆØ± Ø¹ÙŠÙ†Ø§Øª.
    """
    img = Image.new("RGB", size, (18, 20, 24))
    draw = ImageDraw.Draw(img)

    # Ø¬Ø±Ù‘Ø¨ Ø®Ø· Ù†Ø¸Ø§Ù…ØŒ ÙˆØ¥Ù„Ø§ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    try:
        font = ImageFont.truetype("arial.ttf", 44)
    except Exception:
        font = ImageFont.load_default()

    # Ù„ÙÙ‘ Ø§Ù„Ù†Øµ Ø¨Ø¨Ø³Ø§Ø·Ø©
    words = text.split()
    lines, line = [], ""
    for w in words:
        if len(line + " " + w) < 28:
            line = (line + " " + w).strip()
        else:
            lines.append(line)
            line = w
    if line:
        lines.append(line)

    y = 80
    for ln in lines[:12]:
        draw.text((60, y), ln, fill=(235, 235, 235), font=font)
        y += 60

    path = OUTPUT_DIR / f"scene_{idx+1}.png"
    img.save(path, format="PNG")
    return str(path)


def _generate_openai_image(prompt: str, idx: int, size: str, retries: int = 3) -> str:
    """
    ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¹Ø¨Ø± OpenAI Images API (gpt-image-1) Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.
    ÙŠØ±Ù…ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙÙˆÙ„Ø¨Ø§Ùƒ.
    """
    if not USE_OPENAI or client is None:
        raise RuntimeError("OpenAI not configured")

    style_suffix = "\nStyle: cinematic, realistic, dramatic lighting, high detail."
    full_prompt = prompt.strip() + style_suffix

    last_err: Optional[Exception] = None
    for attempt in range(1, retries + 1):
        try:
            resp = client.images.generate(
                model="gpt-image-1",   # Ø¨Ø¯Ù‘Ù„Ù‡Ø§ Ù„Ùˆ Ø­Ø³Ø§Ø¨Ùƒ ÙŠØ¯Ø¹Ù… Ù†Ù…ÙˆØ°Ø¬ ØµÙˆØ± Ø¢Ø®Ø±
                prompt=full_prompt,
                size=size,
                quality="standard",
                n=1,
            )
            b64_img = resp.data[0].b64_json
            out_path = OUTPUT_DIR / f"scene_{idx+1}.png"
            _save_png_from_b64(b64_img, out_path)
            return str(out_path)
        except Exception as e:
            last_err = e
            wait = 1.5 * attempt
            logging.warning(f"[OpenAI] attempt {attempt} failed ({e}), retrying in {wait:.1f}sâ€¦")
            time.sleep(wait)

    raise RuntimeError(f"OpenAI image generation failed after {retries} attempts: {last_err}")


# ========= Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© =========
def generate_image_for_scene(
    scene_description: str,
    index: int,
    image_style: str = "cinematic realistic, dramatic lighting, high detail",
    size: str = "1024x1024",
) -> str:
    """
    ÙŠÙˆÙ„Ù‘Ø¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù…Ø´Ù‡Ø¯ Ù…Ø¹ÙŠÙ† Ù…Ø¹ ÙÙˆÙ„Ø¨Ø§ÙƒØ§Øª Ø¢Ù…Ù†Ø©.
    Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: OpenAI â†’ Ø¹ÙŠÙ†Ø§Øª Ù…Ø­Ù„ÙŠØ© â†’ ØµÙˆØ±Ø© Ù†ØµÙ‘ÙŠØ© Ù…Ø­Ù„ÙŠØ©.
    """
    # Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ø³ØªØ§ÙŠÙ„ØŒ Ø£Ø¯Ù…Ø¬Ù‡ Ù…Ø¹ Ø§Ù„ÙˆØµÙ
    scene_prompt = f"{scene_description}. Style: {image_style}."
    try:
        if USE_OPENAI:
            return _generate_openai_image(scene_prompt, idx=index, size=size)
        raise RuntimeError("OpenAI disabled or missing")
    except Exception as e:
        logging.info(f"[Fallback] OpenAI unavailable: {e}")
        from_samples = _copy_from_samples(index)
        if from_samples:
            return from_samples
        return _make_text_image(scene_description, index)


def generate_images_from_script(
    script_text: str,
    image_style: str = "cinematic realistic",
    size: str = "1024x1024",
) -> List[str]:
    """
    ÙŠØ­ÙˆÙ‘Ù„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ± Ù…Ø´Ø§Ù‡Ø¯.
    ÙŠÙ†Ø¸Ù‘Ù Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ù†ØªØ§Ø¦Ø¬ Ø­Ø¯ÙŠØ«Ø©.
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
    for f in OUTPUT_DIR.glob("*"):
        try:
            f.unlink()
        except Exception:
            pass

    scenes = extract_scenes(script_text)
    paths: List[str] = []

    for i, scene in enumerate(scenes):
        logging.info(f"ğŸ¨ Generating image for scene #{i+1}â€¦")
        p = generate_image_for_scene(
            scene_description=scene,
            index=i,
            image_style=image_style,
            size=size,
        )
        paths.append(p)

    return paths


def generate_images(script_text: str, lang: str = "ar") -> List[str]:
    """
    ÙˆØ§Ø¬Ù‡Ø© ÙŠØ³ØªØ¯Ø¹ÙŠÙ‡Ø§ Ø¨Ù‚ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.
    """
    style = "cinematic realistic, soft contrast, mood lighting, depth of field"
    return generate_images_from_script(script_text, image_style=style, size="1024x1024")


# ========= Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ =========
if _name_ == "_main_":
    try:
        # Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ¯ÙˆÙŠ Ø³Ø±ÙŠØ¹
        test_script = (
            "Ù…Ø´Ù‡Ø¯ 1: Ù„Ø§Ø¹Ø¨ ÙŠØ±Ø¨Ø· Ø§Ù„Ø­Ø°Ø§Ø¡ Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ø±ÙŠ.\n\n"
            "Ù…Ø´Ù‡Ø¯ 2: Ù‚Ø·Ø±Ø© Ø¹Ø±Ù‚ ØªØ³Ù‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶.\n\n"
            "Ù…Ø´Ù‡Ø¯ 3: Ø´Ø±ÙˆÙ‚ Ø§Ù„Ø´Ù…Ø³ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¶Ù…Ø§Ø±."
        )
        out = generate_images(test_script)
        print("âœ… Generated images:", out)
    except Exception as e:
        logging.error(f"Test run failed: {e}")
