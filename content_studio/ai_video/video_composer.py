# -- coding: utf-8 --
from __future__ import annotations

import os
import logging
from pathlib import Path
from typing import Optional, List, Tuple

from moviepy.editor import (
    ImageClip,
    AudioFileClip,
    concatenate_videoclips,
    CompositeAudioClip,
)
from moviepy.audio.fx import all as afx
from moviepy.audio.fx.all import audio_loop  # Ù„Ø¹Ù…Ù„ Ù„ÙˆÙˆØ¨ Ù„Ù„ØµÙˆØª Ø§Ù„Ø®Ù„ÙÙŠ

# ======================== Ù„ÙˆØ¬ÙŠÙ†Øº ========================
logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s | %(asctime)s | video_composer | %(message)s",
)

# ======================== Ù…Ø³Ø§Ø±Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ========================
IMAGES_DIR = Path("content_studio/ai_images/outputs/")
VOICE_PATH_DEFAULT = Path("content_studio/ai_voice/voices/final_voice.mp3")
VIDEO_OUTPUT_DIR = Path("content_studio/ai_video/final_videos/")
VIDEO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ======================== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ========================
def _collect_images(directory: Path) -> List[Path]:
    """ÙŠØ¬Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙˆÙŠØ±ØªÙ‘Ø¨Ù‡Ø§."""
    exts = (".png", ".jpg", ".jpeg", ".webp")
    files = [p for p in directory.glob("*") if p.suffix.lower() in exts]
    files.sort(key=lambda p: p.name)
    return files

def _resolve_aspect(aspect: Optional[str]) -> Tuple[int, int]:
    """
    ÙŠØ®ØªØ§Ø± Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø­Ø³Ø¨ Ø§Ù„Ù€ aspect:
      - "square"     â†’ 1080x1080
      - "portrait"   â†’ 1080x1920 (9:16)
      - "landscape"  â†’ 1920x1080 (16:9)
    Ù„Ùˆ Ù„Ù… ÙŠÙ…Ø±Ù‘Ø± aspect Ù†Ù‚Ø±Ø£ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ± VIDEO_ASPECTØŒ ÙˆØ¥Ù„Ø§ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ø±Ø¨Ø¹.
    """
    asp = (aspect or os.getenv("VIDEO_ASPECT", "square")).lower()
    if asp in ("portrait", "9:16", "portrait_9_16", "tall"):
        return (1080, 1920)
    if asp in ("landscape", "16:9", "landscape_16_9", "wide"):
        return (1920, 1080)
    return (1080, 1080)

def _prepare_clip(path: Path, duration: float, resolution: Tuple[int, int]) -> ImageClip:
    """
    ÙŠØ¶Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:
    - ÙŠØºÙŠÙ‘Ø± Ø§Ø±ØªÙØ§Ø¹Ù‡Ø§ Ù„Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
    - ÙŠØ¶ÙŠÙ Ø®Ù„ÙÙŠÙ‘Ø© (letterbox) Ù„ØªØµØ¨Ø­ Ø¨Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¯ÙˆÙ† Ù‚Øµ
    """
    w, h = resolution
    clip = ImageClip(str(path)).set_duration(duration)
    clip = clip.resize(height=h)  # ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    clip = clip.on_color(size=resolution, color=(0, 0, 0), col_opacity=1)
    return clip

# ======================== Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ========================
def compose_video_from_assets(
    image_duration: float = 4.0,
    resolution: Optional[Tuple[int, int]] = None,   # Ø¥Ù† ØªÙØ±ÙƒØª None Ù†Ø®ØªØ§Ø±Ù‡Ø§ Ù…Ù† aspect/env
    fps: int = 24,
    voice_path: Optional[str] = None,
    music_path: Optional[str] = None,
    music_volume: float = 0.15,
    durations: Optional[List[float]] = None,        # Ù…Ø¯Ø¯ Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ ØµÙˆØ±Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    aspect: Optional[str] = None,                   # "square" | "portrait" | "landscape"
    xfade: float = 0.5,                              # Ø²Ù…Ù† ØªØ¯Ø§Ø®Ù„ Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±
    kenburns_zoom: float = 0.03,                     # Ù†Ø³Ø¨Ø© ØªÙƒØ¨ÙŠØ± Ø¨Ø·ÙŠØ¡ (3%)
) -> Optional[str]:
    """
    ÙŠØ¬Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ IMAGES_DIR Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ ÙˆØ§Ø­Ø¯ Ù…Ø¹ ØµÙˆØª Ø§Ø®ØªÙŠØ§Ø±ÙŠ:

    - Ken Burns Ø®ÙÙŠÙ (ØªÙƒØ¨ÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠ).
    - Crossfade Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ± (xfade).
    - Ø¯Ø¹Ù… Ù…Ø¯Ø¯ Ø«Ø§Ø¨ØªØ© Ø£Ùˆ Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ ØµÙˆØ±Ø© (durations).
    - ØªØ¹Ù„ÙŠÙ‚ ØµÙˆØªÙŠ + Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø®Ù„ÙÙŠØ© Ù…Ø¹ Ù„ÙˆÙˆØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ùˆfade Ùˆ ducking Ø¨Ø³ÙŠØ·.
    - Ø§Ø®ØªÙŠØ§Ø± Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¹Ø¨Ø± Ø§Ù„ÙˆØ³ÙŠØ· Ø£Ùˆ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© VIDEO_ASPECT.

    Returns:
        Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (str) Ø£Ùˆ None Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„.
    """
    voice_clip = None
    music_clip = None
    video = None
    clip_list: List[ImageClip] = []
    music_raw = None
    try:
        # 1) ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        target_res = resolution or _resolve_aspect(aspect)
        logging.info(f"Target resolution: {target_res[0]}x{target_res[1]}")

        # 2) Ø§Ø¬Ù…Ø¹ Ø§Ù„ØµÙˆØ±
        images = _collect_images(IMAGES_DIR)
        if not images:
            raise RuntimeError(f"Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± Ø¯Ø§Ø®Ù„: {IMAGES_DIR}")

        # 3) Ø£Ù†Ø´Ø¦ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ken Burns + Crossfade
        per_image_durations = durations if durations and len(durations) == len(images) else None

        for i, p in enumerate(images):
            dur = per_image_durations[i] if per_image_durations else image_duration
            c = _prepare_clip(p, dur, target_res)

            # Ken Burns: ØªÙƒØ¨ÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠ Ø¨Ø³ÙŠØ·
            if kenburns_zoom and kenburns_zoom > 0:
                c = c.resize(lambda t: 1.0 + kenburns_zoom * (t / dur))

            # crossfade Ø¯Ø§Ø®Ù„ÙŠ Ù„Ù„ØµÙˆØ±Ø© Ø¹Ø¯Ø§ Ø§Ù„Ø£ÙˆÙ„Ù‰
            if xfade and i > 0:
                c = c.crossfadein(xfade)

            clip_list.append(c)

        # padding=-xfade Ù„ÙƒÙŠ ÙŠÙØ·Ø¨Ù‘Ù‚ Ø§Ù„ØªØ¯Ø§Ø®Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ±Ø©
        video = concatenate_videoclips(clip_list, method="compose", padding=-(xfade if xfade else 0))

        # 4) Ø§Ù„ØµÙˆØª
        # ØªØ¹Ù„ÙŠÙ‚ ØµÙˆØªÙŠ
        vp = Path(voice_path) if voice_path else VOICE_PATH_DEFAULT
        if vp and vp.exists():
            voice_clip = AudioFileClip(str(vp)).fx(afx.audio_fadein, 0.3).fx(afx.audio_fadeout, 0.3)

        # Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø®Ù„ÙÙŠØ© (Ù„ÙˆÙˆØ¨ Ø¨Ø·ÙˆÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ + Ø®ÙØ¶ Ø§Ù„ØµÙˆØª)
        if music_path and Path(music_path).exists():
            music_raw = AudioFileClip(music_path)
            music_clip = audio_loop(music_raw, duration=video.duration).volumex(music_volume)
            music_clip = music_clip.fx(afx.audio_fadein, 0.5).fx(afx.audio_fadeout, 0.5)

        if voice_clip and music_clip:
            # Ducking Ø¨Ø³ÙŠØ· Ø¨Ø®ÙØ¶ Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ù‚Ù„ÙŠÙ„Ù‹Ø§
            music_clip = music_clip.volumex(0.6)
            audio = CompositeAudioClip([voice_clip, music_clip])
            video = video.set_audio(audio)
        elif voice_clip:
            video = video.set_audio(voice_clip)
        elif music_clip:
            video = video.set_audio(music_clip)
        # ÙˆØ¥Ù„Ø§: Ø¨Ø¯ÙˆÙ† ØµÙˆØª

        # 5) Ø§Ù„ØªØµØ¯ÙŠØ±
        out_path = VIDEO_OUTPUT_DIR / "final_video.mp4"
        out_path.parent.mkdir(parents=True, exist_ok=True)

        logging.info(f"ğŸï¸ writing video to {out_path}")
        video.write_videofile(
            str(out_path),
            fps=fps,
            codec="libx264",
            audio_codec="aac",
            threads=2,
            preset="medium",
            ffmpeg_params=[
                "-movflags",
                "+faststart",
                # Ø£ÙØ¶Ù„ Ù„Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙŠØ¨
                "-pix_fmt",
                "yuv420p",
                # ØªÙˆØ§ÙÙ‚ Ø£ÙˆØ³Ø¹
            ],
            verbose=False,
            logger=None,
        )

        if not out_path.exists():
            raise RuntimeError("ØªÙ… Ø§Ù„ØªØµØ¯ÙŠØ± ÙˆÙ„ÙƒÙ† Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")

        logging.info(f"âœ… Video exported: {out_path}")
        return str(out_path.resolve())

    except Exception as e:
        logging.error(f"ğŸ”¥ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ±ÙƒÙŠØ¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}")
        return None

    finally:
        # 6) ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
        for c in clip_list:
            try:
                c.close()
            except Exception:
                pass
        try:
            if video:
                video.close()
        except Exception:
            pass
        try:
            if voice_clip:
                voice_clip.close()
        except Exception:
            pass
        try:
            if music_clip:
                music_clip.close()
        except Exception:
            pass
        try:
            if music_raw:
                music_raw.close()
        except Exception:
            pass

# ======================== ØªØ´ØºÙŠÙ„ Ø³Ø±ÙŠØ¹ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ========================
if _name_ == "_main_":
    # ØªØ£ÙƒØ¯ Ø£Ù† Ù„Ø¯ÙŠÙƒ ØµÙˆØ±Ù‹Ø§ Ø¯Ø§Ø®Ù„ IMAGES_DIR Ù‚Ø¨Ù„ Ø§Ù„ØªØ¬Ø±Ø¨Ø©
    out = compose_video_from_assets(
        image_duration=4,
        # aspect="portrait",  # Ø¬Ø±Ù‘Ø¨ "square"/"portrait"/"landscape" Ø£Ùˆ Ø§Ø¶Ø¨Ø· VIDEO_ASPECT Ø¨Ø§Ù„Ø¨ÙŠØ¦Ø©
        fps=24,
        # voice_path="content_studio/ai_voice/voices/final_voice.mp3",
        # music_path="path/to/music.mp3",
        # durations=[3, 5, 4, 4],  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ù…Ø¯Ø© Ù„ÙƒÙ„ ØµÙˆØ±Ø©
        xfade=0.5,
        kenburns_zoom=0.03,
    )
    print("Output:", out)
