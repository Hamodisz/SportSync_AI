# -- coding: utf-8 --
"""
core/kb_ranker.py
Ù…Ø­Ø±Ùƒ ØªÙˆØµÙŠØ§Øª "Ù…Ø¹Ø±ÙÙŠØ©" Ø¨Ø¯ÙˆÙ† ØªÙˆÙ„ÙŠØ¯ Ø­Ø±:
- ÙŠØ³ØªØ®Ø±Ø¬ Ø³Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª (AR/EN).
- ÙŠØ±ØªØ¨ Ø§Ù„Ù‡ÙˆÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ priors + trait_links + guards Ù…Ù† sportsync_knowledge.json.
- ÙŠÙ‚Ø±Ø£ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù‡ÙˆÙŠØ§Øª Ù…Ù† data/identities/*.json ÙˆÙŠØ±Ø¬Ø¹ 3 Ø¨Ø·Ø§Ù‚Ø§Øª ÙÙˆØ±Ù‹Ø§.
"""

from __future__ import annotations
import json, re
from pathlib import Path
from typing import Dict, Any, List, Tuple

# ---------- Ù†Øµ Ø¹Ø±Ø¨ÙŠ: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØªØ·Ø¨ÙŠØ¹ Ø¨Ø³ÙŠØ· ----------
_AR_DIAC = r"[ÙÙ‹ÙÙŒÙÙÙ’Ù‘Ù€]"
def _normalize_ar(t: str) -> str:
    if not t: return ""
    import re
    t = re.sub(_AR_DIAC, "", t)
    t = t.replace("Ø£","Ø§").replace("Ø¥","Ø§").replace("Ø¢","Ø§")
    t = t.replace("Ø¤","Ùˆ").replace("Ø¦","ÙŠ").replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    t = re.sub(r"\s+", " ", t).strip()
    return t.lower()

def _canon(label: str) -> str:
    if not label: return ""
    t = _normalize_ar(label)
    t = re.sub(r"[^a-z0-9\u0600-\u06FF]+", " ", t)
    t = re.sub(r"\s+", " ", t).strip(" -â€”:ØŒ")
    return t

# ---------- ØªØ­Ù…ÙŠÙ„ KB ----------
def _load_json(p: Path) -> dict:
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {}

def load_kb(kb_path: Path) -> dict:
    kb = _load_json(kb_path)
    kb.setdefault("priors", {})
    kb.setdefault("trait_links", {})
    kb.setdefault("guards", {})
    kb.setdefault("label_aliases", {})
    kb.setdefault("z_intent_keywords", {"ar":{}, "en":{}})
    # Ø®Ø±Ø§Ø¦Ø· alias -> canonical
    alias_map = {}
    for canon, aliases in kb.get("label_aliases", {}).items():
        ccanon = _canon(canon)
        for a in aliases or []:
            alias_map[_canon(a)] = ccanon or canon
        alias_map[ccanon] = ccanon
    kb["_alias_map"] = alias_map
    return kb

def resolve_label(label: str, kb: dict) -> str:
    a = _canon(label)
    return kb.get("_alias_map", {}).get(a, a)

# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ù…Ø§Øª Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ----------
def _blob_from_answers(answers: Dict[str, Any]) -> str:
    parts = []
    for v in (answers or {}).values():
        if isinstance(v, dict):
            if "answer" in v: parts.append(str(v.get("answer") or ""))
            else: parts.append(json.dumps(v, ensure_ascii=False))
        elif isinstance(v, list):
            parts.append(", ".join(map(str, v)))
        else:
            parts.append(str(v))
    return " ".join(str(x) for x in parts)

KW = {
    "ar": {
        "introvert": ["Ø§Ù†Ø·ÙˆØ§Ø¦ÙŠ","Ù‡Ø§Ø¯ÙŠ","Ø§Ø­Ø¨ Ù„ÙˆØ­Ø¯ÙŠ","ÙØ±Ø¯ÙŠ","Ù…Ø§Ø§Ø­Ø¨ Ø§Ù„Ø²Ø­Ù…Ù‡","Ù‚Ù„ÙŠÙ„ ÙƒÙ„Ø§Ù…"],
        "extrovert": ["Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ","Ø§Ø­Ø¨ Ø§Ù„ÙØ±ÙŠÙ‚","Ø§Ø­Ø¨ Ø§Ù„Ù†Ø§Ø³","Ø²Ø­Ù…Ù‡","Ø§Ø®ØªÙ„Ø§Ø·","ØªØ¬Ù…Ø¹"],
        "precision": ["Ø¯Ù‚Ù‡","ØªØµÙˆÙŠØ¨","Ù†Ø´Ø§Ù†","Ù…Ø­ÙƒÙ…","Ø¶Ø¨Ø·","Ù…ØªÙ‚Ù†"],
        "sustained_attention": ["ØªØ±ÙƒÙŠØ² Ø·ÙˆÙŠÙ„","ØµØ¨Ø±","ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚","Ø¬Ù„ÙˆØ³ Ø·ÙˆÙŠÙ„","Ø´Ø·Ø±Ù†Ø¬"],
        "sensation_seeking": ["Ù…ØºØ§Ù…Ø±Ù‡","Ø§Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†","Ø³Ø±Ø¹Ù‡","Ø®Ø·Ø±","Ù‚ÙØ²","Ù‚ÙˆÙŠÙ‡"],
        "calm_regulation": ["Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙØ³","ØªÙ†ÙÙ‘Ø³","ØµÙØ§Ø¡","ÙŠÙˆØºØ§","ØªÙ†Ø¸ÙŠÙ… Ù†ÙØ³"],
        "tactical_mindset": ["ØªÙƒØªÙŠÙƒ","Ø®Ø·Ø©","ÙƒÙ…ÙŠÙ†","Ø®Ø¯Ø¹","Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ"],
        "likes_puzzles": ["Ù„ØºØ²","Ø§Ù„ØºØ§Ø²","Ø®Ø¯Ø¹Ù‡ Ø¨ØµØ±ÙŠÙ‡","puzzle","Ø§Ø­Ø§Ø¬ÙŠ"],
        "prefers_solo": ["ÙØ±Ø¯ÙŠ","Ù„ÙˆØ­Ø¯ÙŠ","Ø¨Ø¯ÙˆÙ† ÙØ±ÙŠÙ‚"],
        "prefers_team": ["ÙØ±ÙŠÙ‚","Ø¬Ù…Ø§Ø¹ÙŠ","Ù…Ø¹ Ù†Ø§Ø³","co-op"],
        "anxious": ["Ù‚Ù„Ù‚","Ø®Ø§Ø¦Ù","Ø±Ù‡Ø¨Ù‡","ÙÙˆØ¨ÙŠØ§","ØªÙˆØªØ± Ø¹Ø§Ù„ÙŠ"],
        "low_repetition_tolerance": ["Ø§Ù…Ù„ Ø¨Ø³Ø±Ø¹Ø©","Ù…Ù„Ù„","Ø§ÙƒØ±Ù‡ Ø§Ù„ØªÙƒØ±Ø§Ø±","Ø±ÙˆØªÙŠÙ†"],
        "needs_quick_wins": ["Ù†ØªÙŠØ¬Ù‡ Ø³Ø±ÙŠØ¹Ù‡","Ù†ØªÙŠØ¬Ù‡ ÙÙˆØ±ÙŠÙ‡","Ø§Ø­Ø¨ Ø§Ù„Ø§Ù†Ø¬Ø§Ø² Ø§Ù„Ø³Ø±ÙŠØ¹"],
        "vr_inclination": ["vr","ÙˆØ§Ù‚Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ","Ù†Ø¸Ø§Ø±Ù‡","Ø§ÙØªØ±Ø§Ø¶ÙŠ"],
    },
    "en": {
        "introvert": ["introvert","quiet","alone","solo"],
        "extrovert": ["extrovert","social","team","group","crowd"],
        "precision": ["precision","aim","mark","accurate","steady"],
        "sustained_attention": ["deep focus","long focus","patience","think long"],
        "sensation_seeking": ["adrenaline","thrill","risk","fast","jump"],
        "calm_regulation": ["calm","breath","breathing","yoga","relax"],
        "tactical_mindset": ["tactic","strategic","ambush","plan"],
        "likes_puzzles": ["puzzle","riddle","feint","trick"],
        "prefers_solo": ["solo","alone","individual"],
        "prefers_team": ["team","group","co-op","squad"],
        "anxious": ["anxious","anxiety","fear","phobia","tense"],
        "low_repetition_tolerance": ["bored quickly","hate repetition","monotony"],
        "needs_quick_wins": ["quick win","fast result","immediate"],
        "vr_inclination": ["vr","virtual reality","headset"],
    }
}

def _score_kw(blob: str, words: List[str]) -> float:
    if not words: return 0.0
    hits = 0
    blob_l = blob.lower()
    blob_ar = _normalize_ar(blob)
    for w in words:
        w_l = w.lower()
        if w_l in blob_l or _normalize_ar(w_l) in blob_ar:
            hits += 1
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù…Ø¯Ù‰ 0..1 Ù…Ø¹ Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ø¨Ø³ÙŠØ·
    return min(1.0, hits / max(2.0, len(words)/2.0))

def extract_traits(answers: Dict[str, Any], lang: str, kb: dict) -> Dict[str, float]:
    # Ù†Ø¯Ù…Ø¬ AR Ùˆ EN Ù„Ù„ÙƒØ´Ù Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù„ØºØ©
    blob = _blob_from_answers(answers)
    traits = {}
    for tname, words in KW["ar"].items():
        traits[tname] = max(_score_kw(blob, words), _score_kw(blob, KW["en"].get(tname, [])))
    # Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ§Øª: introvert/extrovert Ùˆ solo/team
    if traits["introvert"] > traits["extrovert"]:
        traits["extrovert"] *= 0.5
    elif traits["extrovert"] > traits["introvert"]:
        traits["introvert"] *= 0.5

    if traits["prefers_solo"] > traits["prefers_team"]:
        traits["prefers_team"] *= 0.5
    elif traits["prefers_team"] > traits["prefers_solo"]:
        traits["prefers_solo"] *= 0.5

    return traits

# ---------- ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù†Ø´Ø·Ø© ----------
def score_labels(traits: Dict[str,float], kb: dict, candidate_labels: List[str]) -> List[Tuple[str,float]]:
    priors: Dict[str,float] = kb.get("priors", {})
    links: Dict[str,Dict[str,float]] = kb.get("trait_links", {})
    guards: Dict[str,Any] = kb.get("guards", {})

    scores = {}
    for raw in candidate_labels:
        lab = resolve_label(raw, kb)
        base = float(priors.get(lab, 0.03))
        s = base
        for t, tscore in traits.items():
            w = float(links.get(t, {}).get(lab, 0.0))
            if w != 0.0 and tscore > 0:
                s += tscore * w
        scores[lab] = s

    # Ø­Ø±Ø³: Ø§Ù„Ù‚Ù„Ù‚ Ø§Ù„Ø¹Ø§Ù„ÙŠ ÙˆØ±ÙŠØ§Ø¶Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
    anxious = traits.get("anxious", 0.0)
    if guards.get("no_high_risk_for_anxiety", True) and anxious >= 0.5:
        for hr in guards.get("high_risk_sports", []):
            lab = resolve_label(hr, kb)
            if lab in scores:
                scores[lab] = max(0.0, scores[lab] - 1.5)

    ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)
    return ranked

# ---------- Ù‚Ø±Ø§Ø¡Ø© Ù‡ÙˆÙŠØ© + ØªÙˆÙ„ÙŠØ¯ Ø¨Ø·Ø§Ù‚Ø© ----------
def _pick_lang(val: Any, lang: str) -> Any:
    # ÙŠØ¯Ø¹Ù… { "ar": "...", "en": "..." } Ø£Ùˆ Ù†Øµ Ù…Ø¨Ø§Ø´Ø±
    if isinstance(val, dict):
        return val.get("ar") if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else val.get("en")
    return val

def _to_list(val: Any, lang: str) -> List[str]:
    v = _pick_lang(val, lang)
    if isinstance(v, list): return v
    if isinstance(v, str):  # ÙŠÙØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø·Ø± Ø£Ùˆ Ø§Ù„ÙÙˆØ§ØµÙ„
        parts = re.split(r"[,\nØŒ]+", v)
        return [p.strip(" -â€¢\t") for p in parts if p.strip()]
    return []

def load_identity(label: str, lang: str, identities_dir: Path, kb: dict) -> Dict[str, Any]:
    lab = resolve_label(label, kb)
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 1: Ø¨Ø§Ù„Ù…Ø³Ø§ÙØ§Øª (ÙƒÙ…Ø§ Ø¬Ø§Ø¡ Ù…Ù† resolve_label)
    path = (identities_dir / f"{lab}.json")
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 2: Ù„Ùˆ Ù…Ø§ Ù„Ù‚Ù‰ Ø§Ù„Ù…Ù„ÙØŒ Ø¬Ø±Ø¨ Ø¨Ø§Ù„Ø´Ø±Ø·Ø§Øª Ø§Ù„Ø³ÙÙ„ÙŠØ©
    if not path.exists():
        lab_underscore = lab.replace(" ", "_")
        path = (identities_dir / f"{lab_underscore}.json")
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 3: Ø¬Ø±Ø¨ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„
    if not path.exists():
        path = (identities_dir / f"{label}.json")
    
    data = _load_json(path)
    if not data:
        return {}
    # Ø­Ø²Ù… Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø¨Ø§Ù„Ù„Ù‘ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    out = {
        "sport_label": _pick_lang(data.get("sport_label",""), lang) or "",
        "what_it_looks_like": _pick_lang(data.get("what_it_looks_like",""), lang) or "",
        "inner_sensation": _pick_lang(data.get("inner_sensation",""), lang) or "",
        "why_you": _pick_lang(data.get("why_you",""), lang) or "",
        "first_week": _pick_lang(data.get("first_week",""), lang) or "",
        "progress_markers": _pick_lang(data.get("progress_markers",""), lang) or "",
        "win_condition": _pick_lang(data.get("win_condition",""), lang) or "",
        "core_skills": _to_list(data.get("core_skills",[]), lang),
        "mode": _pick_lang(data.get("mode","Solo"), lang) or "Solo",
        "variant_vr": _pick_lang(data.get("variant_vr",""), lang) or "",
        "variant_no_vr": _pick_lang(data.get("variant_no_vr",""), lang) or "",
        "difficulty": int(data.get("difficulty", 3)),
        "real_world_examples": _pick_lang(data.get("real_world_examples",""), lang) or "",
        "psychological_hook": _pick_lang(data.get("psychological_hook",""), lang) or "",
    }
    return out

def _one_liner(*parts: str, max_len: int = 140) -> str:
    s = " â€” ".join(str(p).strip() for p in parts if p and str(p).strip())
    return s[:max_len]

def _bullets(text: str, max_items: int = 6) -> List[str]:
    items = _to_list(text, "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") if isinstance(text, dict) else _to_list(text, "en")
    if not items and isinstance(text, str):
        items = [text.strip()]
    return items[:max_items] if items else []

def render_card(rec: Dict[str,Any], idx: int, lang: str) -> str:
    head_ar = ["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1","ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2","ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ğŸŸ¢ Recommendation 1","ğŸŒ¿ Recommendation 2","ğŸ”® Recommendation 3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[idx]

    label = rec.get("sport_label","").strip()
    scene = rec.get("what_it_looks_like","").strip()  # Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ - Ù„Ø§ Ø§Ø®ØªØµØ§Ø±!
    inner = rec.get("inner_sensation","").strip()
    why   = rec.get("why_you","").strip()
    week  = rec.get("first_week","").strip()  # Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„
    prog  = rec.get("progress_markers","").strip()  # Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„
    win   = rec.get("win_condition","").strip()
    skills= rec.get("core_skills", [])[:5]
    diff  = rec.get("difficulty", 3)
    mode  = (rec.get("mode") or "").strip()
    vr    = (rec.get("variant_vr") or "").strip()
    novr  = (rec.get("variant_no_vr") or "").strip()
    
    # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    real_examples = rec.get("real_world_examples", "").strip() if isinstance(rec.get("real_world_examples"), str) else _pick_lang(rec.get("real_world_examples", {}), lang)
    psych_hook = rec.get("psychological_hook", "").strip() if isinstance(rec.get("psychological_hook"), str) else _pick_lang(rec.get("psychological_hook", {}), lang)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ø§Ù„Ø±ÙŠØ§Ø¶Ø© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ùƒ: **{label}**\n")
        
        # Ø§Ù„Ù‚ØµØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© - Ø¨Ø¯ÙˆÙ† Ø§Ø®ØªØµØ§Ø±!
        if scene: 
            out.append("ğŸ’¡ **Ù…Ø§ Ù‡ÙŠØŸ**")
            out.append(scene + "\n")
        
        if inner:
            out.append(f"âœ¨ **Ø§Ù„Ø¥Ø­Ø³Ø§Ø³ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ:**\n{inner}\n")
        
        if why:
            out.append("ğŸ® **Ù„ÙŠÙ‡ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ**")
            out.append(why + "\n")
        
        if skills:
            out.append("ğŸ§© **Ù…Ù‡Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©:**")
            for s in skills:
                out.append(f"â€¢ {s}")
            out.append("")
        
        if win:
            out.append("ğŸ **ÙƒÙŠÙ ØªÙÙˆØ²ØŸ**")
            out.append(win + "\n")
        
        if week:
            out.append("ğŸš€ **Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø£ÙˆÙ„:**")
            out.append(week + "\n")
        
        if prog:
            out.append("âœ… **Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù…:**")
            out.append(prog + "\n")
        
        # Ø®ÙŠØ§Ø±Ø§Øª VR/Non-VR
        if vr or novr:
            out.append("ğŸ® **Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:**\n")
            if vr:
                out.append(vr)
            if novr:
                out.append("\n" + novr if vr else novr)
            out.append("")
        
        # Ø£Ù…Ø§ÙƒÙ† Ø­Ù‚ÙŠÙ‚ÙŠØ©
        if real_examples:
            out.append(real_examples + "\n")
        
        # Ø§Ù„Ù€ Hook Ø§Ù„Ù†ÙØ³ÙŠ
        if psych_hook:
            out.append(psych_hook + "\n")
        
        if mode:
            out.append(f"ğŸ‘¥ **Ø§Ù„ÙˆØ¶Ø¹:** {mode}")
        
        out.append(f"\nğŸ“Š **Ø§Ù„Ù…Ø³ØªÙˆÙ‰:** {diff}/5")
        
        return "\n".join(str(x) for x in out)
    else:
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ideal identity: {label}")
        if intro: out += ["\nğŸ’¡ What is it?", f"- {intro}"]
        if why:
            out += ["\nğŸ® Why you"]
            for b in _bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Core skills:"] + [f"- {s}" for s in skills]
        if win: out += ["\nğŸ Win condition", f"- {win}"]
        if week: out += ["\nğŸš€ First week (qualitative)"] + [f"- {b}" for b in week]
        if prog: out += ["\nâœ… Progress cues"] + [f"- {b}" for b in prog]
        notes = []
        if mode: notes.append(("Mode: " + mode))
        if novr: notes.append("No-VR: " + novr)
        if vr: notes.append("VR (optional): " + vr)
        if notes: out += ["\nğŸ‘â€ğŸ—¨ Notes:", f"- " + "\n- ".join(str(x) for x in notes)]
        out.append(f"\nApprox level: {diff}/5")
        return "\n".join(str(x) for x in out)

# ---------- Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ ----------
def rank_and_render(answers: Dict[str,Any], lang: str,
                    kb_path: Path, identities_dir: Path,
                    top_k: int = 3) -> List[str]:
    kb = load_kb(kb_path)
    traits = extract_traits(answers, lang, kb)

    # Ù†Ø±Ø´Ù‘Ø­ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† ÙØ¹Ù„ÙŠÙ‹Ø§ ÙÙŠ identities_dir
    available = []
    for p in identities_dir.glob("*.json"):
        available.append(p.stem)

    ranked = score_labels(traits, kb, available)
    if not ranked:
        return ["â€”","â€”","â€”"]

    # Ù†Ø®ØªØ§Ø± Ø£Ø¹Ù„Ù‰ 3 Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆÙ†Ø¨Ù†ÙŠ Ø¨Ø·Ø§Ù‚Ø§Øª
    cards: List[str] = []
    picked = 0
    for lab, _ in ranked:
        rec = load_identity(lab, lang, identities_dir, kb)
        if not rec: continue
        cards.append(render_card(rec, picked, lang))
        picked += 1
        if picked >= top_k:
            break

    # Ù„Ùˆ Ù…Ø§ ÙƒÙØªØŒ Ù†ÙƒÙ…Ù‘Ù„ Ø¨Ø£ÙŠ Ù‚ÙˆØ§Ù„Ø¨ Ù…ØªØ§Ø­Ø©
    while picked < top_k and available:
        rec = load_identity(available[picked % len(available)], lang, identities_dir, kb)
        if rec:
            cards.append(render_card(rec, picked, lang))
            picked += 1
        else:
            break

    # Ø¶Ù…Ø§Ù† 3 Ø¹Ù†Ø§ØµØ±
    while len(cards) < 3: cards.append("â€”")
    return cards


def rank_and_get_identities(answers: Dict[str,Any], lang: str,
                             kb_path: Path, identities_dir: Path,
                             top_k: int = 3) -> List[Dict[str, Any]]:
    """
    Ù†ÙØ³ rank_and_render Ù„ÙƒÙ† ØªØ±Ø¬Ø¹ dicts Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù†ØµÙˆØµ
    Ø¹Ø´Ø§Ù† backend_gpt ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
    """
    kb = load_kb(kb_path)
    traits = extract_traits(answers, lang, kb)

    # Ù†Ø±Ø´Ù‘Ø­ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† ÙØ¹Ù„ÙŠÙ‹Ø§ ÙÙŠ identities_dir
    available = []
    for p in identities_dir.glob("*.json"):
        available.append(p.stem)

    ranked = score_labels(traits, kb, available)
    if not ranked:
        return []

    # Ù†Ø®ØªØ§Ø± Ø£Ø¹Ù„Ù‰ top_k Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆÙ†Ø±Ø¬Ø¹ Ø§Ù„Ù€ dicts
    identities: List[Dict[str, Any]] = []
    for lab, _ in ranked:
        rec = load_identity(lab, lang, identities_dir, kb)
        if rec and rec.get('sport_label'):  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
            identities.append(rec)
        if len(identities) >= top_k:
            break

    return identities
