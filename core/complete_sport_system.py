# -*- coding: utf-8 -*-
"""
Complete Sport Invention Integration
=====================================
Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© ÙˆÙ†Ø¸ÙŠÙØ©
"""

from typing import Dict, List, Any, Optional
import json

# Import all components
try:
    from core.advanced_sport_inventor import get_advanced_inventor
    from core.dual_model_client import (
        analyze_user_with_discovery,
        _init_dual_models
    )
    from core.llm_client import chat_once, make_llm_client_singleton
    FULL_SYSTEM_AVAILABLE = True
except Exception as e:
    print(f"[INTEGRATION] Import error: {e}")
    FULL_SYSTEM_AVAILABLE = False


def generate_complete_sport_recommendations(
    user_answers: Dict[str, Any],
    user_traits: Dict[str, float],
    user_identity: Dict[str, float],
    language: str = 'ar',
    num_recommendations: int = 3
) -> List[Dict[str, Any]]:
    """
    ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© - Ø´Ø®ØµÙŠØ© ÙˆØ¹Ù…ÙŠÙ‚Ø©
    """
    
    if not FULL_SYSTEM_AVAILABLE:
        return _fallback_recommendations(language)
    
    print("[INTEGRATION] Starting complete invention process...")
    
    # Step 1: Discovery Analysis
    print("[INTEGRATION] Step 1/6: Discovery Model analysis...")
    discovery_analysis = analyze_user_with_discovery(
        answers=user_answers,
        identity=user_identity,
        traits=user_traits,
        lang=language
    )
    
    # Step 2: Advanced Inventor
    print("[INTEGRATION] Step 2/6: Advanced Sport Invention...")
    inventor = get_advanced_inventor()
    
    inventions = []
    for i in range(num_recommendations):
        try:
            invention = inventor.invent_sport(
                user_answers=user_answers,
                traits=user_traits,
                lang=language
            )
            
            if invention:
                invention['discovery_insights'] = discovery_analysis.get('initial_insights', {})
                invention['layer_z_drivers'] = discovery_analysis.get('hidden_drives', [])
                inventions.append(invention)
                
        except Exception as e:
            print(f"[INTEGRATION] Invention {i} failed: {e}")
    
    # Step 3: Reasoning Model Enhancement
    print("[INTEGRATION] Step 3/6: Reasoning Model enhancement...")
    if len(inventions) > 0:
        inventions = _enhance_with_reasoning(inventions, discovery_analysis, user_traits, language)
    
    # Step 4: Validate and score
    print("[INTEGRATION] Step 4/6: Validation...")
    inventions = _validate_and_score(inventions, user_traits)
    
    # Step 5: Sort and return top N
    print("[INTEGRATION] Step 5/6: Finalization...")
    inventions.sort(key=lambda x: x.get('match_score', 0), reverse=True)
    
    final_inventions = inventions[:num_recommendations]
    
    print(f"[INTEGRATION] âœ… Generated {len(final_inventions)} complete sport inventions")
    
    return final_inventions


def _enhance_with_reasoning(
    inventions: List[Dict],
    discovery_analysis: Dict,
    user_traits: Dict[str, float],
    language: str
) -> List[Dict]:
    """
    ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Reasoning Model - Ù…Ø¹ ØªØ´Ø®ÙŠØµ Ù†ÙØ³ÙŠ Ø¹Ù…ÙŠÙ‚
    """
    try:
        _init_dual_models()
        client = make_llm_client_singleton()
        
        if not client:
            return inventions
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚
        user_context = _build_personal_context(discovery_analysis, user_traits, language)
        
        if language == 'ar':
            system_prompt = """Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø±ÙŠØ§Ø¶ÙŠ Ù†ÙØ³ÙŠ Ø¹Ù…ÙŠÙ‚. Ù…Ù‡Ù…ØªÙƒ: ØªØ´Ø®ÙŠØµ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù…Ø®ÙÙŠØ©.

**Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© (EXACTLY):**

```json
{
  "sports": [
    {
      "sport_name": "[Ø§Ø³Ù… Ù…Ø«ÙŠØ± Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©]",
      "what_is_it": [
        "Ø¬Ù…Ù„Ø© 1 - ÙˆØµÙ Ø§Ù„ØªØ¬Ø±Ø¨Ø©",
        "Ø¬Ù…Ù„Ø© 2 - Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø±ÙŠØ§Ø¶Ø©",
        "Ø¬Ù…Ù„Ø© 3 - Ø§Ù„Ø¥Ø­Ø³Ø§Ø³ Ø§Ù„Ø¹Ù…ÙŠÙ‚"
      ],
      "why_suits_you": [
        "Ø£Ù†Øª [ØµÙØ© Ù†ÙØ³ÙŠØ©] - [Ø±Ø¨Ø· Ø¨Ø§Ù„Ø±ÙŠØ§Ø¶Ø©]",
        "[Ø¯Ø§ÙØ¹ Ø®ÙÙŠ] - [ÙƒÙŠÙ ØªÙ„Ù…Ø³Ù‡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø©]",
        "[Ù…ØªØ¹Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©] - [Ù„ÙŠØ³ Ù…Ø¬Ø±Ø¯ Ø­Ø±ÙƒØ©]"
      ],
      "how_it_looks": [
        "ØªØ¯Ø®Ù„ [ÙˆØµÙ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©]",
        "ØªØ³ØªØ®Ø¯Ù… [Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø­ÙŠØ©]",
        "[Ù†ØªÙŠØ¬Ø© Ù†ÙØ³ÙŠØ©] - Ø¯Ø§Ø®Ù„Ùƒ ØªØ¹Ø±Ù Ø¥Ù†Ùƒ ØªÙ†Ù…Ùˆ"
      ],
      "important_notes": [
        "[Ø¬Ù…Ù„Ø© Ù‚ÙˆÙŠØ© ØªÙ„Ø§Ù…Ø³ Ø§Ù„Ù‡ÙˆÙŠØ©]",
        "[Ù†ØµÙŠØ­Ø© Ø¹Ù…Ù„ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡]"
      ]
    }
  ]
}
```

**Ù…Ø«Ø§Ù„ Ø­Ù‚ÙŠÙ‚ÙŠ:**
"Ø£Ù†Øª ØªÙƒØ±Ù‡ Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ ØªØ±ÙØ¶ Ø§Ù„Ø³Ø·Ø­ÙŠØ©ØŒ ÙˆØªØ­Ø¨ ØªÙˆØµÙ„ Ù„Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø´ÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ"

**CRITICAL:**
- Ø§Ø³ØªØ®Ø¯Ù… "Ø£Ù†Øª" ÙÙŠ ÙƒÙ„ Ø¬Ù…Ù„Ø© Ø¨Ù€ why_suits_you
- Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„ÙƒÙ„ÙŠ: 120-180 ÙƒÙ„Ù…Ø©
- Ù„Ø§ ØªØ°ÙƒØ± VR Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø´Ø®ØµÙŠØ©
- Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø´Ø¹ÙˆØ±

JSON format ONLY."""
        else:
            system_prompt = """You are a deep sports psychologist. Mission: Diagnose hidden athletic identity.

**Exact Structure (EXACTLY):**

```json
{
  "sports": [
    {
      "sport_name": "[Exciting English name]",
      "what_is_it": [
        "Sentence 1 - experience description",
        "Sentence 2 - sport elements",
        "Sentence 3 - deep feeling"
      ],
      "why_suits_you": [
        "You [psychological trait] - [sport connection]",
        "[Hidden driver] - [how sport touches it]",
        "[True pleasure] - [not just movement]"
      ],
      "how_it_looks": [
        "You enter [start description]",
        "You use [live experience]",
        "[Psychological result] - inside you know you're growing"
      ],
      "important_notes": [
        "[One powerful identity-touching sentence]",
        "[Practical advice to start]"
      ]
    }
  ]
}
```

**Real Example:**
"You hate repetition, reject superficiality, and love reaching the true essence"

**CRITICAL:**
- Use "You" in every why_suits_you sentence
- Total length: 120-180 words
- Mention VR only if fits personality
- Focus on identity and feeling

JSON format ONLY."""
        
        import os
        reasoning_model = os.getenv("CHAT_MODEL_REASONING", "gpt-4o")
        
        reasoning_data = {
            'inventions': [
                {
                    'label': inv.get('sport_label'),
                    'base': inv.get('base_sport'),
                    'components': inv.get('hybrid_components', [])
                }
                for inv in inventions
            ],
            'language': language
        }
        
        enhanced_json = chat_once(
            client,
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_context + "\n\n" + json.dumps(reasoning_data, ensure_ascii=False)}
            ],
            model=reasoning_model,
            temperature=0.7,
            max_tokens=800
        )
        
        # Parse and merge
        try:
            enhanced_data = json.loads(enhanced_json)
            enhanced_sports = enhanced_data.get('sports', [])
            
            for i, sport in enumerate(enhanced_sports):
                if i < len(inventions):
                    inventions[i]['sport_name'] = sport.get('sport_name', inventions[i].get('sport_label'))
                    inventions[i]['what_is_it'] = sport.get('what_is_it', [])
                    inventions[i]['why_suits_you'] = sport.get('why_suits_you', [])
                    inventions[i]['how_it_looks'] = sport.get('how_it_looks', [])
                    inventions[i]['important_notes'] = sport.get('important_notes', [])
                    
        except Exception as e:
            print(f"[REASONING] JSON parse failed: {e}")
        
    except Exception as e:
        print(f"[REASONING] Enhancement failed: {e}")
    
    return inventions


def _validate_and_score(
    inventions: List[Dict],
    traits: Dict[str, float]
) -> List[Dict]:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡Ø§
    """
    for invention in inventions:
        # Map old fields to new structure if needed
        if 'sport_label' in invention and 'sport_name' not in invention:
            invention['sport_name'] = invention['sport_label']
        
        if 'what_is_it' not in invention or not invention['what_is_it']:
            # Generate from existing data
            label = invention.get('sport_name', invention.get('sport_label', 'Ø±ÙŠØ§Ø¶Ø© Ù…Ø®ØµØµØ©'))
            base = invention.get('base_sport', '')
            if base:
                invention['what_is_it'] = [
                    f"ØªØ¬Ø±Ø¨Ø© Ø±ÙŠØ§Ø¶ÙŠØ© Ù…Ø¨ØªÙƒØ±Ø© ØªØ¬Ù…Ø¹ Ø¹Ù†Ø§ØµØ± {base}",
                    "Ù…ØµÙ…Ù…Ø© Ø®ØµÙŠØµØ§Ù‹ Ù„ØªÙ†Ø§Ø³Ø¨ Ø´Ø®ØµÙŠØªÙƒ",
                    "ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ¹Ø© ÙˆØ§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ…Ø±"
                ]
            else:
                invention['what_is_it'] = [
                    f"{label} - ØªØ¬Ø±Ø¨Ø© ÙØ±ÙŠØ¯Ø©",
                    "Ù…ØµÙ…Ù…Ø© Ù„ØªÙ„Ø§Ù…Ø³ Ø¯ÙˆØ§ÙØ¹Ùƒ Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©",
                    "ÙƒÙ„ Ø¬Ù„Ø³Ø© ÙØ±ØµØ© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù†Ù…Ùˆ"
                ]
        
        if 'why_suits_you' not in invention or not invention['why_suits_you']:
            # Generate from traits
            top_traits = sorted(traits.items(), key=lambda x: x[1], reverse=True)[:3]
            invention['why_suits_you'] = [
                f"Ø£Ù†Øª ØªÙ…ØªÙ„Ùƒ {top_traits[0][0]} Ø¨Ù†Ø³Ø¨Ø© Ø¹Ø§Ù„ÙŠØ©",
                "ØªØ¨Ø­Ø« Ø¹Ù† ØªØ¬Ø±Ø¨Ø© ØªÙ„Ø§Ù…Ø³ Ø´Ø®ØµÙŠØªÙƒ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©",
                "Ù‡Ø°Ù‡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø© ØªÙÙ‡Ù… Ø¯ÙˆØ§ÙØ¹Ùƒ Ø§Ù„Ø®ÙÙŠØ©"
            ]
        
        if 'how_it_looks' not in invention or not invention['how_it_looks']:
            first_week = invention.get('first_week', {})
            if first_week:
                steps = list(first_week.values())[:3]
                invention['how_it_looks'] = steps if steps else [
                    "ØªØ¯Ø®Ù„ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¨Ø¹Ù‚Ù„ Ù…Ù†ÙØªØ­",
                    "ØªØ³ØªØ®Ø¯Ù… Ø¬Ø³Ù…Ùƒ ÙˆØ¹Ù‚Ù„Ùƒ Ù…Ø¹Ø§Ù‹",
                    "ÙƒÙ„ Ù„Ø­Ø¸Ø© ÙØ±ØµØ© Ù„Ù„Ù†Ù…Ùˆ"
                ]
            else:
                invention['how_it_looks'] = [
                    "ØªØ¨Ø¯Ø£ Ø¨Ø¬Ù„Ø³Ø© Ù‚ØµÙŠØ±Ø© 10-15 Ø¯Ù‚ÙŠÙ‚Ø©",
                    "ØªØ´Ø¹Ø± Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù‚Ù„ ÙˆØ§Ù„Ø¬Ø³Ø¯",
                    "Ø§Ù„ØªÙ‚Ø¯Ù… ÙŠØ£ØªÙŠ Ø·Ø¨ÙŠØ¹ÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø©"
                ]
        
        if 'important_notes' not in invention or not invention['important_notes']:
            where_start = invention.get('where_to_start', [])
            invention['important_notes'] = where_start[:2] if where_start else [
                "Ø§Ø¨Ø¯Ø£ Ø¨Ø¯ÙˆÙ† Ø¶ØºØ· Ø£Ùˆ ØªÙˆÙ‚Ø¹Ø§Øª",
                "Ø§Ø³ØªÙ…ØªØ¹ Ø¨Ø§Ù„Ø±Ø­Ù„Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„ÙˆØ¬Ù‡Ø©"
            ]
        
        # Validate word count
        total_words = 0
        for field in ['what_is_it', 'why_suits_you', 'how_it_looks', 'important_notes']:
            items = invention.get(field, [])
            if isinstance(items, list):
                total_words += sum(len(str(item).split()) for item in items)
        
        # Validate "Ø£Ù†Øª" usage
        why_suits = invention.get('why_suits_you', [])
        you_count = sum(1 for item in why_suits if 'Ø£Ù†Øª' in str(item) or 'You' in str(item))
        
        # Calculate score
        base_score = 85
        if 120 <= total_words <= 180:
            base_score += 5
        if you_count >= 2:
            base_score += 5
        if all(k in invention for k in ['sport_name', 'what_is_it', 'why_suits_you']):
            base_score += 5
        
        invention['match_score'] = min(base_score, 100)
        invention['word_count'] = total_words
        invention['you_count'] = you_count
    
    return inventions


def _build_personal_context(
    discovery_analysis: Dict, 
    user_traits: Dict[str, float],
    language: str
) -> str:
    """
    Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚
    """
    
    # Extract dominant identity
    identity_scores = discovery_analysis.get('identity_scores', {})
    if identity_scores:
        dominant_identity = max(identity_scores.items(), key=lambda x: x[1])[0]
        identity_strength = max(identity_scores.values())
    else:
        dominant_identity = 'explorer'
        identity_strength = 0.5
    
    # Extract hidden drivers
    hidden_drivers = discovery_analysis.get('hidden_drives', [])[:3]
    
    # Extract top traits
    top_traits = sorted(user_traits.items(), key=lambda x: x[1], reverse=True)[:3]
    
    if language == 'ar':
        context = f"""**Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚:**

ğŸ§¬ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰: {dominant_identity} ({identity_strength:.0%})

ğŸ”¥ Ø§Ù„Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ø®ÙÙŠØ© (Layer Z):
{chr(10).join([f'â€¢ {driver}' for driver in hidden_drivers]) if hidden_drivers else 'â€¢ Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù†Ù‰'}

ğŸ§  Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰:
{chr(10).join([f'â€¢ {trait}: {score:.0%}' for trait, score in top_traits])}

**Ù…Ù‡Ù…ØªÙƒ:**
Ø§Ø®ØªØ±Ø¹ Ø±ÙŠØ§Ø¶Ø© ØªÙ„Ø§Ù…Ø³ Ù‡Ø°Ù‡ Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø¯ÙˆØ§ÙØ¹ Ø¨Ø¹Ù…Ù‚.
Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© "Ø£Ù†Øª" Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©.
Ø§Ø¬Ø¹Ù„Ù‡Ù… ÙŠØ´Ø¹Ø±ÙˆÙ† "Ù‡Ø°Ø§ Ø£Ù†Ø§ ØªÙ…Ø§Ù…Ø§Ù‹!".
"""
    else:
        context = f"""**Deep Personal Context:**

ğŸ§¬ Dominant Identity: {dominant_identity} ({identity_strength:.0%})

ğŸ”¥ Hidden Drivers (Layer Z):
{chr(10).join([f'â€¢ {driver}' for driver in hidden_drivers]) if hidden_drivers else 'â€¢ Seeking meaning'}

ğŸ§  Strongest Traits:
{chr(10).join([f'â€¢ {trait}: {score:.0%}' for trait, score in top_traits])}

**Your Mission:**
Invent a sport touching this identity and drivers deeply.
Use direct "you" language.
Make them feel "This is exactly ME!".
"""
    
    return context


def _fallback_recommendations(language: str) -> List[Dict]:
    """
    ØªÙˆØµÙŠØ§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    """
    if language == 'ar':
        return [
            {
                'sport_name': 'Ø±ÙŠØ§Ø¶Ø© Ù…Ø®ØµØµØ©',
                'what_is_it': ['ØªØ¬Ø±Ø¨Ø© ÙØ±ÙŠØ¯Ø© Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±'],
                'why_suits_you': ['ØªÙ… ØªØµÙ…ÙŠÙ…Ù‡Ø§ Ø®ØµÙŠØµØ§Ù‹ Ù„Ùƒ'],
                'how_it_looks': ['Ø³ØªÙƒØªØ´ÙÙ‡Ø§ Ù‚Ø±ÙŠØ¨Ø§Ù‹'],
                'important_notes': ['Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ ØªØ®ØµÙŠØµÙ‡Ø§'],
                'match_score': 75,
                'fallback': True
            }
        ]
    else:
        return [
            {
                'sport_name': 'Custom Sport',
                'what_is_it': ['Unique experience in development'],
                'why_suits_you': ['Designed specifically for you'],
                'how_it_looks': ['You will discover it soon'],
                'important_notes': ['Currently being customized'],
                'match_score': 75,
                'fallback': True
            }
        ]


__all__ = ['generate_complete_sport_recommendations']
