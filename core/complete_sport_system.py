# -*- coding: utf-8 -*-
"""
Complete Sport Invention Integration
=====================================
Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„:
- Layer Z (Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ø®ÙÙŠØ©)
- Facts Layer (Ø­Ù‚Ø§Ø¦Ù‚ Ø¹Ù„Ù…ÙŠØ©)
- 8000 Sports Database
- Dual-Model AI (Discovery + Reasoning)
- Advanced Sport Inventor
"""

from typing import Dict, List, Any, Optional
import json

# Import all components
try:
    from core.advanced_sport_inventor import get_advanced_inventor
    from core.dual_model_client import (
        analyze_user_with_discovery,
        _init_dual_models
    )
    from core.llm_client import chat_once, make_llm_client_singleton
    FULL_SYSTEM_AVAILABLE = True
except Exception as e:
    print(f"[INTEGRATION] Import error: {e}")
    FULL_SYSTEM_AVAILABLE = False


def generate_complete_sport_recommendations(
    user_answers: Dict[str, Any],
    user_traits: Dict[str, float],
    user_identity: Dict[str, float],
    language: str = 'ar',
    num_recommendations: int = 3
) -> List[Dict[str, Any]]:
    """
    ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    
    Ø§Ù„Ø®Ø·ÙˆØ§Øª:
    1. Discovery Model: ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹
    2. Layer Z: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ø®ÙÙŠØ©
    3. Facts Layer: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©
    4. Advanced Inventor: Ø§Ø®ØªØ±Ø§Ø¹/Ø¯Ù…Ø¬ Ø±ÙŠØ§Ø¶Ø§Øª
    5. Reasoning Model: ØµÙ‚Ù„ ÙˆØªØ­Ø³ÙŠÙ†
    6. Final Output: 3 Ø±ÙŠØ§Ø¶Ø§Øª Ù…Ø®ØªØ±Ø¹Ø©/Ù…Ø®ØµØµØ©
    
    Args:
        user_answers: Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        user_traits: Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© (141+ trait)
        user_identity: Ø§Ù„Ù‡ÙˆÙŠØ© (warrior, explorer, etc.)
        language: ar or en
        num_recommendations: Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª (default: 3)
    
    Returns:
        List of invented/personalized sports
    """
    
    if not FULL_SYSTEM_AVAILABLE:
        return _fallback_recommendations(language)
    
    print("[INTEGRATION] Starting complete invention process...")
    
    # Step 1: Discovery Analysis
    print("[INTEGRATION] Step 1/6: Discovery Model analysis...")
    discovery_analysis = analyze_user_with_discovery(
        answers=user_answers,
        identity=user_identity,
        traits=user_traits,
        lang=language
    )
    
    # Step 2: Advanced Inventor
    print("[INTEGRATION] Step 2/6: Advanced Sport Invention...")
    inventor = get_advanced_inventor()
    
    # Generate multiple inventions
    inventions = []
    for i in range(num_recommendations):
        try:
            invention = inventor.invent_sport(
                user_answers=user_answers,
                traits=user_traits,
                lang=language
            )
            
            if invention:
                # Add discovery insights
                invention['discovery_insights'] = discovery_analysis.get('initial_insights', {})
                invention['layer_z_drivers'] = discovery_analysis.get('hidden_drives', [])
                inventions.append(invention)
                
        except Exception as e:
            print(f"[INTEGRATION] Invention {i} failed: {e}")
    
    # Step 3: Reasoning Model Enhancement
    print("[INTEGRATION] Step 3/6: Reasoning Model enhancement...")
    if len(inventions) > 0:
        inventions = _enhance_with_reasoning(inventions, discovery_analysis, language)
    
    # Step 4: Add AI-generated descriptions
    print("[INTEGRATION] Step 4/6: AI descriptions...")
    inventions = _add_ai_descriptions(inventions, user_traits, language)
    
    # Step 5: Validate and score
    print("[INTEGRATION] Step 5/6: Validation...")
    inventions = _validate_and_score(inventions, user_traits)
    
    # Step 6: Sort and return top N
    print("[INTEGRATION] Step 6/6: Finalization...")
    inventions.sort(key=lambda x: x.get('match_score', 0), reverse=True)
    
    final_inventions = inventions[:num_recommendations]
    
    print(f"[INTEGRATION] âœ… Generated {len(final_inventions)} complete sport inventions")
    
    return final_inventions


def _enhance_with_reasoning(
    inventions: List[Dict],
    discovery_analysis: Dict,
    language: str
) -> List[Dict]:
    """
    ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Reasoning Model
    """
    try:
        _init_dual_models()
        client = make_llm_client_singleton()
        
        if not client:
            return inventions
        
        # Prepare reasoning prompt
        reasoning_data = {
            'inventions': [
                {
                    'label': inv.get('sport_label'),
                    'base': inv.get('base_sport'),
                    'components': inv.get('hybrid_components', [])
                }
                for inv in inventions
            ],
            'discovery_analysis': discovery_analysis,
            'language': language
        }
        
        if language == 'ar':
            system_prompt = """Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø±ÙŠØ§Ø¶ÙŠ Ù†ÙØ³ÙŠ Ø¹Ù…ÙŠÙ‚. Ù…Ù‡Ù…ØªÙƒ: ØªØ´Ø®ÙŠØµ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù…Ø®ÙÙŠØ© Ù„Ù„Ø´Ø®Øµ.

**Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©:**
- Ù„Ø§ ØªØµÙ Ø§Ù„Ø±ÙŠØ§Ø¶Ø© ÙÙ‚Ø· - Ø´Ø®Ù‘Øµ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø´Ø®Øµ ÙˆØ§Ù„Ø±ÙŠØ§Ø¶Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© "Ø£Ù†Øª" Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© - Ø§Ù„Ù…Ø³ Ø§Ù„Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©

**Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©:**

ğŸ¯ Ø§Ù„Ø±ÙŠØ§Ø¶Ø© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ùƒ: [Ø§Ø³Ù… Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©]

ğŸ’¡ Ù…Ø§ Ù‡ÙŠØŸ
â€¢ [3-4 Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ØªØµÙ Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙˆØ§Ù„Ø¥Ø­Ø³Ø§Ø³ - Ù„ÙŠØ³ Ø§Ù„ØªØ§Ø±ÙŠØ®]

ğŸ® Ù„ÙŠÙ‡ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ
â€¢ Ø£Ù†Øª [ØµÙØ© Ù†ÙØ³ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø©] - [Ø±Ø¨Ø· Ø¨Ø§Ù„Ø±ÙŠØ§Ø¶Ø©]
â€¢ [Ø¬Ù…Ù„Ø© Ø«Ø§Ù†ÙŠØ© ØªØ´Ø±Ø­ Ø§Ù„Ø¯Ø§ÙØ¹ Ø§Ù„Ø®ÙÙŠ]
â€¢ [Ø¬Ù…Ù„Ø© Ø«Ø§Ù„Ø«Ø© ØªØµÙ Ø§Ù„Ù…ØªØ¹Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¹Ù†Ø¯Ù‡Ù…]

ğŸ” Ø´ÙƒÙ„Ù‡Ø§ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ:
â€¢ ØªØ¯Ø®Ù„ [ÙˆØµÙ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©]
â€¢ ØªØ³ØªØ®Ø¯Ù… [ÙˆØµÙ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø­ÙŠØ©]
â€¢ [Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©] - "Ù„ÙƒÙ† Ø¯Ø§Ø®Ù„Ùƒ ØªØ¹Ø±Ù Ø¥Ù†Ùƒ ØªÙ†Ù…Ùˆ"

ğŸ‘ï¸â€ğŸ—¨ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:
â€¢ [Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ù‚ÙˆÙŠØ© ØªÙ„Ø§Ù…Ø³ Ø§Ù„Ù‡ÙˆÙŠØ©]
â€¢ [Ù†ØµÙŠØ­Ø© Ø¹Ù…Ù„ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡]

**Ù…Ø«Ø§Ù„ Ø­Ù‚ÙŠÙ‚ÙŠ:**
"Ø£Ù†Øª ØªÙƒØ±Ù‡ Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ ØªØ±ÙØ¶ Ø§Ù„Ø³Ø·Ø­ÙŠØ©ØŒ ÙˆØªØ­Ø¨ ØªÙˆØµÙ„ Ù„Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø´ÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ"

**Ø§Ù„Ø·ÙˆÙ„:** 120-180 ÙƒÙ„Ù…Ø© ÙÙ‚Ø·
**Ø§Ù„ØªØ±ÙƒÙŠØ²:** Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø´Ø¹ÙˆØ±ØŒ Ù„ÙŠØ³ Ø§Ù„ÙˆØµÙ Ø§Ù„ØªÙ‚Ù†ÙŠ

JSON format required.
"""
        else:
            system_prompt = """You are a deep sports psychologist. Your mission: Diagnose the hidden athletic identity.

**Golden Rule:**
- Don't just describe the sport - diagnose the relationship between person and sport
- Use direct "you" language - touch deep motivations

**Exact Structure:**

ğŸ¯ Your Perfect Sport: [English name]

ğŸ’¡ What is it?
â€¢ [3-4 short sentences describing EXPERIENCE and FEELING - not history]

ğŸ® Why it suits you?
â€¢ You [deep psychological trait] - [connection to sport]
â€¢ [Second sentence explaining hidden driver]
â€¢ [Third sentence describing their true pleasure]

ğŸ” What it looks like:
â€¢ You enter [describe start]
â€¢ You use [describe live experience]
â€¢ [Psychological result] - "but inside you know you're growing"

ğŸ‘ï¸â€ğŸ—¨ï¸ Important notes:
â€¢ [One powerful identity-touching sentence]
â€¢ [Practical advice to start]

**Real Example:**
"You hate repetition, reject superficiality, and love reaching the true essence of things"

**Length:** 120-180 words only
**Focus:** Identity and feeling, not technical description

JSON format required.
"""
        
        import os
        reasoning_model = os.getenv("CHAT_MODEL_REASONING", "gpt-4o")
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚
        user_context = _build_personal_context(discovery_analysis, language)
        
        enhanced_json = chat_once(
            client,
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_context + "\n\n" + json.dumps(reasoning_data, ensure_ascii=False)}
            ],
            model=reasoning_model,
            temperature=0.7,
            max_tokens=600  # REDUCED from 2000 for compact responses
        )
        
        # Parse and merge enhancements
        try:
            enhanced_data = json.loads(enhanced_json)
            enhanced_sports = enhanced_data.get('sports', [])
            
            for i, sport in enumerate(enhanced_sports):
                if i < len(inventions):
                    inventions[i]['enhanced_label'] = sport.get('enhanced_name', inventions[i].get('sport_label'))
                    inventions[i]['ai_description'] = sport.get('description', '')
                    inventions[i]['ai_reasons'] = sport.get('reasons', [])
        except:
            pass
        
    except Exception as e:
        print(f"[REASONING] Enhancement failed: {e}")
    
    return inventions


def _add_ai_descriptions(
    inventions: List[Dict],
    traits: Dict[str, float],
    language: str
) -> List[Dict]:
    """
    Ø¥Ø¶Ø§ÙØ© Ø£ÙˆØµØ§Ù AI Ù„Ù„Ø±ÙŠØ§Ø¶Ø§Øª
    """
    for invention in inventions:
        if 'ai_description' not in invention:
            # Generate basic description
            label = invention.get('sport_label', 'Ø±ÙŠØ§Ø¶Ø© Ù…Ø®ØµØµØ©')
            
            if language == 'ar':
                invention['ai_description'] = f"{label} - ØªØ¬Ø±Ø¨Ø© Ø±ÙŠØ§Ø¶ÙŠØ© ÙØ±ÙŠØ¯Ø© Ù…ØµÙ…Ù…Ø© Ø®ØµÙŠØµØ§Ù‹ Ù„Ùƒ"
            else:
                invention['ai_description'] = f"{label} - A unique athletic experience designed specifically for you"
    
    return inventions


def _validate_and_score(
    inventions: List[Dict],
    traits: Dict[str, float]
) -> List[Dict]:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡Ø§
    + Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¥ÙŠØ¬Ø§Ø² ÙˆØ§Ù„ÙˆØ¶ÙˆØ­
    """
    for invention in inventions:
        # Validate description length (max 60 words)
        desc = invention.get('ai_description', '')
        if desc:
            words = desc.split()
            if len(words) > 60:
                invention['ai_description'] = ' '.join(words[:60]) + '...'
        
        # Validate reasons (max 3 points, each max 12 words)
        reasons = invention.get('ai_reasons', [])
        if len(reasons) > 3:
            reasons = reasons[:3]
        reasons = [' '.join(r.split()[:12]) for r in reasons]
        invention['ai_reasons'] = reasons
        
        # Calculate match score
        match_score = 0.85  # Base score
        
        # Bonus for having all fields
        if all(k in invention for k in ['sport_label', 'ai_description', 'ai_reasons']):
            match_score += 0.10
        
        invention['match_score'] = min(match_score, 1.0)
    
    return inventions
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
    """
    for invention in inventions:
        # Ensure match_score exists
        if 'match_score' not in invention:
            invention['match_score'] = 85  # Default for invented sports
        
        # Validate required fields
        required_fields = ['sport_label']
        for field in required_fields:
            if field not in invention:
                invention[field] = 'Unknown Sport'
        
        # Add confidence score
        layer_z_confidence = invention.get('layer_z_drivers', [])
        if len(layer_z_confidence) >= 3:
            invention['confidence'] = 0.9
        else:
            invention['confidence'] = 0.7
    
    return inventions


def _fallback_recommendations(language: str) -> List[Dict]:
    """
    ØªÙˆØµÙŠØ§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
    """
    if language == 'ar':
        return [
            {
                'sport_label': 'Ø±ÙŠØ§Ø¶Ø© Ù…Ø®ØµØµØ© - Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1',
                'tagline': 'ØªØ¬Ø±Ø¨Ø© ÙØ±ÙŠØ¯Ø© Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±',
                'match_score': 75,
                'fallback': True
            }
        ]
    else:
        return [
            {
                'sport_label': 'Custom Sport - Phase 1',
                'tagline': 'Unique experience in development',
                'match_score': 75,
                'fallback': True
            }
        ]


def _build_personal_context(discovery_analysis: Dict, language: str) -> str:
    """
    Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
    """
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰
    identity_scores = discovery_analysis.get('identity_scores', {})
    dominant_identity = max(identity_scores.items(), key=lambda x: x[1])[0] if identity_scores else 'explorer'
    identity_strength = max(identity_scores.values()) if identity_scores else 0.5
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ø®ÙÙŠØ©
    hidden_drivers = discovery_analysis.get('hidden_drives', [])[:3]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰
    traits = discovery_analysis.get('traits_summary', {})
    top_traits = sorted(traits.items(), key=lambda x: x[1], reverse=True)[:3]
    
    if language == 'ar':
        context = f"""
**Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚:**

ğŸ§¬ **Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰:** {dominant_identity} ({identity_strength:.0%})
- Ù‡Ø°Ø§ Ø§Ù„Ø´Ø®Øµ ÙŠÙ…ÙŠÙ„ Ø¨Ù‚ÙˆØ© Ù†Ø­Ùˆ Ø§Ù„Ù‡ÙˆÙŠØ©: {dominant_identity}

ğŸ”¥ **Ø§Ù„Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ø®ÙÙŠØ© (Layer Z):**
{chr(10).join([f'â€¢ {driver}' for driver in hidden_drivers])}

ğŸ§  **Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ø£Ù‚ÙˆÙ‰:**
{chr(10).join([f'â€¢ {trait}: {score:.0%}' for trait, score in top_traits])}

**Ù…Ù‡Ù…ØªÙƒ:**
Ø§Ø®ØªØ±Ø¹/Ø§Ø®ØªØ± Ø±ÙŠØ§Ø¶Ø© ØªÙ„Ø§Ù…Ø³ Ù‡Ø°Ù‡ Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø¯ÙˆØ§ÙØ¹ Ø¨Ø¹Ù…Ù‚.
Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© "Ø£Ù†Øª" Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©.
Ø§Ø¬Ø¹Ù„Ù‡Ù… ÙŠØ´Ø¹Ø±ÙˆÙ† "Ù‡Ø°Ø§ Ø£Ù†Ø§ ØªÙ…Ø§Ù…Ø§Ù‹!".
"""
    else:
        context = f"""
**Deep Personal Context:**

ğŸ§¬ **Dominant Identity:** {dominant_identity} ({identity_strength:.0%})
- This person strongly leans toward identity: {dominant_identity}

ğŸ”¥ **Hidden Drivers (Layer Z):**
{chr(10).join([f'â€¢ {driver}' for driver in hidden_drivers])}

ğŸ§  **Strongest Psychological Traits:**
{chr(10).join([f'â€¢ {trait}: {score:.0%}' for trait, score in top_traits])}

**Your Mission:**
Invent/choose a sport touching this identity and drivers deeply.
Use direct "you" language.
Make them feel "This is exactly ME!".
"""
    
    return context


__all__ = ['generate_complete_sport_recommendations']
