#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Core - Triple Intelligence System (OpenAI 1.x Compatible)
===========================================================
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from openai import OpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SportSyncAI:
    """Triple Intelligence System"""
    
    def __init__(self):
        """Initialize OpenAI client"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found!")
        
        self.client = OpenAI(api_key=api_key)
        
        self.models = {
            'fast': 'gpt-3.5-turbo',
            'reasoning': 'gpt-4o',  # Changed from o1-mini
            'intelligence': 'gpt-4o'
        }
        
        logger.info("âœ… AI System Ready")
    
    def call_ai(self, messages: List[Dict], model: str, temp: float = 0.7, max_tokens: int = 1500) -> Optional[str]:
        """Call OpenAI API"""
        try:
            logger.info(f"ðŸ”„ Calling {model}...")
            
            # o1 models use different parameter names
            if model.startswith('o1'):
                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_completion_tokens=max_tokens
                )
            else:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temp,
                    max_tokens=max_tokens
                )
            
            content = response.choices[0].message.content
            logger.info(f"âœ… {model} responded")
            return content
            
        except Exception as e:
            logger.error(f"âŒ {model} failed: {e}")
            return None
    
    def analyze_fast(self, user_input: str, lang: str = "ar") -> Optional[str]:
        """Layer 1: Fast analysis"""
        logger.info("ðŸš€ LAYER 1: Fast Analysis")
        
        prompt = f"""Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† ÙˆØµÙ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:

{user_input}

Ø£Ø¹Ø· JSON ÙÙ‚Ø·:
{{
  "emotional_state": "ÙˆØµÙ Ù‚ØµÙŠØ±",
  "constraints": ["Ù‚ÙŠØ¯1", "Ù‚ÙŠØ¯2"],
  "goals": ["Ù‡Ø¯Ù1", "Ù‡Ø¯Ù2"]
}}""" if lang == "ar" else f"""Extract key information:

{user_input}

Return JSON:
{{
  "emotional_state": "brief",
  "constraints": ["c1", "c2"],
  "goals": ["g1", "g2"]
}}"""
        
        messages = [{"role": "user", "content": prompt}]
        return self.call_ai(messages, self.models['fast'], temp=0.3, max_tokens=300)
    
    def analyze_deep(self, quick_insights: str, user_input: str, lang: str = "ar") -> Optional[str]:
        """Layer 2: Deep reasoning"""
        logger.info("ðŸ§  LAYER 2: Deep Reasoning")
        
        prompt = f"""Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹: {quick_insights}

Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚:
1. Ø§Ù„Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ø®ÙÙŠØ©
2. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø§Ù‡Ø²ÙŠØ©
3. Ø§Ù„Ø­ÙˆØ§Ø¬Ø²
4. Ù†ÙˆØ¹ Ø§Ù„Ø´Ø®ØµÙŠØ©

Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„.""" if lang == "ar" else f"""Quick insights: {quick_insights}

Deep analysis:
1. Hidden motivations
2. Readiness
3. Barriers
4. Personality type

Write comprehensive analysis."""
        
        messages = [{"role": "user", "content": prompt}]
        return self.call_ai(messages, self.models['reasoning'], temp=1.0, max_tokens=2000)
    
    def generate_recommendations(self, quick: str, deep: str, lang: str = "ar") -> Optional[str]:
        """Layer 3: Final recommendations"""
        logger.info("ðŸŽ¯ LAYER 3: Recommendations")
        
        system = f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø±ÙŠØ§Ø¶ÙŠ ÙÙŠ SportSync.

Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª:
- Ø§Ù„Ø³Ø±ÙŠØ¹: {quick}
- Ø§Ù„Ø¹Ù…ÙŠÙ‚: {deep}

Ø£Ù†Ø´Ø¦ 3 ØªÙˆØµÙŠØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ© JSON:
{{
  "recommendations": [
    {{
      "title": "Ø§Ø³Ù… Ø§Ù„Ø±ÙŠØ§Ø¶Ø©",
      "essence": "Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©",
      "experience": "ÙÙ‚Ø±Ø© Ø¹Ù† Ø§Ù„ØªØ¬Ø±Ø¨Ø©",
      "why_perfect": ["Ø³Ø¨Ø¨1", "Ø³Ø¨Ø¨2", "Ø³Ø¨Ø¨3"],
      "first_week": "Ø®Ø·Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø£ÙˆÙ„",
      "signs_of_progress": ["Ø¹Ù„Ø§Ù…Ø©1", "Ø¹Ù„Ø§Ù…Ø©2"]
    }}
  ]
}}

Ù…Ù…Ù†ÙˆØ¹: Ø£ÙˆÙ‚Ø§ØªØŒ ØªÙƒØ§Ù„ÙŠÙØŒ Ø£Ù…Ø§ÙƒÙ†ØŒ Ù…Ø¹Ø¯Ø§Øª.""" if lang == "ar" else f"""You are a sport consultant.

Analysis:
- Quick: {quick}
- Deep: {deep}

Create 3 personalized sport recommendations in JSON.

Forbidden: times, costs, locations, equipment."""
        
        messages = [
            {"role": "system", "content": system},
            {"role": "user", "content": "Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª" if lang == "ar" else "Give recommendations"}
        ]
        
        return self.call_ai(messages, self.models['intelligence'], temp=0.7, max_tokens=2500)
    
    def run_pipeline(self, user_input: str, lang: str = "ar") -> Dict[str, Any]:
        """Run full pipeline"""
        logger.info("=" * 60)
        logger.info("ðŸš€ STARTING PIPELINE")
        logger.info("=" * 60)
        
        result = {
            "success": False,
            "recommendations": None,
            "error": None
        }
        
        # Layer 1
        fast = self.analyze_fast(user_input, lang)
        if not fast:
            result["error"] = "Layer 1 failed"
            return result
        
        # Layer 2
        deep = self.analyze_deep(fast, user_input, lang)
        if not deep:
            result["error"] = "Layer 2 failed"
            return result
        
        # Layer 3
        recs = self.generate_recommendations(fast, deep, lang)
        if not recs:
            result["error"] = "Layer 3 failed"
            return result
        
        result["success"] = True
        result["recommendations"] = recs
        
        logger.info("âœ… PIPELINE COMPLETE!")
        return result


# Global instance
_ai = None

def get_ai() -> SportSyncAI:
    global _ai
    if _ai is None:
        _ai = SportSyncAI()
    return _ai

def generate_sport_recommendations(user_input: str, lang: str = "ar") -> Dict[str, Any]:
    ai = get_ai()
    return ai.run_pipeline(user_input, lang)


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    test = "Ø£Ø¨Ø­Ø« Ø¹Ù† Ø±ÙŠØ§Ø¶Ø© Ù‡Ø§Ø¯Ø¦Ø© ØªØ³Ø§Ø¹Ø¯Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ÙƒÙŠØ²"
    result = generate_sport_recommendations(test, "ar")
    print(json.dumps(result, ensure_ascii=False, indent=2))
