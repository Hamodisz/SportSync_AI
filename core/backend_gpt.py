# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
Sport identity recommendations (3 cards) with Layer-Z, first-week (qualitative),
and VR/no-VR variants. Arabic/English.

Order of operation (ÙˆØ§Ù‚Ø¹ÙŠ Ø£ÙˆÙ„Ø§Ù‹):
1) Evidence Gate (ÙŠØ±ÙØ¶ Ø¥Ù† ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ÙˆÙŠØ¹ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø©)
2) ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù‚Ø¹ÙŠ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:
   - priors + trait_links + guards (Ù…Ù† data/sportsync_knowledge.json)
   - Ù‚ÙˆØ§Ù„Ø¨ Ø¬Ø§Ù‡Ø²Ø© Ù„ÙƒÙ„ label Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¨Ø·Ø§Ù‚Ø§Øª Ù…ÙƒØªÙ…Ù„Ø© Ø¨Ø¯ÙˆÙ† LLM
3) LLM ÙƒØ¢Ø®Ø± Ø®ÙŠØ§Ø± (fallback) Ø¥Ù† Ù…Ø§ ÙƒÙØª Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
4) Hard de-dup + URL scrub + Telemetry

Ù‚ÙˆØ§Ø¹Ø¯ Ø«Ø§Ø¨ØªØ©:
- Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ± Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±.
- ÙŠÙØ³Ù…Ø­ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø§Øª Ø¥Ø°Ø§ ALLOW_SPORT_NAMES=True
- dedupe Ù…Ø­Ù„ÙŠ ÙˆØ¹Ø§Ù„Ù…ÙŠ Ø¹Ø¨Ø± data/blacklist.json
"""

from __future__ import annotations

import os, json, re, hashlib, importlib
from time import perf_counter, sleep
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
from datetime import datetime

## ========= OpenAI =========
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø£Ø¶Ù Ø§Ù„Ø­Ø²Ù…Ø© ÙÙŠ requirements: openai>=1.6.1,<2") from e

# Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ø­ØªÙ…Ø§Ù„ (OpenAI / OpenRouter / Azure)
OPENAI_API_KEY = (
    os.getenv("OPENAI_API_KEY")
    or os.getenv("OPENROUTER_API_KEY")
    or os.getenv("AZURE_OPENAI_API_KEY")
)

# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù€ Base URL (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù…Ø¹ OpenRouter/Azure)
OPENAI_BASE_URL = (
    os.getenv("OPENAI_BASE_URL")
    or os.getenv("OPENROUTER_BASE_URL")
    or os.getenv("AZURE_OPENAI_ENDPOINT")
)

OPENAI_ORG = os.getenv("OPENAI_ORG")  # ØºØ§Ù„Ø¨Ø§Ù‹ ÙØ§Ø¶ÙŠ

OpenAI_CLIENT = None
if OPENAI_API_KEY:
    try:
        kwargs = {"api_key": OPENAI_API_KEY}
        if OPENAI_BASE_URL:
            kwargs["base_url"] = OPENAI_BASE_URL
        if OPENAI_ORG:
            kwargs["organization"] = OPENAI_ORG
        OpenAI_CLIENT = OpenAI(**kwargs)
    except Exception as e:
        print(f"[ENV] âš ï¸ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙŠÙ„ OpenAI: {e}")
        OpenAI_CLIENT = None
else:
    print("[ENV] âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ API key ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©.")

# Ø·Ø¨Ø§Ø¹Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¥Ù‚Ù„Ø§Ø¹ Ù„Ù„ØªØ´Ø®ÙŠØµ
print(
    f"[BOOT] LLM READY? {'YES' if OpenAI_CLIENT else 'NO'} | "
    f"base={OPENAI_BASE_URL or 'default'} | "
    f"model={os.getenv('CHAT_MODEL','gpt-4o-mini')}"
)
# ========= App Config =========
try:
    from core.app_config import get_config
    CFG = get_config()
except Exception:
    CFG = {}

CHAT_MODEL = (CFG.get("llm") or {}).get("model", os.getenv("CHAT_MODEL", "gpt-4o"))
ALLOW_SPORT_NAMES = (CFG.get("recommendations") or {}).get("allow_sport_names", True)

REC_RULES = CFG.get("recommendations") or {}
_MIN_CHARS = int(REC_RULES.get("min_chars", 220))
_REQUIRE_WIN = bool(REC_RULES.get("require_win_condition", True))
_MIN_CORE_SKILLS = int(REC_RULES.get("min_core_skills", 3))

# Evidence Gate thresholds (defaults if not provided)
EGCFG = (CFG.get("analysis") or {}).get("egate", {}) if isinstance(CFG.get("analysis"), dict) else {}
_EG_MIN_ANSWERS = int(EGCFG.get("min_answered", 3))
_EG_MIN_TOTAL_CHARS = int(EGCFG.get("min_total_chars", 120))
_EG_REQUIRED_KEYS = list(EGCFG.get("required_keys", []))  # Ù…Ø«Ø§Ù„: ["goal","injury_history"]

# ========= Project imports (with safe fallbacks) =========
try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: {list(content.keys())}")

# DataPipe (Zapier/Webhook/Disk)
try:
    from core.data_pipe import get_pipe
    _PIPE = get_pipe()
except Exception:
    _PIPE = None

# Security scrubber
try:
    from core.security import scrub_unknown_urls
except Exception:
    def scrub_unknown_urls(text_or_card: str, cfg: Dict[str, Any]) -> str:
        return text_or_card

# Evidence Gate (external) + fallback Ø¯Ø§Ø®Ù„ÙŠ
try:
    from core.evidence_gate import evaluate as egate_evaluate
except Exception:
    egate_evaluate = None  # Ø³Ù†Ø³ØªØ®Ø¯Ù… fallback Ø£Ø¯Ù†Ø§Ù‡

# ========= Helpers: Arabic normalization =========
_AR_DIAC = r"[ÙÙ‹ÙÙŒÙÙÙ’Ù‘Ù€]"
def _normalize_ar(t: str) -> str:
    if not t: return ""
    t = re.sub(_AR_DIAC, "", t)
    t = t.replace("Ø£","Ø§").replace("Ø¥","Ø§").replace("Ø¢","Ø§")
    t = t.replace("Ø¤","Ùˆ").replace("Ø¦","ÙŠ")
    t = t.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    t = re.sub(r"\s+", " ", t).strip()
    return t

# ========= Text normalizer (robust for list/dict inputs) =========
def _norm_text(val: Any) -> str:
    """Ø­ÙˆÙ‘Ù„ Ø£ÙŠ Ù†ÙˆØ¹ (list/dict/None/tuple/number) Ø¥Ù„Ù‰ Ù†Øµ Ù†Ø¸ÙŠÙ."""
    if val is None:
        return ""
    if isinstance(val, str):
        return val
    if isinstance(val, (list, tuple)):
        flat: List[str] = []
        for x in val:
            if isinstance(x, (list, tuple)):
                flat.extend(map(str, x))
            else:
                flat.append(str(x))
        return "ØŒ ".join([s.strip() for s in flat if s and str(s).strip()])
    if isinstance(val, dict):
        # Ø¬Ø±Ù‘Ø¨ Ù…ÙØ§ØªÙŠØ­ Ø´Ø§Ø¦Ø¹Ø©
        for k in ("text", "desc", "value", "answer"):
            if k in val and isinstance(val[k], str):
                return val[k]
        return json.dumps(val, ensure_ascii=False)
    return str(val)

# ========= Soft persona cache =========
try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

# âœ… Recommendations cache (optional external import + safe fallback)
try:
    from core.memory_cache import get_cached_recommendation, save_cached_recommendation  # type: ignore
except Exception:
    _REC_CACHE: Dict[str, List[str]] = {}
    def _answers_fingerprint(answers: Dict[str, Any], lang: str) -> str:
        try:
            blob = json.dumps(answers or {}, ensure_ascii=False, sort_keys=True)
        except Exception:
            blob = str(answers)
        h = hashlib.sha256((lang + "::" + blob).encode("utf-8")).hexdigest()[:24]
        return h
    def get_cached_recommendation(user_id: str, answers: Dict[str, Any], lang: str) -> Optional[List[str]]:
        key = f"{user_id}:{_answers_fingerprint(answers, lang)}"
        return _REC_CACHE.get(key)
    def save_cached_recommendation(user_id: str, answers: Dict[str, Any], lang: str, cards: List[str]) -> None:
        key = f"{user_id}:{_answers_fingerprint(answers, lang)}"
        _REC_CACHE[key] = list(cards or [])

# ========= Paths / Data =========
try:
    HERE = Path(__file__).resolve().parent
except NameError:
    HERE = Path.cwd()
ROOT = HERE.parent if HERE.name == "core" else HERE
DATA_DIR = (ROOT / "data").resolve()
DATA_DIR.mkdir(parents=True, exist_ok=True)

BL_PATH = DATA_DIR / "blacklist.json"
KB_PATH = DATA_DIR / "sportsync_knowledge.json"
AL_PATH = DATA_DIR / "labels_aliases.json"

# ========= Helpers: Files =========
def _load_json_safe(p: Path) -> dict:
    try:
        with p.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def _save_json_atomic(p: Path, payload: dict) -> None:
    tmp = p.with_suffix(".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    tmp.replace(p)

# ========= Load KB / Aliases / Guards =========
KB = _load_json_safe(KB_PATH)
_ALIAS_MAP: Dict[str, str] = {}
if isinstance(KB.get("label_aliases"), dict):
    for canon, alist in KB["label_aliases"].items():
        for a in alist:
            _ALIAS_MAP[_normalize_ar(a).lower()] = canon  # ØªØ·Ø¨ÙŠØ¹ Ø¹Ø±Ø¨ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸

AL2 = _load_json_safe(AL_PATH)
if isinstance(AL2.get("canonical"), dict):
    for a, canon in AL2["canonical"].items():
        _ALIAS_MAP[_normalize_ar(a).lower()] = canon  # ØªØ·Ø¨ÙŠØ¹ Ø¹Ø±Ø¨ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸

# New KB knobs (priors & links & guards & z-intent keywords)
KB_PRIORS: Dict[str, float] = dict(KB.get("priors") or {})
TRAIT_LINKS: Dict[str, Dict[str, float]] = dict(KB.get("trait_links") or {})
GUARDS: Dict[str, Any] = dict(KB.get("guards") or {})
HIGH_RISK_SPORTS: set = set(GUARDS.get("high_risk_sports", []) or [])
KB_ZI: Dict[str, Dict[str, List[str]]] = dict(KB.get("z_intent_keywords") or {})

_FORBIDDEN_GENERIC = set(
    KB.get("guards", {}).get("forbidden_generic_labels", [])
) | set(AL2.get("forbidden_generic", []) or [])

# ========= Analysis import (user traits) =========
def _call_analyze_user_from_answers(user_id: str, answers: Dict[str, Any], lang: str) -> Dict[str, Any]:
    try:
        from analysis.user_analysis import analyze_user_from_answers as _ana
        try:
            out = _ana(user_id=user_id, answers=answers, lang=lang)
        except TypeError:
            out = _ana(answers)
        return {"traits": out} if isinstance(out, list) else (out or {})
    except Exception:
        try:
            from core.user_analysis import analyze_user_from_answers as _ana2
            try:
                out = _ana2(user_id=user_id, answers=answers, lang=lang)
            except TypeError:
                out = _ana2(answers)
            return {"traits": out} if isinstance(out, list) else (out or {})
        except Exception:
            return {"quick_profile": "fallback", "raw_answers": answers}

# ========= Layer Z (silent drivers) =========
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
            return ["Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±", "ØªÙØ¶ÙŠÙ„ ØªØ­Ø¯Ù‘ÙŠ Ø°Ù‡Ù†ÙŠ"]

# ========= Simple keyword signals from answers =========
def _lang_key(lang: str) -> str:
    return "ar" if (lang or "").startswith("Ø§Ù„Ø¹") else "en"

def _extract_signals(answers: Dict[str, Any], lang: str) -> Dict[str, int]:
    """
    ÙŠØ³ØªØ®Ø±Ø¬ Ø¥Ø´Ø§Ø±Ø§Øª Ù†ØµÙ‘ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù…Ù† Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (solo/team/vr/precision/stealth/â€¦)
    Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… z_intent_keywords Ø¥Ù† ØªÙˆÙÙ‘Ø±Øª.
    """
    blob = " ".join(
        (v.get("answer") if isinstance(v, dict) and "answer" in v else str(v))
        for v in (answers or {}).values()
    )
    blob_l = blob.lower()
    blob_n = _normalize_ar(blob_l)
    res: Dict[str, int] = {}
    zi = KB_ZI.get(_lang_key(lang), {})
    def any_kw(keys: List[str]) -> bool:
        return any((k.lower() in blob_l) or (_normalize_ar(k).lower() in blob_n) for k in keys)
    # Ø¥Ø´Ø§Ø±Ø§Øª Ø¹Ø§Ù…Ø©
    if any_kw(zi.get("VR", ["vr","virtual reality","headset","ÙˆØ§Ù‚Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ","Ù†Ø¸Ø§Ø±Ù‡"])): res["vr"] = 1
    if any_kw(zi.get("Ø¯Ù‚Ø©/ØªØµÙˆÙŠØ¨", []) + zi.get("Precision", []) + ["precision","aim","Ù†Ø´Ø§Ù†","Ø¯Ù‚Ù‡"]): res["precision"] = 1
    if any_kw(zi.get("ØªØ®ÙÙ‘ÙŠ", []) + zi.get("Stealth", []) + ["stealth","Ø¸Ù„","ØªØ®ÙÙŠ"]): res["stealth"] = 1
    if any_kw(zi.get("Ù‚ØªØ§Ù„ÙŠ", []) + zi.get("Combat", []) + ["Ù‚ØªØ§Ù„","Ù…Ø¨Ø§Ø±Ø²Ù‡","Ø§Ø´ØªØ¨Ø§Ùƒ","combat"]): res["combat"] = 1
    if any_kw(zi.get("Ø£Ù„ØºØ§Ø²/Ø®Ø¯Ø§Ø¹", []) + zi.get("Puzzles/Feint", []) + ["puzzle","Ù„ØºØ²","Ø®Ø¯Ø¹Ù‡"]): res["puzzles"] = 1
    if any_kw(zi.get("ÙØ±Ø¯ÙŠ", []) + ["solo","ÙˆØ­ÙŠØ¯","Ù„ÙˆØ­Ø¯ÙŠ"]): res["solo_pref"] = 1
    if any_kw(zi.get("Ø¬Ù…Ø§Ø¹ÙŠ", []) + ["team","group","ÙØ±ÙŠÙ‚","Ø¬Ù…Ø§Ø¹ÙŠ"]): res["team_pref"] = 1
    if any_kw(zi.get("Ù‡Ø¯ÙˆØ¡/ØªÙ†ÙÙ‘Ø³", []) + zi.get("Calm/Breath", []) + ["breath","calm","Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙØ³"]): res["breath"] = 1; res["calm"] = 1
    if any_kw(zi.get("Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†", []) + zi.get("Adrenaline", []) + ["fast","rush","Ø§Ù†Ø¯ÙØ§Ø¹"]): res["high_agg"] = 1
    return res

# ========= Intent (Z-intent) =========
def _call_analyze_intent(answers: Dict[str, Any], lang: str="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
    for modpath in ("core.layer_z_engine", "analysis.layer_z_engine"):
        try:
            mod = importlib.import_module(modpath)
            if hasattr(mod, "analyze_user_intent"):
                return list(mod.analyze_user_intent(answers, lang=lang) or [])
        except Exception:
            pass
    # fallback: Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª
    intents = set()
    sig = _extract_signals(answers, lang)
    if sig.get("vr"): intents.add("VR")
    if sig.get("stealth"): intents.add("ØªØ®ÙÙ‘ÙŠ")
    if sig.get("puzzles"): intents.add("Ø£Ù„ØºØ§Ø²/Ø®Ø¯Ø§Ø¹")
    if sig.get("precision"): intents.add("Ø¯Ù‚Ø©/ØªØµÙˆÙŠØ¨")
    if sig.get("combat"): intents.add("Ù‚ØªØ§Ù„ÙŠ")
    if sig.get("solo_pref"): intents.add("ÙØ±Ø¯ÙŠ")
    if sig.get("team_pref"): intents.add("Ø¬Ù…Ø§Ø¹ÙŠ")
    if sig.get("breath"): intents.add("Ù‡Ø¯ÙˆØ¡/ØªÙ†ÙÙ‘Ø³")
    if sig.get("high_agg"): intents.add("Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†")
    return list(intents)

# ========= (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù…ÙØ´ÙÙ‘ÙØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª =========
def _extract_profile(answers: Dict[str, Any], lang: str) -> Optional[Dict[str, Any]]:
    prof = answers.get("profile") if isinstance(answers, dict) else None
    if isinstance(prof, dict):
        return prof
    encode_answers = None
    try:
        from core.answers_encoder import encode_answers as _enc
        encode_answers = _enc
    except Exception:
        try:
            from analysis.answers_encoder import encode_answers as _enc
            encode_answers = _enc
        except Exception:
            encode_answers = None
    if encode_answers is None:
        return None
    try:
        enc = encode_answers(answers, lang=lang)
        preferences = enc.get("prefs", enc.get("preferences", {}))
        z_markers = enc.get("z_markers", [])
        signals   = enc.get("signals", [])
        hints = " | ".join([*z_markers, *signals])[:1000]
        return {
            "scores": enc.get("scores", {}),
            "axes": enc.get("axes", {}),
            "preferences": preferences,
            "hints_for_prompt": hints,
            "vr_inclination": enc.get("vr_inclination", 0),
            "confidence": enc.get("confidence", 0.0),
            "signals": signals,
            "z_markers": z_markers
        }
    except Exception:
        return None

# ========= Evidence Gate (fallback) =========
def _norm_answer_value(v: Any) -> str:
    if v is None: return ""
    if isinstance(v, dict):
        if "answer" in v: return str(v.get("answer") or "")
        if "value" in v: return str(v.get("value") or "")
        return json.dumps(v, ensure_ascii=False)
    if isinstance(v, list):
        return ", ".join(map(str, v))
    return str(v)

def _egate_fallback(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, Any]:
    if not isinstance(answers, dict) or not answers:
        status = "fail"; total_chars = 0; answered = 0
    else:
        vals = [_norm_answer_value(v) for v in answers.values() if str(v).strip()]
        total_chars = sum(len(s.strip()) for s in vals)
        answered = sum(1 for s in vals if len(s.strip()) >= 3)
        if _EG_REQUIRED_KEYS:
            if any(not _norm_answer_value(answers.get(k, "")).strip() for k in _EG_REQUIRED_KEYS):
                status = "fail"
            else:
                status = "pass" if (answered >= _EG_MIN_ANSWERS and total_chars >= _EG_MIN_TOTAL_CHARS) else "borderline"
        else:
            if answered == 0 or total_chars < 40:
                status = "fail"
            elif answered < _EG_MIN_ANSWERS or total_chars < _EG_MIN_TOTAL_CHARS:
                status = "borderline"
            else:
                status = "pass"

    followups = (
        [
            "ØªÙØ¶Ù‘Ù„ Ø§Ù„Ù„Ø¹Ø¨: ÙØ±Ø¯ÙŠ Ø£Ù… Ø¬Ù…Ø§Ø¹ÙŠØŸ ÙˆÙ„Ù…Ø§Ø°Ø§ Ø¨Ø³Ø·Ø± ÙˆØ§Ø­Ø¯.",
            "ØªÙ…ÙŠÙ„ Ù„Ù‡Ø¯ÙˆØ¡ ÙˆØ§Ù†Ø³ÙŠØ§Ø¨ Ø£Ù… Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ† ÙˆÙ‚Ø±Ø§Ø±Ø§Øª Ø®Ø§Ø·ÙØ©ØŸ",
            "ØªØ­Ø¨ Ø¯Ù‚Ù‘Ø©/ØªØµÙˆÙŠØ¨ Ø£Ù… Ø£Ù„ØºØ§Ø²/Ø®Ø¯Ø§Ø¹ Ø¨ØµØ±ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©ØŸ"
        ] if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else [
            "Do you prefer solo or team play â€” and why, in one short line?",
            "Do you want calm/flow or adrenaline/snap decisions?",
            "Are you more into precision/aim or puzzles/visual feints in motion?"
        ]
    )
    return {
        "status": "fail" if answered == 0 or total_chars < 40 else status,
        "answered": int(answered),
        "total_chars": int(total_chars),
        "required_missing": [k for k in _EG_REQUIRED_KEYS if not _norm_answer_value((answers or {}).get(k, "")).strip()],
        "followup_questions": followups[:3]
    }

def _run_egate(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, Any]:
    if callable(egate_evaluate):
        try:
            res = egate_evaluate(answers=answers, lang=lang, cfg=EGCFG)
            if isinstance(res, dict) and "status" in res:
                return res
        except Exception:
            pass
    return _egate_fallback(answers, lang=lang)

def _format_followup_card(followups: List[str], lang: str) -> str:
    head = "ğŸ§­ Ù†Ø­ØªØ§Ø¬ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù‚ØµÙŠØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªÙˆØµÙŠØ©" if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "ğŸ§­ I need a few quick answers first"
    tips = "Ø§ÙƒØªØ¨ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„." if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "One short line per question."
    lines = [head, "", tips, ""]
    for q in followups:
        lines.append(f"- {q}")
    lines.append("")
    lines.append("Ø£Ø±Ø³Ù„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ ÙˆØ³Ù†Ù‚ØªØ±Ø­ Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙÙˆØ±Ù‹Ø§." if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                 else "Send your answers and Iâ€™ll propose a clear sport-identity right away.")
    return "\n".join(lines)

# ========= Rules & helpers =========
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_AVOID_GENERIC = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]
_SENSORY = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªØ±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

_GENERIC_LABELS = {
    "impressive compact", "impressive-compact", "generic sport", "sport identity",
    "movement flow", "basic flow", "simple flow", "body flow"
}

_FORBIDDEN_SENT = re.compile(
    r"(\b\d+(\.\d+)?\s*(?:min|mins|minute|minutes|second|seconds|hour|hours|Ø¯Ù‚ÙŠÙ‚Ø©|Ø¯Ù‚Ø§Ø¦Ù‚|Ø«Ø§Ù†ÙŠØ©|Ø«ÙˆØ§Ù†ÙŠ|Ø³Ø§Ø¹Ø©|Ø³Ø§Ø¹Ø§Øª)\b|"
    r"(?:rep|reps|set|sets|ØªÙƒØ±Ø§Ø±|Ø¹Ø¯Ø©|Ø¹Ø¯Ø§Øª|Ø¬ÙˆÙ„Ø©|Ø¬ÙˆÙ„Ø§Øª|Ã—)|"
    r"(?:ØªÙƒÙ„ÙØ©|Ù…ÙŠØ²Ø§Ù†ÙŠØ©|cost|budget|Ø±ÙŠØ§Ù„|Ø¯ÙˆÙ„Ø§Ø±|\$|â‚¬)|"
    r"(?:Ø¨Ø§Ù„Ø¨ÙŠØª|ÙÙŠ\s*Ø§Ù„Ø¨ÙŠØª|Ù‚Ø±Ø¨\s*Ø§Ù„Ù…Ù†Ø²Ù„|Ø¨Ø§Ù„Ù…Ù†Ø²Ù„|ÙÙŠ\s*Ø§Ù„Ù†Ø§Ø¯ÙŠ|ÙÙŠ\s*Ø§Ù„Ø¬ÙŠÙ…|ØµØ§Ù„Ø©|Ù†Ø§Ø¯ÙŠ|Ø¬ÙŠÙ…|ØºØ±ÙØ©|Ø³Ø§Ø­Ø©|Ù…Ù„Ø¹Ø¨|Ø­Ø¯ÙŠÙ‚Ø©|Ø´Ø§Ø·Ø¦|"
    r"Ø·Ø¨ÙŠØ¹Ø©|Ø®Ø§Ø±Ø¬ÙŠ(?:Ø©)?|Ø¯Ø§Ø®Ù„(?:ÙŠ|ÙŠØ©)?|outdoor|indoor|park|beach|gym|studio))",
    re.IGNORECASE
)

def _contains_blocked_name(t: str) -> bool:
    if not t: return False
    return bool(_name_re.search(t)) or bool(_name_re.search(_normalize_ar(t)))

def _mask_names(t: str) -> str:
    if ALLOW_SPORT_NAMES:
        return t or ""
    s = t or ""
    s = _name_re.sub("â€”", s)
    if s == (t or "") and _contains_blocked_name(t):
        s = "â€”"
    return s

def _split_sentences(text: str) -> List[str]:
    if not text: return []
    return [s.strip() for s in re.split(r"(?<=[\.\!\?ØŸ])\s+|[\nØŒ]+", text) if s.strip()]

def _scrub_forbidden(text: str) -> str:
    kept = [s for s in _split_sentences(text) if not _FORBIDDEN_SENT.search(_normalize_ar(s))]
    return "ØŒ ".join(kept).strip(" .ØŒ")

def _clip(s: str, n: int) -> str:
    if not s: return ""
    s = s.strip()
    return s if len(s) <= n else (s[: max(0, n - 1)] + "â€¦")

def _to_bullets(text_or_list: Any, max_items: int = 6) -> List[str]:
    """
    ÙŠØ±Ø¬Ù‘Ø¹ Ø¯Ø§Ø¦Ù…Ù‹Ø§ List[str] Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (string/list/tuple/dict/nested).
    """
    out: List[str] = []

    def _flat_add(x: Any) -> None:
        if x is None:
            return
        # Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…/Ø§Ù„ØªØ¹Ø´ÙŠØ´ Ø¥Ù„Ù‰ Ù†ØµÙˆØµ
        if isinstance(x, (list, tuple, set)):
            for y in x:
                _flat_add(y)
            return
        if isinstance(x, dict):
            # Ø®Ø° Ø£Ø´Ù‡Ø± Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ØŒ ÙˆÙ„Ùˆ Ù…Ø§ Ù„Ù‚ÙŠØªÙ‡Ø§ Ø­ÙˆÙ‘Ù„ Ø§Ù„Ø¯ÙƒØª Ù„Ù†Øµ
            for k in ("text", "desc", "value", "answer", "label", "title"):
                if k in x and isinstance(x[k], str) and x[k].strip():
                    out.append(x[k].strip())
                    return
            out.append(json.dumps(x, ensure_ascii=False))
            return
        # Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø± Ø­ÙˆÙ‘Ù„Ù‡ Ù„Ù†Øµ ÙˆÙ†Ø¸Ù‘ÙÙ‡
        s = _norm_text(x).strip()
        if s:
            out.append(s)

    _flat_add(text_or_list)

    # Ù„Ùˆ ÙƒØ§Ù† Ø£ØµÙ„Ø§Ù‹ string ÙˆÙÙŠÙ‡ ÙÙˆØ§ØµÙ„/Ø³Ø·ÙˆØ±ØŒ Ø¬Ø²Ù‘Ø¦Ù‡ Ù„Ø¨Ù†ÙˆØ¯
    if len(out) == 1 and isinstance(text_or_list, str):
        raw = re.split(r"[;\n\.ØŒ]+", out[0])
        out = [i.strip(" -â€¢\t ") for i in raw if i.strip()]

    # Ù‚ØµÙ‘ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯
    out = out[:max_items]
    # ØªØ£ÙƒØ¯ ÙƒÙ„Ù‡Ø§ Ù†ØµÙˆØµ 100%
    out = [str(i) for i in out if str(i).strip()]
    return out

# ========= Alignment with Z-axes =========
_AR_TOK = {
    "calm": ["Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙÙ‘Ø³","Ø¨Ø·ÙŠØ¡","Ø§Ø³ØªØ±Ø®Ø§Ø¡","ØµÙØ§Ø¡","Ø³ÙƒÙˆÙ†"],
    "adren": ["Ø§Ù†Ø¯ÙØ§Ø¹","ÙƒÙ…ÙŠÙ†","Ø³Ø±ÙŠØ¹","Ø§Ù†Ù‚Ø¶Ø§Ø¶","Ø¥Ø«Ø§Ø±Ø©","Ù‚Ø±Ø§Ø± Ø®Ø§Ø·Ù"],
    "solo": ["ÙØ±Ø¯ÙŠ","Ù„ÙˆØ­Ø¯Ùƒ","Ø°Ø§ØªÙŠØ©"],
    "group": ["Ø¬Ù…Ø§Ø¹Ø©","Ø´Ø±ÙŠÙƒ","ÙØ±ÙŠÙ‚","ØªØ¹Ø§ÙˆÙ†"],
    "tech": ["ØªÙ‚Ù†ÙŠØ©","ØªÙØ§ØµÙŠÙ„","ØµÙ‚Ù„","Ø¯Ù‚Ø©","Ø¶Ø¨Ø·"],
    "intu": ["Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø³Ø§Ø³","Ø­Ø¯Ø³","ØªÙ„Ù‚Ø§Ø¦ÙŠØ©","ØªØ¯ÙÙ‘Ù‚"]
}
_EN_TOK = {
    "calm": ["calm","breath","slow","relax","settle"],
    "adren": ["burst","fast","risk","strike","adrenaline"],
    "solo": ["solo","alone","individual"],
    "group": ["team","partner","group","co-op"],
    "tech": ["technique","detail","precision","drill","refine"],
    "intu": ["by feel","intuitive","flow","improvise"]
}

def _axes_expectations(axes: Dict[str, float], lang: str) -> Dict[str, List[str]]:
    tok = _AR_TOK if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else _EN_TOK
    out: Dict[str, List[str]] = {}
    if not isinstance(axes, dict): return out
    ca = axes.get("calm_adrenaline")
    if isinstance(ca, (int, float)):
        out["calm_adrenaline"] = tok["adren"] if ca >= 0.5 else tok["calm"] if ca <= -0.5 else []
    sg = axes.get("solo_group")
    if isinstance(sg, (int, float)):
        out["solo_group"] = tok["group"] if sg >= 0.5 else tok["solo"] if sg <= -0.5 else []
    ti = axes.get("tech_intuition")
    if isinstance(ti, (int, float)):
        out["tech_intuition"] = tok["intu"] if ti >= 0.5 else tok["tech"] if ti <= -0.5 else []
    return out

def _mismatch_with_axes(rec: Dict[str, Any], axes: Dict[str, float], lang: str) -> bool:
    exp = _axes_expectations(axes or {}, lang)
    if not exp: return False
    blob = " ".join(_norm_text(rec.get(k,"")) for k in ("what_it_looks_like","inner_sensation","why_you","first_week"))
    blob_l = blob.lower()
    for _, words in exp.items():
        if words and not any(w.lower() in blob_l for w in words):
            return True
    return False

# ========= Label normalization / similarity =========
def _canonical_label(label: str) -> str:
    if not label: return ""
    lab = re.sub(r"\s+", " ", label).strip(" -â€”:ØŒ").lower()
    lab = _normalize_ar(lab)
    return lab

def _label_is_generic(label: str) -> bool:
    lab = _canonical_label(label)
    return (lab in _GENERIC_LABELS) or (len(lab) <= 3)

def _tokenize(text: str) -> List[str]:
    if not text: return []
    t = _normalize_ar(text.lower())
    toks = re.split(r"[^a-zA-Z0-9\u0600-\u06FF]+", t)
    return [w for w in toks if w and len(w) > 2]

def _sig_for_rec(r: Dict[str, Any]) -> set:
    core = r.get("core_skills") or []
    core_txt = " ".join(core) if isinstance(core, list) else str(core)
    toks = set(_tokenize(r.get("sport_label","")) + _tokenize(core_txt))
    return toks

def _jaccard(a: set, b: set) -> float:
    if not a and not b: return 1.0
    inter = len(a & b)
    union = len(a | b) or 1
    return inter / union

# ========= Sanitizers / Fallbacks =========
def _sanitize_record(r: Dict[str, Any]) -> Dict[str, Any]:
    r = dict(r or {})
    r.pop("practical_fit", None)

    # Ø·Ø¨Ù‘Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© (Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª list/dict)
    for k in ("sport_label","scene","what_it_looks_like","inner_sensation","why_you",
              "first_week","progress_markers","win_condition","variant_vr","variant_no_vr","vr_idea","mode"):
        if k in r:
            r[k] = _scrub_forbidden(_mask_names(_norm_text(r.get(k))))

    # core_skills â†’ Ù‚Ø§Ø¦Ù…Ø© Ù†ØµÙˆØµ Ù†Ø¸ÙŠÙØ© (Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 6)
    cs = r.get("core_skills")
    if isinstance(cs, str):
        parts = [p.strip(" -â€¢\t") for p in re.split(r"[,\nØŒ]+", cs) if p.strip()]
        r["core_skills"] = parts[:6]
    elif isinstance(cs, (list, tuple)):
        skills = [_norm_text(x).strip() for x in cs if _norm_text(x).strip()]
        r["core_skills"] = skills[:6]
    else:
        r["core_skills"] = []

    # difficulty â†’ 1..5
    try:
        d = int(r.get("difficulty", 3))
        r["difficulty"] = max(1, min(5, d))
    except Exception:
        r["difficulty"] = 3

    # mode
    if r.get("mode") not in ("Solo","Team","Solo/Team","ÙØ±Ø¯ÙŠ","Ø¬Ù…Ø§Ø¹ÙŠ","ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ"):
        r["mode"] = r.get("mode","Solo")
    return r


def _fallback_identity(i: int, lang: str) -> Dict[str, Any]:
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        presets = [
            {
                "sport_label":"Tactical Immersive Combat",
                "what_it_looks_like":"Ø³Ø§Ø­Ø© Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ØµØ±ÙŠØ© Ø£Ùˆ VR: ØªØªØ¨Ù‘Ø¹ØŒ ÙƒÙ…ÙŠÙ†ØŒ Ù‚Ø±Ø§Ø± Ø®Ø§Ø·ÙØŒ Ø§Ù‚ØªØ±Ø§Ø¨ Ù…Ø­Ø³ÙˆØ¨ØŒ Ø§Ù†Ø³Ø­Ø§Ø¨ Ø¢Ù…Ù†.",
                "inner_sensation":"Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø°Ù‡Ù†ÙŠ Ù…Ø¹ ÙŠÙ‚Ø¸Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ«Ù‚Ø© Ù‡Ø§Ø¯Ø¦Ø©.",
                "why_you":"ØªÙƒØ±Ù‡ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØªÙØ¶Ù‘Ù„ ØµØ±Ø§Ø¹Ù‹Ø§ ØªÙƒØªÙŠÙƒÙŠÙ‹Ø§ ÙŠØ®ØªØ¨Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„Ø£Ø¹ØµØ§Ø¨.",
                "first_week":"Ø§Ø¨Ø¯Ø£ Ø¨Ø¬ÙˆÙ„Ø© Ø­Ø³Ù‘ÙŠØ©: ØªØ¹Ø±Ù‘Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ØŒ Ø¬Ø±Ù‘Ø¨ Ø§Ù‚ØªØ±Ø§Ø¨/Ø§Ù†Ø³Ø­Ø§Ø¨ØŒ ÙˆØ«Ø¨Ù‘Øª ØªÙ†ÙÙ‘Ø³Ùƒ Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ø±Ø§Ø±.",
                "progress_markers":"Ù‚Ø±Ø§Ø±Ø§Øª Ø£Ø³Ø±Ø¹ØŒ Ù‡Ø¯ÙˆØ¡ ØªØ­Øª Ø§Ù„Ø¶ØºØ·ØŒ Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø³ÙŠØ·Ø±Ø© Ø£Ø¹Ù„Ù‰.",
                "win_condition":"Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù‡Ø¯Ù Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù Ø£Ùˆ ØªØ¹Ø·ÙŠÙ„ 'Ø§Ù„Ø®ØµÙ…' Ø¨Ù‚Ø±Ø§Ø± Ø®Ø§Ø·Ù.",
                "core_skills":["ØªØªØ¨Ù‘Ø¹ Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø±Ø¤ÙŠØ©","ØªØºÙŠÙŠØ± Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹","Ø«Ø¨Ø§Øª Ø§Ù„ØªÙˆØ§Ø²Ù†","ØªÙ†ÙÙ‘Ø³ Ù‡Ø§Ø¯Ø¦"],
                "mode":"Solo/Team",
                "variant_vr":"Ù…Ø¨Ø§Ø±Ø²Ø§Øª ØªÙƒØªÙŠÙƒÙŠØ© ÙÙŠ VR Ù…Ø¹ ØªØªØ¨Ø¹ Ù…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ© Ø§Ù„Ø®ØµÙ….",
                "variant_no_vr":"Ø¹Ù‚Ø¨Ø§Øª Ø®ÙÙŠÙØ© Ù…Ø¹ Ù…Ù…Ø±Ø§Øª Ø¸Ù„Ù‘.",
                "difficulty":3
            },
            {
                "sport_label":"Stealth-Flow Missions",
                "what_it_looks_like":"Ù…Ø³Ø§Ø± ØµØ§Ù…Øª Ù…ØªØ¯Ø±Ù‘Ø¬: Ø§Ø®ØªØ¨Ø§Ø¡ Ù‚ØµÙŠØ±ØŒ Ø¸Ù‡ÙˆØ± Ù…Ø­Ø³ÙˆØ¨ØŒ Ù„Ù…Ø³ 'Ø¹Ù„Ø§Ù…Ø©' Ø«Ù… Ø§Ø®ØªÙØ§Ø¡.",
                "inner_sensation":"ØªØ±ÙƒÙŠØ² Ø¹Ù…ÙŠÙ‚ ÙˆØªÙ†Ø¸ÙŠÙ… Ù„Ù„Ù†ÙØ³ Ù…Ø¹ Ø­Ø±ÙƒØ© Ù†Ø§Ø¹Ù…Ø©.",
                "why_you":"ØªØ¨ØºÙ‰ ØªÙ‚Ø¯Ù‘Ù… Ù…Ù„Ù…ÙˆØ³ Ø¨Ø¯ÙˆÙ† Ø¶Ø¬ÙŠØ¬ ÙˆØªØ­Ø¨ Ø§Ù„Ø¥ØªÙ‚Ø§Ù† Ø§Ù„Ù‡Ø§Ø¯Ø¦.",
                "first_week":"Ø¯Ø±Ù‘Ø¨ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±Ø¹Ø§Øª Ø¨Ø³Ù„Ø§Ø³Ø© ÙˆÙ…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¢Ù…Ù†Ø©.",
                "progress_markers":"ØªÙˆØªØ± Ø£Ù‚Ù„ØŒ Ù†Ø¹ÙˆÙ…Ø© Ø­Ø±ÙƒØ©ØŒ Ù‚Ø±Ø§Ø±Ø§Øª Ø£ÙˆØ¶Ø­.",
                "win_condition":"Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù.",
                "core_skills":["ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¸Ù‡ÙˆØ±","Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­ÙˆØ§Ø¬Ø²","ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙ†ÙÙ‘Ø³ ØµØ§Ù…Øª","ØªÙˆØ§Ø²Ù†"],
                "mode":"Solo",
                "variant_vr":"ØªØ³Ù„Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ø¹ Ù…Ø¤Ø´Ù‘Ø± Ø§Ù†ÙƒØ´Ø§Ù Ø¨ØµØ±ÙŠ.",
                "variant_no_vr":"Ø¹ÙˆØ§Ø¦Ù‚ Ø®ÙÙŠÙØ© ÙˆØ£Ø´Ø±Ø·Ø© Ø¸Ù„.",
                "difficulty":2
            },
            {
                "sport_label":"Mind-Trap Puzzles in Motion",
                "what_it_looks_like":"Ø£Ù„ØºØ§Ø² Ù‚Ø±Ø§Ø± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©: ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±ØŒ Ø®Ø¯Ø¹Ø© Ø¨ØµØ±ÙŠØ©ØŒ Ø­Ø±ÙƒØ© Ù…Ø¶Ø§Ø¯Ø© Ù„Ø­Ø±ÙƒØ© 'Ø®ØµÙ…' Ø§ÙØªØ±Ø§Ø¶ÙŠ.",
                "inner_sensation":"ÙØ¶ÙˆÙ„ Ø°Ù‡Ù†ÙŠ Ù…Ø¹ Ù„Ø°Ù‘Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù.",
                "why_you":"ØªØ­Ø¨ Ø§Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆÙ…Ø¨Ø§Ø±Ø²Ø© Ø§Ù„Ù‡ÙˆÙŠØ© Ø°Ù‡Ù†ÙŠÙ‹Ø§ Ù‚Ø¨Ù„ Ø¬Ø³Ø¯ÙŠÙ‹Ø§.",
                "first_week":"Ø­Ù„ Ù„ØºØ² Ø­Ø±ÙƒÙŠ Ø¨Ø³ÙŠØ· Ù…Ø¹ ØªØªØ¨Ù‘Ø¹ Ø§Ù„Ù†ÙØ³ØŒ Ø«Ù… Ø£Ø¶Ù Ø®Ø¯Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©.",
                "progress_markers":"ÙˆØ¶ÙˆØ­ ØªØ±ÙƒÙŠØ²ØŒ Ø«Ù‚Ø© Ù‚Ø±Ø§Ø±ØŒ ØªÙ†Ø§ØºÙ… Ø­Ø±ÙƒØ©/ÙÙƒØ±.",
                "win_condition":"Ø­Ù„ Ø§Ù„Ù„ØºØ² Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØªØ§Ù„ÙŠØ©.",
                "core_skills":["Ø®Ø¯Ø§Ø¹ Ø¨ØµØ±ÙŠ","ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±","ØªØ«Ø¨ÙŠØª Ù†Ø¸Ø±Ø©","Ù‚Ø±Ø§Ø± Ø¨Ø¯ÙŠÙ‡ÙŠ","Ù‡Ø¯ÙˆØ¡ ØªØ­Øª Ø¶ØºØ·"],
                "mode":"Solo",
                "variant_vr":"Ø£ÙØ®Ø§Ø® Ø¨ØµØ±ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©.",
                "variant_no_vr":"Ù…Ø³Ø§Ø±Ø§Øª Ø£Ø±Ø¶ÙŠØ© Ø°Ø§Øª Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø®ÙÙŠØ©.",
                "difficulty":2
            },
            {
                "sport_label":"Range Precision Circuit",
                "what_it_looks_like":"Ø¯Ù‚Ø© ØªØµÙˆÙŠØ¨ Ù‡Ø§Ø¯Ø¦Ø© Ù…Ø¹ Ø²ÙˆØ§ÙŠØ§ Ø«Ø§Ø¨ØªØ© ÙˆØ§Ù†ØªÙ‚Ø§Ù„ Ù…Ù†Ø¸Ù‘Ù… Ø¨ÙŠÙ† Ø£Ù‡Ø¯Ø§Ù.",
                "inner_sensation":"Ù‡Ø¯ÙˆØ¡ Ù…ØªÙ…Ø±ÙƒØ² ÙˆÙ†Ø¨Ø¶ Ù…Ø³ØªÙ‚Ø±.",
                "why_you":"ØªÙ…ÙŠÙ„ Ù„ØªÙ‡Ø°ÙŠØ¨ Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø§ØªÙ‚Ø§Ù† Ø§Ù„ØµØ§Ù…Øª.",
                "first_week":"Ø«Ø¨Ù‘Øª Ø§Ù„Ù†Ø¸Ø±Ø©ØŒ Ø§Ø¶Ø¨Ø· Ø§Ù„Ù†ÙØ³ØŒ Ø¨Ø¯Ù‘Ù„ Ø²ÙˆØ§ÙŠØ§Ùƒ Ø¨Ø³Ù„Ø§Ø³Ø©.",
                "progress_markers":"Ø«Ø¨Ø§Øª ÙŠØ¯ØŒ Ù‚Ø±Ø§Ø± Ø£ÙˆØ¶Ø­ØŒ ØªÙˆØªØ± Ø£Ù‚Ù„.",
                "win_condition":"ØªØ­Ù‚ÙŠÙ‚ Ø¯Ù‚Ø© Ø«Ø§Ø¨ØªØ© Ø¹Ø¨Ø± Ø³Ù„Ø³Ù„Ø© Ø£Ù‡Ø¯Ø§Ù Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØªØ§Ù„ÙŠØ©.",
                "core_skills":["ØªØ«Ø¨ÙŠØª Ù†Ø¸Ø±Ø©","Ø¶Ø¨Ø· Ù†ÙØ³","Ø§Ù†ØªÙ‚Ø§Ù„ Ø²ÙˆØ§ÙŠØ§","ØªØ­ÙƒÙ‘Ù… Ø¯Ù‚ÙŠÙ‚"],
                "mode":"Solo",
                "variant_vr":"ØªØµÙˆÙŠØ¨ Ø§ÙØªØ±Ø§Ø¶ÙŠ ØªÙØ§Ø¹Ù„ÙŠ.",
                "variant_no_vr":"Ù„ÙˆØ­Ø§Øª Ø£Ù‡Ø¯Ø§Ù Ø¥Ø³ÙÙ†Ø¬ÙŠØ© Ø¢Ù…Ù†Ø©.",
                "difficulty":2
            },
            {
                "sport_label":"Grip & Balance Ascent",
                "what_it_looks_like":"Ù…Ø³Ø§Ø± Ù‚Ø¨Ø¶Ø§Øª ÙˆØªÙˆØ§Ø²Ù† ØªØ¯Ø±ÙŠØ¬ÙŠØŒ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³ÙƒØŒ ØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù† Ù‡Ø§Ø¯Ø¦.",
                "inner_sensation":"ØªÙ…Ø§Ø³Ùƒ Ø¯Ø§Ø®Ù„ÙŠ ÙˆØ«Ù‚Ø© Ø­Ø±ÙƒØ©.",
                "why_you":"ØªØ­Ø¨ ØªØ­Ø¯Ù‘ÙŠ ØªØ­ÙƒÙ‘Ù… Ø§Ù„Ø¬Ø³Ø¯ Ø¨Ø¯ÙˆÙ† Ø¶Ø¬ÙŠØ¬.",
                "first_week":"Ø§Ù‚Ø±Ø£ Ù…ÙˆØ¶Ø¹ Ø§Ù„Ù‚Ø¨Ø¶Ø©ØŒ ÙˆØ²Ù‘Ù† Ø§Ù„Ø­Ù…Ù„ØŒ ØªØ­Ø±Ù‘Ùƒ Ø¨Ø¨Ø·Ø¡ ØµØ§Ø¹Ø¯.",
                "progress_markers":"ØªØ¹Ø¨ Ø£Ù‚Ù„ ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø¯ØŒ Ø§ØªØ²Ø§Ù† Ø£ÙˆØ¶Ø­.",
                "win_condition":"Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© Ø¯ÙˆÙ† Ø¥ÙÙ„Ø§Øª.",
                "core_skills":["Ù‚Ø¨Ø¶Ø©","ØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù†","ØªÙˆØ§Ø²Ù†","Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³Ø§Ø±"],
                "mode":"Solo",
                "variant_vr":"Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø¨Ø¶Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.",
                "variant_no_vr":"Ø¹Ù†Ø§ØµØ± Ù‚Ø¨Ø¶Ø© Ø¢Ù…Ù†Ø© Ø®ÙÙŠÙØ©.",
                "difficulty":2
            }
        ]
    else:
        presets = [
            {
                "sport_label":"Tactical Immersive Combat",
                "what_it_looks_like":"Arena/VR with tracking, ambush, snap decisions, calculated approach and safe exit.",
                "inner_sensation":"Locked-in focus with calm confidence.",
                "why_you":"You dislike repetition and enjoy tactical mind-body duels.",
                "first_week":"Feel the rhythm, practice approach/retreat, anchor breath before decisions.",
                "progress_markers":"Faster decisions, calmer under pressure, stronger control.",
                "win_condition":"Reach objective unseen or neutralize threat via snap decision.",
                "core_skills":["angle tracking","tempo shifts","fast decision","balance","quiet breath"],
                "mode":"Solo/Team",
                "variant_vr":"Tactical VR duels with FOV tracking.",
                "variant_no_vr":"Foam obstacles with shadow lanes.",
                "difficulty":3
            },
            {
                "sport_label":"Stealth-Flow Missions",
                "what_it_looks_like":"Silent path: brief hide, measured reveal, tag and vanish.",
                "inner_sensation":"Deep focus with smooth breathing.",
                "why_you":"You want tangible progress without noise and love quiet mastery.",
                "first_week":"Practice smooth tempo shifts and safe angles.",
                "progress_markers":"Lower tension, smoother movement, clearer decisions.",
                "win_condition":"Complete the mission without detection.",
                "core_skills":["timed reveal","reading cover","tempo control","silent breath","balance"],
                "mode":"Solo",
                "variant_vr":"Stealth VR with exposure indicator.",
                "variant_no_vr":"Light obstacles and shadow tapes.",
                "difficulty":2
            },
            {
                "sport_label":"Mind-Trap Puzzles in Motion",
                "what_it_looks_like":"Decision puzzles in motion: route switch, visual feint, counter-move.",
                "inner_sensation":"Curious mind with discovery joy.",
                "why_you":"You enjoy deep understanding and identity duelsâ€”mind first.",
                "first_week":"Solve a simple motion puzzle with breath tracking; add one feint.",
                "progress_markers":"Sharper focus, steadier decisions, mindâ€“body sync.",
                "win_condition":"Solve without consecutive errors.",
                "core_skills":["visual feint","path switch","gaze hold","intuitive decision","calm under stress"],
                "mode":"Solo",
                "variant_vr":"Interactive visual traps.",
                "variant_no_vr":"Floor cues with hidden hints.",
                "difficulty":2
            }
        ]
    return presets[i % len(presets)]


def _fill_defaults(r: Dict[str, Any], lang: str) -> Dict[str, Any]:
    r = dict(r or {})
    if not r.get("win_condition"):
        r["win_condition"] = ("Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                              else "Complete the mission without being detected.")
    if not r.get("core_skills"):
        r["core_skills"] = ["ØªØªØ¨Ù‘Ø¹ Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø±Ø¤ÙŠØ©","ØªØºÙŠÙŠØ± Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹"] if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" \
                           else ["angle tracking","tempo shifts","fast decision"]
    if not r.get("mode"):
        r["mode"] = "Solo/Team"
    if not r.get("variant_vr"):
        r["variant_vr"] = ("Ù…Ø¨Ø§Ø±Ø²Ø§Øª ØªÙƒØªÙŠÙƒÙŠØ© ÙÙŠ VR Ù…Ø¹ Ù…Ø¤Ø´Ù‘Ø± Ù…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ©." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                           else "Tactical VR duels with FOV indicator.")
    if not r.get("variant_no_vr"):
        r["variant_no_vr"] = ("Ø¹Ù‚Ø¨Ø§Øª Ø®ÙÙŠÙØ© Ù…Ø¹ Ù…Ù…Ø±Ø§Øª Ø¸Ù„." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                              else "Light obstacle arena with shadow lanes.")
    return r

# ======== HARD DEDUPE (no repeats, no near-duplicates) ========
def _hard_dedupe_and_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    used_labels = set()
    used_sigs: List[set] = []

    def pick_unique_fallback(idx: int) -> Dict[str, Any]:
        for j in range(idx, idx+6):
            fb = _fallback_identity(j, lang)
            lab = _canonical_label(fb.get("sport_label",""))
            sig = _sig_for_rec(fb)
            if lab and (lab not in used_labels) and all(_jaccard(sig, s) <= 0.6 for s in used_sigs):
                return fb
        fb = _fallback_identity(idx, lang)
        fb["sport_label"] = (fb.get("sport_label","") + " â€” Alt")
        return fb

    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        r = _fill_defaults(_sanitize_record(r), lang)

        lab = _canonical_label(r.get("sport_label",""))
        if not lab or _label_is_generic(lab):
            r = pick_unique_fallback(i); lab = _canonical_label(r.get("sport_label",""))

        if lab in used_labels:
            r = pick_unique_fallback(i); lab = _canonical_label(r.get("sport_label",""))

        sig = _sig_for_rec(r)
        if any(_jaccard(sig, s) > 0.6 for s in used_sigs):
            r = pick_unique_fallback(i); lab = _canonical_label(r.get("sport_label","")); sig = _sig_for_rec(r)

        out.append(r)
        used_labels.add(lab)
        used_sigs.append(sig)

    return out

# ========= KB-first: derive traits & score =========
def _derive_binary_traits(analysis: Dict[str, Any], answers: Dict[str, Any], lang: str) -> Dict[str, float]:
    """
    ÙŠØ±Ø¬Ù‘Ø¹ {trait_name: strength in [0,1]} Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ù…Ø­Ø§ÙˆØ± ZØŒ silent_driversØŒ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©.
    """
    traits: Dict[str, float] = {}
    prof = (analysis or {}).get("encoded_profile") or {}
    axes = (prof or {}).get("axes") or {}
    silent = set(map(str, (analysis or {}).get("silent_drivers") or []))

    sig = _extract_signals(answers, lang)

    # solo/group -> introvert/extrovert + prefers_*
    sg = float(axes.get("solo_group", 0.0)) if isinstance(axes, dict) else 0.0
    if sg <= -0.35: traits["introvert"] = 1.0; traits["prefers_solo"] = 1.0
    if sg >=  0.35: traits["extrovert"] = 1.0; traits["prefers_team"] = 1.0
    if sig.get("solo_pref"): traits["prefers_solo"] = max(1.0, traits.get("prefers_solo", 0))
    if sig.get("team_pref"): traits["prefers_team"] = max(1.0, traits.get("prefers_team", 0))

    # calm/adrenaline -> calm_regulation / sensation_seeking
    ca = float(axes.get("calm_adrenaline", 0.0)) if isinstance(axes, dict) else 0.0
    if ca <= -0.35 or sig.get("breath"):
        traits["calm_regulation"] = max(traits.get("calm_regulation", 0.0), 0.8)
    if ca >= 0.35 or sig.get("high_agg"):
        traits["sensation_seeking"] = max(traits.get("sensation_seeking", 0.0), 0.8)

    # tech/intu -> precision
    ti = float(axes.get("tech_intuition", 0.0)) if isinstance(axes, dict) else 0.0
    if ti <= -0.35 or sig.get("precision"):
        traits["precision"] = max(traits.get("precision", 0.0), 0.8)

    # ØªÙƒØªÙŠÙƒÙŠ/Ø£Ù„ØºØ§Ø²/Ù‚ØªØ§Ù„ÙŠ/VR
    if sig.get("stealth"):
        traits["tactical_mindset"] = max(1.0, traits.get("tactical_mindset", 0))
    if sig.get("puzzles"): traits["likes_puzzles"] = 1.0
    if sig.get("combat"): traits["tactical_mindset"] = max(1.0, traits.get("tactical_mindset", 0))
    vr_i = float((prof or {}).get("vr_inclination", 0.0))
    if sig.get("vr") or vr_i >= 0.4:
        traits["vr_inclination"] = max(traits.get("vr_inclination", 0.0), max(vr_i, 0.8))

    # sustained_attention ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ù„Ù‡Ø¯ÙˆØ¡/Ø§Ù„Ø£Ù„ØºØ§Ø²
    if traits.get("calm_regulation", 0) >= 0.8 or traits.get("likes_puzzles", 0) >= 1.0:
        traits["sustained_attention"] = max(traits.get("sustained_attention", 0.0), 0.6)

    # Ù‚Ù„Ù‚/Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±/Ø­Ø§Ø¬Ø© Ù…ÙƒØ§Ø³Ø¨ Ø³Ø±ÙŠØ¹Ø©
    ar_blob = _normalize_ar(" ".join(_norm_answer_value(v) for v in (answers or {}).values()).lower())
    if any(w in ar_blob for w in ["Ù‚Ù„Ù‚","Ù…Ø®Ø§ÙˆÙ","ØªÙˆØªØ± Ø´Ø¯ÙŠØ¯","Ø±Ù‡Ø§Ø¨","Ø®ÙˆÙ"]):
        traits["anxious"] = 1.0
    if any("Ù†ÙÙˆØ±" in s or "ØªÙƒØ±Ø§Ø±" in s for s in silent):
        traits["low_repetition_tolerance"] = 1.0
    if any("Ø§Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ù‡" in _normalize_ar(s) for s in silent):
        traits["needs_quick_wins"] = 1.0

    return traits

def _score_candidates_from_links(traits: Dict[str, float]) -> List[Tuple[float, str]]:
    """
    score(label) = prior[label] + Î£ (trait_strength * link_weight)
    Ù…Ø¹ Ø§Ø­ØªØ±Ø§Ù… Ø§Ù„Ø­Ø±Ø§Ø³ (anxiety vs high-risk).
    """
    anxious = traits.get("anxious", 0.0) >= 0.8 and GUARDS.get("no_high_risk_for_anxiety", True)

    labels = set(KB_PRIORS.keys())
    for t, mapping in (TRAIT_LINKS or {}).items():
        labels.update(mapping.keys())

    scored: List[Tuple[float, str]] = []
    for label in labels:
        if anxious and label in HIGH_RISK_SPORTS:
            scored.append((-1e9, label))
            continue
        s = float(KB_PRIORS.get(label, 0.0))
        for t_name, strength in traits.items():
            link = (TRAIT_LINKS.get(t_name) or {}).get(label, 0.0)
            if link:
                s += float(strength) * float(link)
        scored.append((s, label))
    scored.sort(key=lambda x: x[0], reverse=True)
    return scored

# ========= Optional: identities from KB (if provided) =========
def _pick_kb_recommendations(user_axes: Dict[str, Any], user_signals: Dict[str, int], lang: str) -> List[Dict[str, Any]]:
    """
    Ù„Ùˆ Ù…Ù„Ù KB ÙŠØ­ÙˆÙŠ "identities": Ù†Ù‚Ø¯Ø± Ù†ÙÙ„ØªØ±/Ù†Ø±ØªÙ‘Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­Ø§Ø°Ø§Ø© Ø¨Ø³ÙŠØ·Ø©.
    Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ ÙŠØ±Ø¬Ø¹ [].
    """
    identities = KB.get("identities")
    if not isinstance(identities, list) or not identities:
        return []
    scored: List[Tuple[float, Dict[str, Any]]] = []
    exp = _axes_expectations(user_axes or {}, lang)
    for rec in identities:
        r = _sanitize_record(rec)
        blob = " ".join([_norm_text(r.get("what_it_looks_like","")),
                         _norm_text(r.get("why_you","")),
                         _norm_text(r.get("first_week",""))]).lower()
        hit = 0
        for words in exp.values():
            if words and any(w.lower() in blob for w in words):
                hit += 1
        # Ø¥Ø´Ø§Ø±Ø§Øª Ù†ØµÙŠØ©
        if user_signals.get("precision") and ("precision" in blob or "Ø¯Ù‚Ù‡" in blob): hit += 1
        if user_signals.get("stealth") and ("stealth" in blob or "ØªØ®ÙÙŠ" in blob): hit += 1
        scored.append((hit, r))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [s[1] for s in scored[:3]]

# ========= Templates by label (AR/EN) =========
def _canon_label(label: str) -> str:
    lab = _normalize_ar((label or "")).lower().strip(" -â€”:ØŒ")
    if not lab:
        return ""
    if lab in _ALIAS_MAP:
        return _ALIAS_MAP[lab]
    lab = re.sub(r"[^a-z0-9\u0600-\u06FF]+", " ", lab)
    lab = re.sub(r"\s+", " ", lab).strip()
    return lab

def _is_forbidden_generic(label: str) -> bool:
    base = _normalize_ar((label or "")).lower()
    return any(g in base for g in _FORBIDDEN_GENERIC)

if L in (_canon_label("esports"),):
    return _sanitize_record(_fill_defaults({
        "sport_label": "Esports â€” Ø¯Ù‚Ø© ÙˆØªÙƒØªÙŠÙƒ" if ar else "Esports â€” Precision & Tactics",
        "what_it_looks_like": "ØªØµÙˆÙŠØ¨ Ù„Ø­Ø¸ÙŠ ÙˆÙ‚Ø±Ø§Ø¡Ø© Ù…ÙˆØ§Ù‚Ù ÙˆØªÙ†Ø³ÙŠÙ‚ ÙØ±ÙŠÙ‚/ÙØ±Ø¯.",
        "inner_sensation": "ØªÙŠÙ‚Ù‘Ø¸ Ù…Ø¹ Ù‡Ø¯ÙˆØ¡ Ù‚Ø±Ø§Ø±.",
        "why_you": "ØªØ³ØªÙ…ØªØ¹ Ø¨Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØªÙƒØªÙŠÙƒÙŠ.",
        "first_week": "ØªØ«Ø¨ÙŠØª Ø­Ø³Ù‘ Ø§Ù„Ù†Ø¸Ø± â€” Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ â€” Ù‚Ø±Ø§Ø± Ù†Ø¸ÙŠÙ.",
        "progress_markers": "Ø«Ø¨Ø§Øª ØªØµÙˆÙŠØ¨ â€” Ø£Ø®Ø·Ø§Ø¡ Ø£Ù‚Ù„.",
        "win_condition": "ØªØ­Ù‚ÙŠÙ‚ Ø£Ù‡Ø¯Ø§Ù ØªÙƒØªÙŠÙƒÙŠØ© Ø¶Ù…Ù† Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ø­Ø§ÙƒØ§Ø©.",
        "core_skills": ["ØªØªØ¨Ù‘Ø¹ Ù†Ø¸Ø±Ø©","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹","ØªÙ†Ø³ÙŠÙ‚"] if ar else
                       ["gaze tracking","snap decision","coordination"],
        "mode": "Solo/Team",
        "variant_vr": "Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ØªÙƒØªÙŠÙƒÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ.",
        "variant_no_vr": "ØªÙ…Ø§Ø±ÙŠÙ† Ø¯Ù‚Ø© Ù‚ØµÙŠØ±Ø©.",  # â† Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­
        "difficulty": 3
    }, lang))

    # Ø®Ø±Ø§Ø¦Ø· Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø®Ù…Ø³Ø© "Ø§Ù„Ù‡ÙˆÙŠØ§Øª" Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©
    KB_PRESETS = {
        "tactical_immersive_combat": _fallback_identity(0, lang),
        "stealth_flow_missions": _fallback_identity(1, lang),
        "mind_trap_puzzles": _fallback_identity(2, lang),
        "range_precision_circuit": _fallback_identity(3, lang),
        "grip_balance_ascent": _fallback_identity(4, lang),
    }
    for k, v in KB_PRESETS.items():
        if L == _canon_label(k):
            return _sanitize_record(_fill_defaults(v, lang))

    # Ø±ÙŠØ§Ø¶Ø§Øª Ø´Ø§Ø¦Ø¹Ø©
    if L in (_canon_label("archery"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Ø§Ù„Ø±Ù…Ø§ÙŠØ© (Ø¯Ù‚Ø©)" if ar else "Archery (Precision)",
            "what_it_looks_like": "ÙˆØ¶Ø¹ Ø«Ø§Ø¨Øª ÙˆÙ†Ø¸Ø±Ø© Ù…Ø±ÙƒÙ‘Ø²Ø© ÙˆØ§Ù†ØªÙ‚Ø§Ù„ Ù…Ù†Ø¸Ù‘Ù… Ù„Ù‡Ø¯Ù Ø¨ØµØ±ÙŠ.",
            "inner_sensation": "Ù‡Ø¯ÙˆØ¡ ÙˆÙ†Ø¨Ø¶ Ù…Ø³ØªÙ‚Ø± ÙˆØ«Ù‚Ø© ÙŠØ¯.",
            "why_you": "ØªÙ…ÙŠÙ„ Ù„Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ… ÙˆÙ‚Ø±Ø§Ø±Ø§Øª Ù‡Ø§Ø¯Ø¦Ø©.",
            "first_week": "Ø«Ø¨Ù‘Øª Ø§Ù„Ù†Ø¸Ø±Ø© â€” Ø§Ø¶Ø¨Ø· Ø§Ù„Ù†ÙØ³ â€” Ø¨Ø¯Ù‘Ù„ Ø²ÙˆØ§ÙŠØ§Ùƒ Ø¨Ø³Ù„Ø§Ø³Ø©.",
            "progress_markers": "Ø«Ø¨Ø§Øª ÙŠØ¯ Ø£ÙˆØ¶Ø­ â€” Ù‚Ø±Ø§Ø±Ø§Øª Ø£Ù†Ø¸Ù â€” ØªÙˆØªØ± Ø£Ù‚Ù„.",
            "win_condition": "ØªØ­Ù‚ÙŠÙ‚ Ø¯Ù‚Ø© Ù…ØªÙ‘Ø³Ù‚Ø© Ø¹Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ø£Ù‡Ø¯Ø§Ù.",
            "core_skills": ["ØªØ«Ø¨ÙŠØª Ù†Ø¸Ø±Ø©","Ø¶Ø¨Ø· Ù†ÙØ³","Ø§Ù†ØªÙ‚Ø§Ù„ Ø²ÙˆØ§ÙŠØ§","ØªØ­ÙƒÙ‘Ù… Ø¯Ù‚ÙŠÙ‚"] if ar else
                           ["gaze hold","breath control","angle transitions","fine control"],
            "mode": "Solo",
            "variant_vr": "Ù„ÙˆØ­Ø© Ø£Ù‡Ø¯Ø§Ù Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ø¹ Ø§Ø±ØªØ¬Ø§Ø¹ Ø¨ØµØ±ÙŠ.",
            "variant_no_vr": "Ø£Ù‡Ø¯Ø§Ù Ø¥Ø³ÙÙ†Ø¬ÙŠØ© Ø¢Ù…Ù†Ø©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("marksmanship"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ØªØµÙˆÙŠØ¨ Ø¢Ù…Ù† (Ù…Ø¯Ù‰)" if ar else "Marksmanship (Safe Range)",
            "what_it_looks_like": "ÙˆÙ‚ÙØ© Ø«Ø§Ø¨ØªØ©ØŒ ØªÙ†ÙÙ‘Ø³ Ù‡Ø§Ø¯Ø¦ØŒ Ù‚Ø±Ø§Ø± Ù†Ø¸ÙŠÙ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ø¨ØµØ±ÙŠØ©.",
            "inner_sensation": "ØªØ±ÙƒÙŠØ² Ù…ØªÙ…Ø±ÙƒØ² ÙˆØ«Ø¨Ø§Øª ÙŠØ¯.",
            "why_you": "ØªØ¨Ø­Ø« Ø¹Ù† ÙˆØ¶ÙˆØ­ Ø§Ù„Ù‚Ø±Ø§Ø± ÙˆØ¯Ù‚Ù‘Ø© Ù‡Ø§Ø¯Ø¦Ø©.",
            "first_week": "ØªÙ†Ø³ÙŠÙ‚ Ù†Ø¸Ø±Ø©-Ù†ÙØ³ â€” Ø¯Ø®ÙˆÙ„ ÙˆØ®Ø±ÙˆØ¬ Ù‚Ø±Ø§Ø± Ø¯ÙˆÙ† Ø§Ø±ØªØ¨Ø§Ùƒ.",
            "progress_markers": "ØªØ´ØªØª Ø£Ù‚Ù„ â€” ØªÙ…Ø§Ø³Ùƒ Ù‚Ø±Ø§Ø± â€” Ø§ØªØ³Ø§Ù‚ Ø£Ø¹Ù„Ù‰.",
            "win_condition": "Ø³Ù„Ø³Ù„Ø© Ø¥ØµØ§Ø¨Ø§Øª Ø¶Ù…Ù† Ù‡Ø§Ù…Ø´ Ø¯Ù‚Ø© Ù…Ø­Ø¯Ø¯.",
            "core_skills": ["Ø«Ø¨Ø§Øª","ØªÙ†ÙÙ‘Ø³","Ù‚Ø±Ø§Ø¡Ø© Ù…Ø¤Ø´Ø±Ø§Øª","Ù‚Ø±Ø§Ø± Ù‡Ø§Ø¯Ø¦"] if ar else
                           ["stability","breathing","cue reading","calm decision"],
            "mode": "Solo",
            "variant_vr": "Ù…Ø­Ø§ÙƒØ§Ø© ØªØµÙˆÙŠØ¨ Ø¢Ù…Ù†Ø©.",
            "variant_no_vr": "Ù„ÙˆØ­Ø§Øª Ø¥Ø³ÙÙ†Ø¬ÙŠØ©/Ù„ÙŠØ²Ø± ØªØ¯Ø±ÙŠØ¨ÙŠØ©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("climbing"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ØªØ³Ù„Ù‚ â€” Ù‚Ø¨Ø¶Ø© ÙˆØªÙˆØ§Ø²Ù†" if ar else "Climbing â€” Grip & Balance",
            "what_it_looks_like": "Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³ÙƒØ§Øª ÙˆØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù† Ù‡Ø§Ø¯Ø¦ ÙˆÙ…Ø³Ø§Ø± ØµØ§Ø¹Ø¯ Ù…Ù†Ø¸Ù‘Ù….",
            "inner_sensation": "ØªÙ…Ø§Ø³Ùƒ Ø¯Ø§Ø®Ù„ÙŠ ÙˆØ«Ù‚Ø© Ø­Ø±ÙƒØ©.",
            "why_you": "ØªØ­Ø¨ ØªØ­Ø¯Ù‘ÙŠ ØªØ­ÙƒÙ‘Ù… Ø§Ù„Ø¬Ø³Ø¯ Ø¨Ù„Ø§ Ø¶Ø¬ÙŠØ¬.",
            "first_week": "Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø³ÙƒØ© â€” Ø­Ø±Ù‘Ø± ÙˆØ²Ù†Ùƒ â€” ØªØ­Ø±Ù‘Ùƒ Ø¨Ø¨Ø·Ø¡ ØµØ§Ø¹Ø¯.",
            "progress_markers": "ØªØ¹Ø¨ Ø³Ø§Ø¹Ø¯ Ø£Ù‚Ù„ â€” Ø§ØªØ²Ø§Ù† Ø£ÙˆØ¶Ø­.",
            "win_condition": "Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù‡Ø¯Ù Ø¯ÙˆÙ† Ø¥ÙÙ„Ø§Øª.",
            "core_skills": ["Ù‚Ø¨Ø¶Ø©","ØªÙˆØ§Ø²Ù†","ØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù†","Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³Ø§Ø±"] if ar else
                           ["grip","balance","weight shift","route reading"],
            "mode": "Solo",
            "variant_vr": "Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø¨Ø¶Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.",
            "variant_no_vr": "Ø¹Ù†Ø§ØµØ± Ù‚Ø¨Ø¶Ø© Ø¢Ù…Ù†Ø© Ø®ÙÙŠÙØ©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("swimming"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Ø³Ø¨Ø§Ø­Ø© â€” Ø®Ø·ÙˆØ· Ù‡Ø§Ø¯Ø¦Ø©" if ar else "Swimming â€” Calm Lines",
            "what_it_looks_like": "Ø³ÙƒØªØ§Øª Ù…Ù†ØªØ¸Ù…Ø© ÙˆØªÙˆØ§ÙÙ‚ Ù†ÙØ³-Ø­Ø±ÙƒØ©.",
            "inner_sensation": "Ø§Ù†Ø³ÙŠØ§Ø¨ ÙˆÙ‡Ø¯ÙˆØ¡ Ø°Ù‡Ù†ÙŠ.",
            "why_you": "ØªØ¨Ø­Ø« Ø¹Ù† ØµÙØ§Ø¡ ÙˆØªÙ†Ø¸ÙŠÙ… Ø¥ÙŠÙ‚Ø§Ø¹.",
            "first_week": "Ù„Ø§Ø­Ø¸ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ â€” Ù†Ø¸Ù‘Ù… Ø§Ù„Ø²ÙÙŠØ± â€” Ø«Ø¨Ù‘Øª Ø®Ø· Ø§Ù„Ø¬Ø³Ù….",
            "progress_markers": "ØªÙˆØªØ± Ø£Ù‚Ù„ â€” Ø³Ù„Ø§Ø³Ø© Ø£Ø¹Ù„Ù‰ â€” Ø¥ÙŠÙ‚Ø§Ø¹ Ù…ØªØ³Ù‚.",
            "win_condition": "Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆØ§Ù„Ù…Ø­Ø§Ø°Ø§Ø© Ø¹Ø¨Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø·ÙˆØ§Ù„.",
            "core_skills": ["Ù…Ø­Ø§Ø°Ø§Ø© Ø¬Ø³Ù…","ØªÙ†ÙÙ‘Ø³ Ù…Ù†Ø¸Ù…","Ø¥ÙŠÙ‚Ø§Ø¹ Ø«Ø§Ø¨Øª"] if ar else
                           ["body alignment","paced breathing","steady rhythm"],
            "mode": "Solo",
            "variant_vr": "ØªØ®ÙŠÙ‘Ù„ Ø¨ØµØ±ÙŠ Ù„Ù„ØªÙ†ÙØ³ ÙˆØ§Ù„Ù…Ø­Ø§Ø°Ø§Ø©.",
            "variant_no_vr": "ØªÙ…Ø§Ø±ÙŠÙ† Ù…Ø­Ø§Ø°Ø§Ø© ÙˆØªÙ†ÙØ³ Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ§Ø¨Ø³Ø©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("distance_running"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Ø¬Ø±ÙŠ Ù…Ø³Ø§ÙØ§Øª â€” Ø¥ÙŠÙ‚Ø§Ø¹ Ø«Ø§Ø¨Øª" if ar else "Distance Running â€” Steady Rhythm",
            "what_it_looks_like": "Ø®Ø·ÙˆØ© Ù…Ù†ØªØ¸Ù…Ø© ÙˆÙ†ÙÙÙØ³ Ù…ÙˆØ²ÙˆÙ† ÙˆØ§Ù†ØªØ¨Ø§Ù‡ Ù„Ù„Ø¥ÙŠÙ‚Ø§Ø¹.",
            "inner_sensation": "ØµÙØ§Ø¡ ÙˆØ­Ø¶ÙˆØ± Ø¬Ø³Ø¯ÙŠ Ø¨Ø³ÙŠØ·.",
            "why_you": "ØªÙØ¶Ù‘Ù„ ØªÙ‚Ø¯Ù…Ù‹Ø§ Ù‡Ø§Ø¯Ø¦Ù‹Ø§ ÙˆÙ…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ø¶Ø­Ø©.",
            "first_week": "Ø§Ø¨Ù†Ù Ø¥ÙŠÙ‚Ø§Ø¹Ùƒ â€” Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù†ÙØ³ â€” Ø®ÙÙ‘Ù ØªÙˆØªØ± Ø§Ù„ÙƒØªÙÙŠÙ†.",
            "progress_markers": "Ù†Ø¹ÙˆÙ…Ø© Ø®Ø·ÙˆØ© â€” ØµÙØ§Ø¡ Ø°Ù‡Ù†ÙŠ â€” Ù‚Ø±Ø§Ø± Ø£Ù‡Ø¯Ø£.",
            "win_condition": "Ø­ÙØ¸ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ Ø¯ÙˆÙ† Ø§Ù†Ù‚Ø·Ø§Ø¹ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ù…Ø­Ø¯Ø¯.",
            "core_skills": ["Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙ†ÙÙ‘Ø³","Ø§Ø³ØªØ±Ø®Ø§Ø¡ ÙƒØªÙ","Ù…Ø­Ø§Ø°Ø§Ø©"] if ar else
                           ["rhythm","breath","shoulder relax","alignment"],
            "mode": "Solo",
            "variant_vr": "Ù…Ø¤Ø´Ø±Ø§Øª Ø¥ÙŠÙ‚Ø§Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.",
            "variant_no_vr": "ØªÙ…Ø§Ø±ÙŠÙ† Ø¥ÙŠÙ‚Ø§Ø¹ Ø¹Ù„Ù‰ Ø£Ø±Ø¶ Ù…Ø³Ø·Ø­Ø©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("tennis"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ØªÙ†Ø³ â€” Ø²ÙˆØ§ÙŠØ§ ÙˆØ±ÙØ¯" if ar else "Tennis â€” Angles & Rally",
            "what_it_looks_like": "ØªØ¨Ø§Ø¯Ù„ ÙƒÙØ±Ø§Øª Ø¨Ø²ÙˆØ§ÙŠØ§ Ù…Ø­Ø³ÙˆØ¨Ø© ÙˆØªÙˆÙ‚ÙŠØª Ù†Ø¸ÙŠÙ Ù„Ù„Ø¶Ø±Ø¨Ø©.",
            "inner_sensation": "ÙŠÙ‚Ø¸Ø© Ø®ÙÙŠÙØ© Ù…Ø¹ Ù‚Ø±Ø§Ø± ÙˆØ§Ø¶Ø­.",
            "why_you": "ØªÙˆØ§Ø²Ù† Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ/ÙØ±Ø¯ÙŠ Ù…Ø¹ Ø¯Ù‚Ù‘Ø© Ù„Ø­Ø¸ÙŠØ©.",
            "first_week": "Ø«Ø¨Ù‘Øª Ø§Ù„Ù†Ø¸Ø±Ø© â€” ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¶Ø±Ø¨Ø© â€” Ø§Ù‚Ø±Ø£ Ø§Ù„Ø²Ø§ÙˆÙŠØ©.",
            "progress_markers": "ØªØµÙˆÙŠØ¨ Ø£Ù†Ø¸Ù â€” Ø±Ø¯Ù‘ ÙØ¹Ù„ Ø£ÙˆØ¶Ø­.",
            "win_condition": "Ø³Ù„Ø³Ù„Ø© ØªØ¨Ø§Ø¯Ù„Ø§Øª Ù†Ø§Ø¬Ø­Ø© Ø¨Ø²ÙˆØ§ÙŠØ§ Ù…Ø­Ø³ÙˆØ¨Ø©.",
            "core_skills": ["ØªÙˆÙ‚ÙŠØª","Ø²Ø§ÙˆÙŠØ©","ØªÙˆØ§Ø²Ù†","Ù‚Ø±Ø§Ø±"] if ar else
                           ["timing","angle","balance","decision"],
            "mode": "Solo/Team",
            "variant_vr": "Ø±Ø§Ù„ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ ØªÙØ§Ø¹Ù„ÙŠ.",
            "variant_no_vr": "Ø­Ø§Ø¦Ø· Ø±Ø¯Ù‘/Ø´Ø±ÙŠÙƒ ØªØ¯Ø±ÙŠØ¨.",
            "difficulty": 3
        }, lang))
    if L in (_canon_label("yoga"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ÙŠÙˆØºØ§ â€” ØªÙ†Ø¸ÙŠÙ… Ù†ÙØ³ ÙˆÙ…Ø­Ø§Ø°Ø§Ø©" if ar else "Yoga â€” Breath & Alignment",
            "what_it_looks_like": "Ø³Ù„Ø§Ø³Ù„ Ù…Ø­Ø§Ø°Ø§Ø© Ù‡Ø§Ø¯Ø¦Ø© ÙˆØªØ±ÙƒÙŠØ² ØªÙ†ÙÙ‘Ø³.",
            "inner_sensation": "ØµÙØ§Ø¡ ÙˆØªÙ…Ø§Ø³Ùƒ Ø¯Ø§Ø®Ù„ÙŠ.",
            "why_you": "ØªØ¨Ø­Ø« Ø¹Ù† ØªÙ‡Ø¯Ø¦Ø© Ø§Ù„Ø£Ø¹ØµØ§Ø¨ ÙˆÙˆØ¹ÙŠ Ø¬Ø³Ø¯ÙŠ.",
            "first_week": "Ù…Ø­Ø§Ø°Ø§Ø© Ø£Ø³Ø§Ø³ÙŠØ© â€” Ù…Ø±Ø§Ù‚Ø¨Ø© Ø²ÙÙŠØ± â€” Ù†Ø¹ÙˆÙ…Ø© Ø§Ù†ØªÙ‚Ø§Ù„.",
            "progress_markers": "ØªÙˆØªØ± Ø£Ù‚Ù„ â€” ÙˆØ¹ÙŠ Ù…ÙØµÙ„ÙŠ Ø£ÙØ¶Ù„.",
            "win_condition": "Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø°Ø§Ø© ÙˆØ§Ù„ØªÙ†ÙØ³ Ø¹Ø¨Ø± ØªØ³Ù„Ø³Ù„ ÙƒØ§Ù…Ù„.",
            "core_skills": ["ØªÙ†ÙÙ‘Ø³","Ù…Ø­Ø§Ø°Ø§Ø©","Ø§ØªØ²Ø§Ù†"] if ar else
                           ["breath","alignment","balance"],
            "mode": "Solo",
            "variant_vr": "Ø¥Ø±Ø´Ø§Ø¯ Ø¨ØµØ±ÙŠ Ù„Ù„ØªÙ†ÙØ³ ÙˆØ§Ù„Ù…Ø­Ø§Ø°Ø§Ø©.",
            "variant_no_vr": "Ø³Ù„Ø³Ù„Ø© ÙˆØ¶Ø¹ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©.",
            "difficulty": 1
        }, lang))
    if L in (_canon_label("free_diving"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ØºÙˆØµ Ø­Ø± â€” Ù‡Ø¯ÙˆØ¡ ÙˆØªÙ†Ø¸ÙŠÙ…" if ar else "Free Diving â€” Calm Regulation",
            "what_it_looks_like": "ØªØ­Ø¶ÙŠØ± ØªÙ†ÙÙ‘Ø³ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ‡Ø¯ÙˆØ¡ Ø¯Ø§Ø®Ù„ÙŠ.",
            "inner_sensation": "Ø³ÙƒÙˆÙ† ÙˆØªØ±ÙƒÙŠØ² Ø¹Ø§Ù„ÙŠ.",
            "why_you": "ØªØ±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø¶Ø¨Ø· Ø§Ù„Ù†ÙØ³ ÙˆØ§Ù„Ù‡Ø¯ÙˆØ¡.",
            "first_week": "Ø¬ÙˆÙ„Ø§Øª Ù†ÙØ³ Ù…Ù†Ø¶Ø¨Ø· ÙˆØªØ®ÙŠÙ‘Ù„ Ù‡Ø§Ø¯Ø¦.",
            "progress_markers": "ØµÙØ§Ø¡ Ø£Ø¹Ù„Ù‰ â€” ØªØ­ÙƒÙ… Ù†ÙØ³ÙŠ Ø£Ø¹Ù…Ù‚.",
            "win_condition": "Ø­ÙØ¸ Ù‡Ø¯ÙˆØ¡ ÙˆØªÙ†ÙØ³ Ù…Ù†Ø¸Ù… Ø®Ù„Ø§Ù„ Ù…Ù‡Ù…Ø© Ù…Ø­Ø§ÙƒØ§Ø©.",
            "core_skills": ["Ø¶Ø¨Ø· Ù†ÙØ³","ØªØ±ÙƒÙŠØ²","Ø§Ø³ØªØ±Ø®Ø§Ø¡"] if ar else
                           ["breath control","focus","relaxation"],
            "mode": "Solo",
            "variant_vr": "Ù…Ø­Ø§ÙƒØ§Ø© Ù†ÙØ³ ÙˆØºÙ…Ø± Ø¨ØµØ±ÙŠ.",
            "variant_no_vr": "Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ØªÙ†ÙÙ‘Ø³ Ø¬Ø§Ù Ø¢Ù…Ù†.",
            "difficulty": 3
        }, lang))
    if L in (_canon_label("chess"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Ø´Ø·Ø±Ù†Ø¬ â€” ØªÙƒØªÙŠÙƒ Ø°Ù‡Ù†ÙŠ" if ar else "Chess â€” Tactical Mind",
            "what_it_looks_like": "Ù…Ù†Ø§ÙˆØ±Ø§Øª Ù‡Ø§Ø¯Ø¦Ø© ÙˆÙ‚Ø±Ø§Ø¡Ø© Ø²ÙˆØ§ÙŠØ§ Ù‚Ø±Ø§Ø±.",
            "inner_sensation": "ÙØ¶ÙˆÙ„ Ø°Ù‡Ù†ÙŠ ÙˆØ«Ù‚Ø© Ù‡Ø§Ø¯Ø¦Ø©.",
            "why_you": "ØªØ­Ø¨ Ø§Ù„Ø£Ù„ØºØ§Ø² ÙˆØ§Ù„ØªÙƒØªÙŠÙƒ.",
            "first_week": "Ù†Ù…Ø· Ø§ÙØªØªØ§Ø­ Ø«Ø§Ø¨Øª â€” Ù‚Ø±Ø§Ø¡Ø© ØªÙ‡Ø¯ÙŠØ¯Ø§Øª â€” Ù‡Ø¯ÙˆØ¡ Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ø±Ø§Ø±.",
            "progress_markers": "Ø£Ø®Ø·Ø§Ø¡ Ø£Ù‚Ù„ â€” ÙˆØ¶ÙˆØ­ Ø®Ø·Ù‘Ø©.",
            "win_condition": "Ø¥Ù†Ù‡Ø§Ø¡ Ù„Ø¹Ø¨Ø© Ø¨Ø®Ø·Ù‘Ø© ÙˆØ§Ø¶Ø­Ø© Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØªØ§Ù„ÙŠØ©.",
            "core_skills": ["Ù‚Ø±Ø§Ø¡Ø© ØªÙ‡Ø¯ÙŠØ¯","ØµØ¨Ø±","Ø®Ø¯Ø¹Ø© Ø¨ØµØ±ÙŠØ©"] if ar else
                           ["threat reading","patience","feint"],
            "mode": "Solo/Team",
            "variant_vr": "Ù„ÙˆØ­ Ø§ÙØªØ±Ø§Ø¶ÙŠ ØªÙØ§Ø¹Ù„ÙŠ.",
            "variant_no_vr": "Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ØªÙƒØªÙŠÙƒÙŠØ© Ù‚ØµÙŠØ±Ø©.",
            "difficulty": 2
        }, lang))
    if L in (_canon_label("esports"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Esports â€” Ø¯Ù‚Ø© ÙˆØªÙƒØªÙŠÙƒ" if ar else "Esports â€” Precision & Tactics",
            "what_it_looks_like": "ØªØµÙˆÙŠØ¨ Ù„Ø­Ø¸ÙŠ ÙˆÙ‚Ø±Ø§Ø¡Ø© Ù…ÙˆØ§Ù‚Ù ÙˆØªÙ†Ø³ÙŠÙ‚ ÙØ±ÙŠÙ‚/ÙØ±Ø¯.",
            "inner_sensation": "ØªÙŠÙ‚Ù‘Ø¸ Ù…Ø¹ Ù‡Ø¯ÙˆØ¡ Ù‚Ø±Ø§Ø±.",
            "why_you": "ØªØ³ØªÙ…ØªØ¹ Ø¨Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØªÙƒØªÙŠÙƒÙŠ.",
            "first_week": "ØªØ«Ø¨ÙŠØª Ø­Ø³Ù‘ Ø§Ù„Ù†Ø¸Ø± â€” Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ â€” Ù‚Ø±Ø§Ø± Ù†Ø¸ÙŠÙ.",
            "progress_markers": "Ø«Ø¨Ø§Øª ØªØµÙˆÙŠØ¨ â€” Ø£Ø®Ø·Ø§Ø¡ Ø£Ù‚Ù„.",
            "win_condition": "ØªØ­Ù‚ÙŠÙ‚ Ø£Ù‡Ø¯Ø§Ù ØªÙƒØªÙŠÙƒÙŠØ© Ø¶Ù…Ù† Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ø­Ø§ÙƒØ§Ø©.",
            "core_skills": ["ØªØªØ¨Ù‘Ø¹ Ù†Ø¸Ø±Ø©","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹","ØªÙ†Ø³ÙŠÙ‚"] if ar else
                           ["gaze tracking","snap decision","coordination"],
            "mode": "Solo/Team",
            "variant_vr": "Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ØªÙƒØªÙŠÙƒÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ.",
            "variant_no_vr": "ØªÙ…Ø§Ø±ÙŠÙ† Ø¯Ù‚Ø© Ù‚ØµÙŠØ±Ø©.",  # FIXED
            "difficulty": 3
        }, lang))
    if L in (_canon_label("football"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "ÙƒØ±Ø© Ù‚Ø¯Ù… â€” Ø²ÙˆØ§ÙŠØ§ ÙˆØªÙ…Ø±ÙŠØ±" if ar else "Football â€” Angles & Passing",
            "what_it_looks_like": "ØªØ­Ø±Ù‘Ùƒ Ø¬Ù…Ø§Ø¹ÙŠ ÙˆÙ‚Ø±Ø§Ø¡Ø© Ù…Ø³Ø§Ø­Ø§Øª.",
            "inner_sensation": "Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø¬Ù…Ø§Ø¹ÙŠ Ù…Ø¹ Ù‚Ø±Ø§Ø± Ù„Ø­Ø¸ÙŠ.",
            "why_you": "ØªÙ…ÙŠÙ„ Ù„Ù„ØªØ¹Ø§ÙˆÙ† ÙˆØ§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©.",
            "first_week": "Ù‚Ø±Ø§Ø¡Ø© Ø²Ø§ÙˆÙŠØ© Ø§Ù„ØªÙ…Ø±ÙŠØ± â€” Ø¯Ø¹Ù… Ø¨Ø¯ÙˆÙ† ÙƒØ±Ø©.",
            "progress_markers": "ØªÙ…Ø±ÙƒØ² Ø£ÙØ¶Ù„ â€” Ù‚Ø±Ø§Ø±Ø§Øª Ø£Ø³Ø±Ø¹.",
            "win_condition": "ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ù‘Ø© ØªÙƒØªÙŠÙƒÙŠØ© Ø¶Ù…Ù† Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ.",
            "core_skills": ["ØªÙ…Ø±ÙƒØ²","Ø²Ø§ÙˆÙŠØ©","Ø¯Ø¹Ù…","Ù‚Ø±Ø§Ø±"] if ar else
                           ["positioning","angle","support","decision"],
            "mode": "Team",
            "variant_vr": "ØªÙƒØªÙŠÙƒ ØªÙ…Ø±ÙƒØ² Ø§ÙØªØ±Ø§Ø¶ÙŠ.",
            "variant_no_vr": "Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø²ÙˆØ§ÙŠØ§ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ù…Ø­Ø¯Ø¯.",
            "difficulty": 3
        }, lang))
    if L in (_canon_label("basketball"),):
        return _sanitize_record(_fill_defaults({
            "sport_label": "Ø³Ù„Ø© â€” Ù…Ø³Ø§Ø­Ø§Øª ÙˆØ¥ÙŠÙ‚Ø§Ø¹" if ar else "Basketball â€” Space & Rhythm",
            "what_it_looks_like": "ØªØ­Ø±Ù‘ÙƒØ§Øª Ù‚ØµÙŠØ±Ø© ÙˆØ²ÙˆØ§ÙŠØ§ ØªÙ…Ø±ÙŠØ±/ØªØµÙˆÙŠØ¨.",
            "inner_sensation": "ÙŠÙ‚Ø¸Ø© ÙˆØ¥ÙŠÙ‚Ø§Ø¹ Ø¬Ù…Ø§Ø¹ÙŠ.",
            "why_you": "ØªÙØ¶Ù‘Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ.",
            "first_week": "Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³Ø§Ø­Ø© â€” ØªÙˆÙ‚ÙŠØª Ù‚Ø·Ø¹ â€” Ù‚Ø±Ø§Ø± Ù‡Ø§Ø¯Ø¦.",
            "progress_markers": "ØªÙ…Ø±ÙƒØ² Ø£ÙˆØ¶Ø­ â€” Ø£Ø®Ø·Ø§Ø¡ Ø£Ù‚Ù„.",
            "win_condition": "Ø³Ù„Ø³Ù„Ø© Ù„Ø¹Ø¨Ø§Øª Ù†Ø§Ø¬Ø­Ø© Ø¶Ù…Ù† Ù…Ø®Ø·Ø·.",
            "core_skills": ["Ø²Ø§ÙˆÙŠØ©","ØªÙˆÙ‚ÙŠØª","ØªÙˆØ§Ø²Ù†","Ù‚Ø±Ø§Ø±"] if ar else
                           ["angle","timing","balance","decision"],
            "mode": "Team",
            "variant_vr": "Ù…Ø®Ø·Ø·Ø§Øª Ù„Ø¹Ø¨ Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.",
            "variant_no_vr": "ØªÙ…Ø§Ø±ÙŠÙ† Ø²ÙˆØ§ÙŠØ§ Ø¨Ø¯ÙˆÙ† Ø£Ø¯ÙˆØ§Øª.",
            "difficulty": 3
        }, lang))

    return None

# ====== Blacklist (persistent, JSON) =========================================
def _load_blacklist() -> dict:
    bl = _load_json_safe(BL_PATH)
    if not isinstance(bl.get("labels"), dict):
        bl["labels"] = {}
    bl.setdefault("version", "1.0")
    return bl

def _bl_has(bl: dict, label: str) -> bool:
    c = _canon_label(label)
    return bool(c and c in bl["labels"])

def _bl_add(bl: dict, label: str, alias: str = "") -> None:
    c = _canon_label(label)
    if not c:
        return
    rec = bl["labels"].get(c, {"aliases": [], "count": 0, "first_seen": None})
    if alias and alias not in rec["aliases"]:
        rec["aliases"].append(alias)
    rec["count"] = int(rec.get("count", 0)) + 1
    if not rec.get("first_seen"):
        rec["first_seen"] = datetime.utcnow().isoformat() + "Z"
    rec["last_used"] = datetime.utcnow().isoformat() + "Z"
    bl["labels"][c] = rec

_AR_VARIANTS = [
    "Ù†Ø³Ø®Ø© Ø¸Ù„Ù‘ÙŠØ©", "Ù†Ù…Ø· Ù…Ø±Ø§ÙˆØºØ©", "Ø®Ø· ØªØ­ÙƒÙ‘Ù… Ù‡Ø§Ø¯Ø¦", "Ù†Ø³Ø®Ø© ØªÙÙƒÙŠÙƒ ØªÙƒØªÙŠÙƒÙŠ",
    "Ù…Ù†Ø§ÙˆØ±Ø© Ø¹ÙƒØ³ÙŠØ©", "Ø²Ø§ÙˆÙŠØ© ØµØ§Ù…ØªØ©", "Ø·ÙŠÙ Ø§Ù„ØªØªØ¨Ø¹", "ØªØ¯ÙÙ‚ Ø®ÙÙŠ"
]
_EN_VARIANTS = [
    "Shadow Variant", "Evasive Pattern", "Calm-Control Line", "Tactical Deconstruction",
    "Counter-Maneuver", "Silent Angle", "Tracking Flux", "Stealth Flow"
]

def _generate_variant_label(base: str, lang: str, salt: int = 0) -> str:
    base = (base or "").strip(" -â€”:ØŒ")
    pool = _AR_VARIANTS if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else _EN_VARIANTS
    joiner = " â€” "
    idx = abs(hash(_normalize_ar(base) + str(salt))) % len(pool)
    return f"{base}{joiner}{pool[idx]}"

def _perturb_phrasing(rec: Dict[str, Any], lang: str) -> Dict[str, Any]:
    r = dict(rec)
    tacky_add_ar = " Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø²ÙˆØ§ÙŠØ§ Ø¨Ø¯Ù„ Ù…Ø·Ø§Ø±Ø¯Ø© Ø§Ù„Ø­Ø±ÙƒØ©. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù‚Ø±Ø§Ø± ÙŠØ¸Ù‡Ø± ÙØ¬Ø£Ø© Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙ‡Ø¯Ø£ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹."
    tacky_add_en = " Emphasize reading angles over chasing motion; let decisions snap when the rhythm calms."
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        r["what_it_looks_like"] = (r.get("what_it_looks_like","") + tacky_add_ar).strip()
        r["why_you"] = (r.get("why_you","") + " ØªØ­Ø¨ Ø§Ù„Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ø°ÙƒÙŠ ÙˆØ¥Ø®ÙØ§Ø¡ Ù†ÙˆØ§ÙŠØ§Ùƒ Ø­ØªÙ‰ Ø§Ù„Ù„Ø­Ø¸Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.").strip()
    else:
        r["what_it_looks_like"] = (r.get("what_it_looks_like","") + tacky_add_en).strip()
        r["why_you"] = (r.get("why_you","") + " You like smart brevity and hiding intent until the decisive beat.").strip()
    return r

def _ensure_unique_labels_v_global(recs: List[Dict[str, Any]], lang: str, bl: dict) -> List[Dict[str, Any]]:
    used_now = set()
    out = []
    for r in recs:
        r = dict(r or {})
        label = r.get("sport_label") or ""
        if _is_forbidden_generic(label) or not label.strip():
            label = "ØªÙƒØªÙŠÙƒÙŠ ØªØ®ÙÙ‘ÙŠ" if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Tactical Stealth"
            r["sport_label"] = label

        salt = 0
        while _bl_has(bl, label) or _canon_label(label) in used_now:
            label = _generate_variant_label(label, lang, salt=salt)
            r = _perturb_phrasing(r, lang)
            salt += 1
        used_now.add(_canon_label(label))
        r["sport_label"] = label
        out.append(r)
    return out

def _persist_blacklist(recs: List[Dict[str, Any]], bl: dict) -> None:
    for r in recs:
        lab = r.get("sport_label") or ""
        if lab.strip():
            _bl_add(bl, lab, alias=lab)
    _save_json_atomic(BL_PATH, bl)

# ========= Prompt Builder (LLM) =========
def _style_seed(user_id: str, profile: Optional[Dict[str, Any]]) -> int:
    base = user_id or "anon"
    axes = profile.get("axes", {}) if isinstance(profile, dict) else {}
    s = f"{base}:{json.dumps(axes, sort_keys=True, ensure_ascii=False)}"
    h = hashlib.sha256(s.encode("utf-8")).hexdigest()
    return int(h[:8], 16)

def _compact_analysis_for_prompt(analysis: Dict[str, Any], profile: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    p_axes   = (profile or {}).get("axes", {})
    p_signals= (profile or {}).get("signals", [])
    hints    = (profile or {}).get("hints_for_prompt", "")
    out = {
        "silent_drivers": analysis.get("silent_drivers", []),
        "z_axes": analysis.get("z_axes", p_axes),
        "z_intent": analysis.get("z_intent", []),
        "encoded_profile": {"axes": p_axes, "signals": p_signals, "hints": _clip(str(hints), 300)},
    }
    blob = json.dumps(out, ensure_ascii=False)
    if len(blob) > MAX_PROMPT_CHARS // 2:
        out["encoded_profile"]["signals"] = out["encoded_profile"]["signals"][:10]
    return out

def _strip_code_fence(s: str) -> str:
    if not s: return s
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(?:json)?\s*", "", s)
        s = re.sub(r"\s*```$", "", s)
    return s

def _json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                 personality: Any, lang: str, style_seed: int) -> List[Dict[str, str]]:
    bullets = _answers_to_bullets(answers)
    persona = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)
    profile = analysis.get("encoded_profile") or {}
    compact_analysis = _compact_analysis_for_prompt(analysis, profile)

    comp_blob = json.dumps(compact_analysis, ensure_ascii=False)
    if len(comp_blob) > MAX_PROMPT_CHARS:
        compact_analysis = {"z_axes": compact_analysis.get("z_axes", {}), "z_intent": compact_analysis.get("z_intent", [])}

    axis = compact_analysis.get("z_axes", {})
    exp = _axes_expectations(axis, lang)
    exp_lines = []
    if exp:
        title = {"calm_adrenaline":"Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†","solo_group":"ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ","tech_intuition":"ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ"} \
                if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else \
                {"calm_adrenaline":"Calm/Adrenaline","solo_group":"Solo/Group","tech_intuition":"Technical/Intuitive"}
        for k, words in exp.items():
            if words:
                exp_lines.append(f"{title[k]}: {', '.join(words)}")
    axis_hint = ("\n".join(exp_lines)) if exp_lines else ""

    z_intent = compact_analysis.get("z_intent", [])
    intent_hint = ("ØŒ ".join(z_intent) if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else ", ".join(z_intent)) if z_intent else ""

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        sys = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ SportSync AI Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ù„Ø·ÙŠÙØ© (ØµØ¯ÙŠÙ‚ Ù…Ø­ØªØ±Ù).\n"
            "Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ± (Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±).\n"
            "Ø³ÙÙ…Ù‘Ù 'Ù‡ÙˆÙŠØ©/Ø±ÙŠØ§Ø¶Ø©' ÙˆØ§Ø¶Ø­Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©.\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
        usr = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Â«Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ§Ø¶Ø­Ø©Â». "
            "Ø£Ø¹ÙØ¯ JSON Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­: "
            "{\"recommendations\":[{"
            "\"sport_label\":\"...\",\"what_it_looks_like\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\"," 
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"win_condition\":\"...\"," 
            "\"core_skills\":[\"...\",\"...\"],\"mode\":\"Solo/Team\",\"variant_vr\":\"...\",\"variant_no_vr\":\"...\",\"difficulty\":1-5"
            "}]} "
            "Ù‚ÙˆØ§Ø¹Ø¯ Ø¥Ù„Ø²Ø§Ù…ÙŠØ©: Ø§Ø°ÙƒØ± win_condition Ùˆ 3â€“5 core_skills Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. "
            "Ø­Ø§Ø°Ù Z-axes Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù† Ø£Ù…ÙƒÙ†:\n" + axis_hint +
            ("\n\nâ€” Ù†ÙˆØ§ÙŠØ§ Z Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: " + intent_hint if intent_hint else "") + "\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{persona}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ¬Ø²:\n" + json.dumps(compact_analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©:\n" + bullets + "\n\n"
            f"â€” style_seed: {style_seed}\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
    else:
        sys = (
            "You are a warm, human SportSync coach. "
            "No time/cost/reps/sets/minutes/place. Name the sport/identity if clarity needs it. JSON only."
        )
        usr = (
            "Create THREE clear sport-like identities with required keys: "
            "{\"recommendations\":[{\"sport_label\":\"...\",\"what_it_looks_like\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\"," 
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"win_condition\":\"...\",\"core_skills\":[\"...\"]," 
            "\"mode\":\"Solo/Team\",\"variant_vr\":\"...\",\"variant_no_vr\":\"...\",\"difficulty\":1-5}]}"
            " Align with Z-axes using words:\n" + axis_hint +
            ( "\n\nâ€” Z intents: " + intent_hint if intent_hint else "" ) + "\n\n"
            f"â€” Coach persona:\n{persona}\nâ€” Compact analysis:\n" + json.dumps(compact_analysis, ensure_ascii=False) + "\n"
            "â€” Bulleted answers:\n" + bullets + f"\nâ€” style_seed: {style_seed}\nJSON only."
        )
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

def _parse_json(text: str) -> Optional[List[Dict[str, Any]]]:
    if not text:
        return None
    text = _strip_code_fence(text)
    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return recs
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}", text or "")
    if m:
        try:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return recs
        except Exception:
            pass
    return None

def _to_bullets(text_or_list: Any, max_items: int = 6) -> List[str]:
    if text_or_list is None:
        return []
    if isinstance(text_or_list, (list, tuple)):
        items = [str(i).strip(" -â€¢\t ") for i in text_or_list if str(i).strip()]
        return items[:max_items]
    text = str(text_or_list)
    raw = re.split(r"[;\n\.ØŒ]+", text)
    items = [i.strip(" -â€¢\t ") for i in raw if i.strip()]
    return items[:max_items]

def _one_liner(*parts: str, max_len: int = 140) -> str:
    s = " â€” ".join([p.strip() for p in parts if p and p.strip()])
    return s[:max_len]

def _format_card(rec: Dict[str, Any], i: int, lang: str) -> str:
    head_ar = ["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1","ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2","ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ğŸŸ¢ Recommendation 1","ğŸŒ¿ Recommendation 2","ğŸ”® Recommendation 3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[i]

    label = _norm_text(rec.get("sport_label") or "")
    scene = _norm_text(rec.get("what_it_looks_like") or rec.get("scene") or "")
    inner = _norm_text(rec.get("inner_sensation") or "")
    why   = _norm_text(rec.get("why_you") or "")
    week  = _to_bullets(rec.get("first_week") or "")
    prog  = _to_bullets(rec.get("progress_markers") or "", max_items=4)
    win   = _norm_text(rec.get("win_condition") or "")
    skills= rec.get("core_skills") or []
    diff  = rec.get("difficulty", 3)
    mode  = _norm_text(rec.get("mode") or "Solo")
    vr    = _norm_text(rec.get("variant_vr") or rec.get("vr_idea") or "")
    novr  = _norm_text(rec.get("variant_no_vr") or "")

    intro = _one_liner(scene, inner)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ùƒ: {label}")
        if intro: out += ["\nğŸ’¡ Ù…Ø§ Ù‡ÙŠØŸ", f"- {intro}"]
        if why:
            out += ["\nğŸ® Ù„ÙŠÙ‡ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ"]
            for b in _to_bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Ù…Ù‡Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©:"]
            for s in [ _norm_text(x) for x in skills[:5] ]: out.append(f"- {s}")
        if win: out += ["\nğŸ ÙƒÙŠÙ ØªÙÙˆØ²ØŸ", f"- {win}"]
        if week:
            out += ["\nğŸš€ Ø£ÙˆÙ„ Ø£Ø³Ø¨ÙˆØ¹ (Ù†ÙˆØ¹ÙŠ):"]
            for b in week: out.append(f"- {b}")
        if prog:
            out += ["\nâœ… Ø¹Ù„Ø§Ù…Ø§Øª ØªÙ‚Ø¯Ù… Ù…Ø­Ø³ÙˆØ³Ø©:"]
            for b in prog: out.append(f"- {b}")
        notes = []
        if mode: notes.append(("ÙˆØ¶Ø¹ Ø§Ù„Ù„Ø¹Ø¨: " + mode))
        if novr: notes.append("Ø¨Ø¯ÙˆÙ† VR: " + novr)
        if vr: notes.append("VR (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): " + vr)
        if notes:
            out += ["\nğŸ‘â€ğŸ—¨ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:", f"- " + "\n- ".join(notes)]
        out.append(f"\nØ§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: {diff}/5")
        return "\n".join(out)

    else:
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ideal identity: {label}")
        if intro: out += ["\nğŸ’¡ What is it?", f"- {intro}"]
        if why:
            out += ["\nğŸ® Why you"]
            for b in _to_bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Core skills:"]
            for s in [ _norm_text(x) for x in skills[:5] ]: out.append(f"- {s}")
        if win: out += ["\nğŸ Win condition", f"- {win}"]
        if week:
            out += ["\nğŸš€ First week (qualitative)"]
            for b in week: out.append(f"- {b}")
        if prog:
            out += ["\nâœ… Progress cues"]
            for b in prog: out.append(f"- {b}")
        notes = []
        if mode: notes.append(("Mode: " + mode))
        if novr: notes.append("No-VR: " + novr)
        if vr: notes.append("VR (optional): " + vr)
        if notes:
            out += ["\nğŸ‘â€ğŸ—¨ Notes:", f"- " + "\n- ".join(notes)]
        out.append(f"\nApprox level: {diff}/5")
        return "\n".join(out)
    else:
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ideal identity: {label}")
        if intro: out += ["\nğŸ’¡ What is it?", f"- {intro}"]
        if why:
            out += ["\nğŸ® Why you"]
            for b in _to_bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Core skills:"]
            for s in skills[:5]: out.append(f"- {s}")
        if win: out += ["\nğŸ Win condition", f"- {win}"]
        if week:
            out += ["\nğŸš€ First week (qualitative)"]
            for b in week: out.append(f"- {b}")
        if prog:
            out += ["\nâœ… Progress cues"]
            for b in prog: out.append(f"- {b}")
        notes = []
        if mode: notes.append(("Mode: " + mode))
        if novr: notes.append("No-VR: " + novr)
        if vr: notes.append("VR (optional): " + vr)
        if notes:
            out += ["\nğŸ‘â€ğŸ—¨ Notes:", f"- " + "\n- ".join(notes)]
        out.append(f"\nApprox level: {diff}/5")
        return "\n".join(out)

def _sanitize_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    """
    ØªÙ†Ø¸Ù‘Ù ÙˆØªÙƒÙ…Ù‘Ù„ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ù…Ù† Ø§Ù„Ù€KB Ø£Ùˆ Ø§Ù„Ù€LLM ÙˆØªÙ…Ù†Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù†Ø§ØªØ¬Ø© Ù…Ù†
    ÙˆØ¬ÙˆØ¯ Ù‚ÙˆØ§Ø¦Ù…/Ø¯ÙŠÙƒØ´Ù†Ø±ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù†ØµÙŠØ©.
    """
    temp: List[Dict[str, Any]] = []
    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        r = _fill_defaults(_sanitize_record(r), lang)

        # ØªØ£ÙƒØ¯ Ø£Ù† ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… Ù†ØµÙˆØµ Ù‚Ø¨Ù„ Ø§Ù„Ù€ join
        vals = [
            _norm_text(r.get("sport_label","")),
            _norm_text(r.get("what_it_looks_like","")),
            _norm_text(r.get("why_you","")),
            _norm_text(r.get("first_week","")),
            _norm_text(r.get("progress_markers","")),
            _norm_text(r.get("win_condition","")),
        ]
        blob = " ".join(vals)

        if _too_generic(blob, _MIN_CHARS) or not _has_sensory(blob) or not _is_meaningful(r) \
           or (_REQUIRE_WIN and not r.get("win_condition")) \
           or len(r.get("core_skills") or []) < _MIN_CORE_SKILLS \
           or _label_is_generic(r.get("sport_label","")):
            r = _fallback_identity(i, lang)

        temp.append(r)

    return _hard_dedupe_and_fill(temp, lang)

# ========= OpenAI helper with timeout + retry =========
def _chat_with_retry(messages: List[Dict[str, str]], max_tokens: int, temperature: float) -> str:
    """
    ÙŠÙ†ÙÙ‘Ø° Ù…ÙƒØ§Ù„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø¹ Ù…Ù‡Ù„Ø© REC_BUDGET_S ÙˆØ±ÙŠØªØ±Ø§ÛŒ Ø°ÙƒÙŠ (ØªÙ‚Ù„ÙŠØµ Ø§Ù„ØªÙˆÙƒÙ†Ø² + Ù…ÙˆØ¯ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ).
    """
    if OpenAI_CLIENT is None:
        raise RuntimeError("OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·")

    attempts = 4 if not REC_FAST_MODE else 3
    last_err = None
    model_local = CHAT_MODEL
    max_tokens_local = max_tokens

    timeout_s = max(4.0, min(REC_BUDGET_S, 26.0))
    client = OpenAI_CLIENT.with_options(timeout=timeout_s)

    for i in range(1, attempts + 1):
        try:
            resp = client.chat.completions.create(
                model=model_local,
                messages=messages,
                temperature=temperature,
                top_p=0.9,
                presence_penalty=0.15,
                frequency_penalty=0.1,
                max_tokens=max_tokens_local
            )
            return (resp.choices[0].message.content or "").strip()
        except Exception as e:
            last_err = e
            es = (str(e) or "").lower()
            if any(t in es for t in ["timeout", "rate limit", "overloaded", "503", "504", "gateway", "temporar"]):
                sleep(min(1.2 * i, 2.5))
                max_tokens_local = max(256, int(max_tokens_local * 0.75))
                if i == attempts - 1 and model_local != CHAT_MODEL_FALLBACK:
                    model_local = CHAT_MODEL_FALLBACK
                continue
            break
    raise RuntimeError(f"LLM call failed after retries: {last_err}")

# ========= PUBLIC API =========
def generate_sport_recommendation(answers: Dict[str, Any],
                                  lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                                  user_id: str = "N/A",
                                  job_id: str = "") -> List[str]:
    t0 = perf_counter()

    # âœ… ÙƒØ§Ø´
    try:
        cached_cards = get_cached_recommendation(user_id, answers, lang)
    except TypeError:
        try:
            cached_cards = get_cached_recommendation(user_id)  # type: ignore
        except Exception:
            cached_cards = None
    if cached_cards:
        _dbg("cache HIT for recommendations")
        return cached_cards
    _dbg("cache MISS for recommendations")

    # Evidence Gate
    eg = _run_egate(answers or {}, lang=lang)
    if _PIPE:
        try:
            _PIPE.send(
                event_type="egate_decision",
                payload={
                    "status": eg.get("status"),
                    "answered": eg.get("answered"),
                    "total_chars": eg.get("total_chars"),
                    "required_missing": eg.get("required_keys", []) or eg.get("required_missing", []),
                    "job_id": job_id
                },
                user_id=user_id, lang=("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "English"),
                model=CHAT_MODEL
            )
        except Exception:
            pass

    if eg.get("status") != "pass":
        card = _format_followup_card(eg.get("followup_questions", []), lang=lang)
        try:
            sec = (CFG.get("security") or {})
            if sec.get("scrub_urls", True):
                card = scrub_unknown_urls(card, CFG)
        except Exception:
            pass
        return [card, "â€”", "â€”"]

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + Ø·Ø¨Ù‚Ø© Z + Intent + profile
    analysis: Dict[str, Any] = _call_analyze_user_from_answers(user_id, answers, lang)
    try:
        analysis["silent_drivers"] = analyze_silent_drivers(answers, lang=lang) or []
    except Exception:
        analysis["silent_drivers"] = []
    try:
        z_intent = _call_analyze_intent(answers, lang=lang) or []
        if z_intent: analysis["z_intent"] = z_intent
    except Exception:
        pass
    profile = _extract_profile(answers, lang)
    if profile:
        analysis["encoded_profile"] = profile
        if "axes" in profile: analysis["z_axes"] = profile["axes"]
        if "scores" in profile: analysis["z_scores"] = profile["scores"]

    # ======== KB-first (priors + trait_links + guards + templates) ========
    user_axes = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}
    user_signals = _extract_signals(answers, lang)

    # (A) identities Ù…Ù† KB Ø¥Ù† ÙˆØ¬Ø¯Øª
    kb_recs = _pick_kb_recommendations(user_axes, user_signals, lang)

    # (B) Ø¥Ù† Ù„Ù… ØªÙƒÙÙØŒ Ø§Ø³ØªØ®Ø¯Ù… trait_links
    if len(kb_recs) < 3 and (KB_PRIORS or TRAIT_LINKS):
        trait_strengths = _derive_binary_traits(analysis, answers, lang)
        ranked = _score_candidates_from_links(trait_strengths)

        picked: List[Dict[str, Any]] = []
        used = set()
        for _, lbl in ranked:
            if len(picked) >= 3: break
            c = _canon_label(lbl)
            if c in used: continue
            tpl = _template_for_label(lbl, lang)
            if not tpl:
                tpl = _fallback_identity(len(picked), lang)  # ÙƒØ­Ù„Ù‘ Ø£Ø®ÙŠØ± Ø¯Ø§Ø®Ù„ Ù…Ø³Ø§Ø± KB
            picked.append(tpl)
            used.add(c)
        kb_recs.extend(picked)
        kb_recs = kb_recs[:3]

    if len(kb_recs) >= 3:
        kb_recs = _sanitize_fill(kb_recs, lang)
        bl = _load_blacklist()
        kb_recs = _ensure_unique_labels_v_global(kb_recs, lang, bl)
        _persist_blacklist(kb_recs, bl)
        cards = [_format_card(kb_recs[i], i, lang) for i in range(3)]
        try:
            sec = (CFG.get("security") or {})
            if sec.get("scrub_urls", True):
                cards = [scrub_unknown_urls(c, CFG) for c in cards]
        except Exception:
            pass
        try:
            log_user_insight(
                user_id=user_id,
                content={
                    "language": lang,
                    "answers": {k: v for k, v in (answers or {}).items() if k != "profile"},
                    "analysis": analysis,
                    "source": "KB/trait_links" if (KB_PRIORS or TRAIT_LINKS) else "KB",
                    "seed": _style_seed(user_id, profile or {}),
                    "elapsed_s": round(perf_counter() - t0, 3),
                    "fast_mode": REC_FAST_MODE,
                    "job_id": job_id
                },
                event_type="kb_recommendation"
            )
        except Exception:
            pass
        try:
            save_cached_recommendation(user_id, answers, lang, cards)
        except Exception:
            pass
        return cards

       # ======== LLM ÙƒØ¢Ø®Ø± Ø®ÙŠØ§Ø± ========
    # Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ø¹Ù…ÙŠÙ„ LLMØŒ Ø±Ø¬Ù‘Ø¹ Ø±Ø³Ø§Ù„Ø© ØªØ´Ø®ÙŠØµ ÙˆØ§Ø¶Ø­Ø©
    if OpenAI_CLIENT is None:
        _dbg("[LLM] client=None -> fallback card")
        return [
            "âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†. Ø«Ø¨Ù‘Øª OPENAI_API_KEY (Ø£Ùˆ OPENROUTER_API_KEY/AZURE_OPENAI_API_KEY) Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù… ÙˆØ£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„.",
            "â€”",
            "â€”"
        ]

    # Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ (ÙƒØ§Ø´)
    persona = get_cached_personality(analysis, lang=lang)
    if not persona:
        persona = {
            "name":"SportSync Coach",
            "tone":"Ø­Ø§Ø²Ù…-Ù‡Ø§Ø¯Ø¦",
            "style":"Ø­Ø³Ù‘ÙŠ ÙˆØ§Ù‚Ø¹ÙŠ Ø¥Ù†Ø³Ø§Ù†ÙŠ",
            "philosophy":"Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø¹ ÙˆØ¶ÙˆØ­ Ù‡ÙˆÙŠÙ‘Ø©"
        }
        try:
            save_cached_personality(analysis, persona, lang=lang)
        except Exception:
            pass

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª ÙˆØ§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    seed = _style_seed(user_id, profile or {})
    msgs = _json_prompt(analysis, answers, persona, lang, seed)
    max_toks_1 = 800 if REC_FAST_MODE else 1200

    try:
        _dbg("calling LLM - round #1")
        raw1 = _chat_with_retry(messages=msgs, max_tokens=max_toks_1, temperature=0.5)
        _dbg(f"round #1 ok, len={len(raw1)}")
    except Exception as e:
        # Ø±Ø³Ø§Ù„Ø© ØªØ´Ø®ÙŠØµÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø§Ù„ÙƒØ±Øª Ø§Ù„Ø£ÙˆÙ„
        err = f"âŒ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}"
        _dbg(f"[LLM] error round #1 -> {e}")
        if _PIPE:
            try:
                _PIPE.send("model_error", {"error": str(e), "job_id": job_id},
                           user_id=user_id, lang=lang, model=CHAT_MODEL)
            except Exception:
                pass
        return [err, "â€”", "â€”"]

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø«Ù… Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ€ JSON
    raw1 = _strip_code_fence(raw1)
    if not ALLOW_SPORT_NAMES and _contains_blocked_name(raw1):
        raw1 = _mask_names(raw1)
    parsed = _parse_json(raw1) or []
    cleaned = _sanitize_fill(parsed, lang)

    # Ù†Ù‚Ø±Ø± Ù‡Ù„ Ù†Ø­ØªØ§Ø¬ Ø¬ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­
    elapsed = perf_counter() - t0
    time_left = REC_BUDGET_S - elapsed
    axes = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}

    mismatch_axes = any(_mismatch_with_axes(rec, axes, lang) for rec in cleaned)
    need_repair_generic = any(
        _too_generic(
            " ".join([_norm_text(c.get("what_it_looks_like","")),
                      _norm_text(c.get("why_you",""))]),
            _MIN_CHARS
        ) for c in cleaned
    )
    missing_fields = any(
        ((_REQUIRE_WIN and not c.get("win_condition"))
         or len(c.get("core_skills") or []) < _MIN_CORE_SKILLS)
        for c in cleaned
    )
    need_repair = (mismatch_axes or need_repair_generic or missing_fields) \
                  and REC_REPAIR_ENABLED and (time_left >= (6 if not REC_FAST_MODE else 4))

    if need_repair:
        exp = _axes_expectations(axes or {}, lang)
        align_hint = ""
        if exp:
            if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                align_hint = (
                    "Ø­Ø§Ø°Ù Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù…Ø¹ Ù…Ø­Ø§ÙˆØ± Z:\n"
                    f"- Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ: {', '.join(exp.get('solo_group', []))}\n"
                    f"- ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ: {', '.join(exp.get('tech_intuition', []))}\n"
                )
            else:
                align_hint = (
                    "Align with Z-axes:\n"
                    f"- Calm/Adrenaline: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- Solo/Group: {', '.join(exp.get('solo_group', []))}\n"
                    f"- Technical/Intuitive: {', '.join(exp.get('tech_intuition', []))}\n"
                )
        repair_prompt = {
            "role":"user",
            "content":(
                ("Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© ÙˆÙˆØ§Ø¶Ø­Ø© (Ø§Ø³Ù… Ø±ÙŠØ§Ø¶Ø© Ù…Ø³Ù…ÙˆØ­). " if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                 else "Rewrite with a warm, human tone (sport names allowed). ")
                + "ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯: sport_label, what_it_looks_like, win_condition, 3â€“5 core_skills, mode, variant_vr, variant_no_vr. "
                + "Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±. "
                + "Ø­Ø³Ù‘Ù† Ù…Ø­Ø§Ø°Ø§Ø© Z-axes. JSON ÙÙ‚Ø·.\n\n" + align_hint
            )
        }
        try:
            _dbg("calling LLM - round #2 (repair)")
            raw2 = _chat_with_retry(
                messages=msgs + [{"role":"assistant","content":raw1}, repair_prompt],
                max_tokens=(650 if REC_FAST_MODE else 950),
                temperature=0.55
            )
            raw2 = _strip_code_fence(raw2)
            if not ALLOW_SPORT_NAMES and _contains_blocked_name(raw2):
                raw2 = _mask_names(raw2)
            parsed2 = _parse_json(raw2) or []
            cleaned2 = _sanitize_fill(parsed2, lang)

            def score(r: Dict[str,Any]) -> int:
                txt = " ".join([
                    _norm_text(r.get("sport_label","")),
                    _norm_text(r.get("what_it_looks_like","")),
                    _norm_text(r.get("inner_sensation","")),
                    _norm_text(r.get("why_you","")),
                    _norm_text(r.get("first_week","")),
                    _norm_text(r.get("win_condition",""))
                ])
                bonus = 5 * len(r.get("core_skills") or [])
                return len(txt) + bonus

            if sum(map(score, cleaned2)) > sum(map(score, cleaned)):
                cleaned = cleaned2
                _dbg("repair improved result")
        except Exception as e:
            _dbg(f"repair skipped due to error: {e}")

    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ + Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ùƒ Ù„ÙØ³Øª
    bl = _load_blacklist()
    cleaned = _ensure_unique_labels_v_global(cleaned, lang, bl)
    _persist_blacklist(cleaned, bl)

       # ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ù†ØµÙŠØ©
    cards = [_format_card(cleaned[i], i, lang) for i in range(3)]

    # ØªÙ†Ø¸ÙŠÙ Ø£ÙŠ Ø±ÙˆØ§Ø¨Ø· ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© (Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)
    try:
        sec = (CFG.get("security") or {})
        if sec.get("scrub_urls", True):
            cards = [scrub_unknown_urls(c, CFG) for c in cards]
    except Exception:
        pass

    # âœ… Ø­Ø§Ø±Ø³ Ø£Ø®ÙŠØ±: ØªØ£ÙƒØ¯ Ø£Ù† ÙƒÙ„ Ø¨Ø·Ø§Ù‚Ø© Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù†Øµ (ÙˆÙ„ÙŠØ³ list Ø£Ùˆ dict)
    try:
        cards = [_norm_text(c) for c in cards]
    except Exception:
        safe_cards: List[str] = []
        for c in cards:
            try:
                safe_cards.append(_norm_text(c))
            except Exception:
                safe_cards.append(str(c))
        cards = safe_cards

    # (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„ÙˆØ¬ ØªØ´Ø®ÙŠØµÙŠ Ù„Ùˆ ÙØ¹Ù‘Ù„Øª REC_DEBUG=1
    _dbg(f"[CARDS TYPES] { [type(c).__name__ for c in cards] }")

    # Ù„ÙˆØ¬ Ø¬ÙˆØ¯Ø© Ø¯Ø§Ø®Ù„ÙŠ (ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ cleanedØŒ Ù…Ùˆ Ø¹Ù„Ù‰ cards)
    axes = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}
    quality_flags = {
        "generic": any(_too_generic(
            " ".join([_norm_text(c.get("what_it_looks_like","")),
                      _norm_text(c.get("why_you",""))]),
            _MIN_CHARS) for c in cleaned),
        "low_sensory": any(not _has_sensory(
            " ".join([_norm_text(c.get("what_it_looks_like","")),
                      _norm_text(c.get("inner_sensation",""))])) for c in cleaned),
        "mismatch_axes": any(_mismatch_with_axes(c, axes, lang) for c in cleaned),
        "missing_fields": any(((_REQUIRE_WIN and not c.get("win_condition"))
                               or len(c.get("core_skills") or []) < _MIN_CORE_SKILLS) for c in cleaned)
    }

    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang,
                "answers": {k: v for k, v in (answers or {}).items() if k != "profile"},
                "analysis": analysis,
                "recommendations": cleaned,
                "quality_flags": quality_flags,
                "seed": seed,
                "elapsed_s": round(perf_counter() - t0, 3),
                "fast_mode": REC_FAST_MODE,
                "job_id": job_id
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    try:
        save_cached_recommendation(user_id, answers, lang, cards)
    except Exception:
        pass

    return cards
