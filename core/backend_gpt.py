# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
ØªÙˆØµÙŠØ§Øª "Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡" Ø¨Ø«Ù„Ø§Ø« ÙƒØ±ÙˆØª Ø­Ø³Ù‘ÙŠØ© Ù…Ù†Ø¸Ù…Ø© + Ø·Ø¨Ù‚Ø© Z + Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ (Ù†ÙˆØ¹ÙŠØ© ÙÙ‚Ø·) + ÙÙƒØ±Ø© VR.
- Ù„Ø§ Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ© ÙˆÙ„Ø§ Ø¹Ø¯Ù‘Ø§Øª/Ø¬ÙˆÙ„Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.
- ÙŠØ­Ø§ÙˆÙ„ Ù…Ø±ØªÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ù€ fallback. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/English.
"""

from __future__ import annotations

import os, json, re
from typing import Any, Dict, List, Optional

# ========= OpenAI =========
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø£Ø¶Ù Ø§Ù„Ø­Ø²Ù…Ø© ÙÙŠ requirements: openai>=1.6.1,<2") from e

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OpenAI_CLIENT = None
else:
    OpenAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o")  # Ø¨Ø¯Ù‘Ù„ Ø¥Ù„Ù‰ gpt-4o-mini Ù„ØªÙƒÙ„ÙØ© Ø£Ù‚Ù„

# ========= Project imports (with safe fallbacks) =========
try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: {list(content.keys())}")

try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

try:
    from core.user_analysis import analyze_user_from_answers
except Exception:
    def analyze_user_from_answers(answers: Dict[str, Any]) -> Dict[str, Any]:
        return {"quick_profile": "fallback", "raw_answers": answers}

# Layer Z Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ ÙÙŠ core Ø£Ùˆ analysis
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
            return ["Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±", "ØªÙØ¶ÙŠÙ„ ØªØ­Ø¯Ù‘ÙŠ Ø°Ù‡Ù†ÙŠ"]

# ========= (Ø¬Ø¯ÙŠØ¯) Ù…ÙØ´ÙÙ‘ÙØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) =========
def _extract_profile(answers: Dict[str, Any], lang: str) -> Optional[Dict[str, Any]]:
    """
    ÙŠØ¹ÙŠØ¯ Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ù…ÙØ´ÙÙ‘ÙŽØ± Ø¥Ù† ÙˆÙØ¬Ø¯ ÙÙŠ answers ØªØ­Øª Ø§Ù„Ù…ÙØªØ§Ø­ "profile"ØŒ
    Ø£Ùˆ ÙŠØ­Ø§ÙˆÙ„ ØªÙˆÙ„ÙŠØ¯Ù‡ Ø¹Ø¨Ø± core.answers_encoder.encode_answers (Ø¥Ù† ØªÙˆÙÙ‘Ø±).
    ÙŠÙØ±Ø¬ÙØ¹ None Ù„Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­.
    """
    prof = answers.get("profile")
    if isinstance(prof, dict):
        return prof

    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙˆÙ„ÙŠØ¯ Ø³Ø±ÙŠØ¹
    encode_answers = None
    try:
        from core.answers_encoder import encode_answers as _enc
        encode_answers = _enc
    except Exception:
        try:
            from analysis.answers_encoder import encode_answers as _enc
            encode_answers = _enc
        except Exception:
            encode_answers = None

    if encode_answers is None:
        return None

    try:
        enc = encode_answers(answers, lang=lang)
        preferences = enc.get("prefs", enc.get("preferences", {}))
        z_markers = enc.get("z_markers", [])
        signals   = enc.get("signals", [])
        hints = " | ".join([*z_markers, *signals])[:1000]  # Ù†Øµ Ù…ÙˆØ¬Ø² Ù„Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª

        return {
            "scores": enc.get("scores", {}),
            "axes": enc.get("axes", {}),
            "preferences": preferences,
            "hints_for_prompt": hints,
            "vr_inclination": enc.get("vr_inclination", 0),
            "confidence": enc.get("confidence", 0.0),
        }
    except Exception:
        return None

# ========= Rules & helpers =========
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_AVOID_GENERIC = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]
_SENSORY = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªØ±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

# ÙƒÙ„Ù…Ø§Øª/Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¸ÙˆØ±Ø© (Ø£Ø±Ù‚Ø§Ù… Ø²Ù…Ù†/Ø¹Ø¯Ù‘Ø§Øª/ØªÙƒÙ„ÙØ©/Ù…ÙƒØ§Ù† Ù…Ø¨Ø§Ø´Ø±)
_NUM_TIME_COST_PAT = re.compile(
    r"(\b\d+(\.\d+)?\b|\b\d+\s*(min|mins|minute|minutes|second|seconds|hour|hours|Ø¬ÙˆÙ„Ø©|Ø¬ÙˆÙ„Ø§Øª|Ø¹Ø¯Ø©|Ø¹Ø¯Ø§Øª|Ø¯Ù‚ÙŠÙ‚Ø©|Ø¯Ù‚Ø§Ø¦Ù‚|Ø³Ø§Ø¹Ø©|Ø³Ø§Ø¹Ø§Øª)\b|"
    r"ØªÙƒÙ„ÙØ©|cost|budget|Ø±ÙŠØ§Ù„|Ø¯ÙˆÙ„Ø§Ø±|$|â‚¬|Ù…ÙƒØ§Ù†|near home|Ø¨Ø§Ù„Ø¨ÙŠØª|ÙÙŠ Ø§Ù„Ù†Ø§Ø¯ÙŠ|ÙÙŠ Ø§Ù„Ø¬ÙŠÙ…)",
    re.IGNORECASE
)

def _mask_names(t: str) -> str: return _name_re.sub("â€”", t or "")
def _violates(t: str) -> bool:   return bool(_name_re.search(t or ""))

def _answers_to_bullets(answers: Dict[str, Any]) -> str:
    out = []
    for k, v in (answers or {}).items():
        if k == "profile":
            continue
        if isinstance(v, dict):
            q, a = v.get("question", k), v.get("answer", "")
        else:
            q, a = str(k), v
        if isinstance(a, list): a = ", ".join(map(str, a))
        out.append(f"- {q}: {a}")
    return "\n".join(out)

def _too_generic(text: str, min_chars: int = 280) -> bool:
    t = (text or "").strip()
    return len(t) < min_chars or any(p in t for p in _AVOID_GENERIC)

def _has_sensory(text: str, min_hits: int = 3) -> bool:
    return sum(1 for w in _SENSORY if w in (text or "")) >= min_hits

def _is_meaningful(rec: Dict[str, Any]) -> bool:
    blob = " ".join([
        rec.get("scene",""), rec.get("inner_sensation",""),
        rec.get("why_you",""), rec.get("first_week",""),
        rec.get("progress_markers","")
    ]).strip()
    return len(blob) >= 80

def _strip_forbidden(text: str) -> str:
    """ÙŠØ²ÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ¯Ù‚Ø§Ø¦Ù‚/Ø¬ÙˆÙ„Ø§Øª/ØªÙƒÙ„ÙØ©/Ù…ÙƒØ§Ù† Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù†Øµ."""
    if not text: return text
    return _NUM_TIME_COST_PAT.sub("", text)

def _sanitize_record(r: Dict[str, Any]) -> Dict[str, Any]:
    """ÙŠÙ†Ø¸Ù‘Ù Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªÙˆØµÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø§Øª ÙˆÙŠØ´ÙŠÙ„ practical_fit Ø¥Ù† ÙˆÙØ¬Ø¯."""
    r = dict(r or {})
    r.pop("practical_fit", None)  # Ø­Ø°Ù Ø§Ù„Ø­Ù‚Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„

    for k in ("scene","inner_sensation","why_you","first_week","progress_markers","vr_idea"):
        if isinstance(r.get(k), str):
            r[k] = _strip_forbidden(_mask_names(r[k].strip()))
    # Ø¶Ø¨Ø· Ø§Ù„ØµØ¹ÙˆØ¨Ø© Ø¶Ù…Ù† 1..5
    try:
        d = int(r.get("difficulty", 3))
        r["difficulty"] = max(1, min(5, d))
    except Exception:
        r["difficulty"] = 3
    return r

def _fallback_identity(i: int, lang: str) -> Dict[str, Any]:
    """ÙÙˆÙ„Ø¨Ø§Ùƒ Ø¨Ù„Ø§ Ø£Ø±Ù‚Ø§Ù… ÙˆÙ„Ø§ Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ©."""
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        presets = [
            {
                "scene":"Ù…Ø³Ø§Ø­Ø© Ù…ÙØªÙˆØ­Ø© Ø¨Ø¥Ø­Ø³Ø§Ø³ Ø§Ù†Ø³ÙŠØ§Ø¨ÙŠ ÙˆØªØºÙŠÙ‘Ø± Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„Ø³Ø·Ø­.",
                "inner_sensation":"Ø¯ÙØ¡ ØªØ¯Ø±ÙŠØ¬ÙŠ ÙˆÙˆØ¶ÙˆØ­ Ø°Ù‡Ù†ÙŠ Ù‡Ø§Ø¯Ø¦.",
                "why_you":"ØªØ­Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù‘Ù… Ø§Ù„Ø³Ù„Ø³ Ø¨Ù„Ø§ Ø±ØªØ§Ø¨Ø© ÙˆØªØ¨Ø­Ø« Ø¹Ù† Ø³ÙŠØ·Ø±Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ø³ÙŠØ·Ø©.",
                "first_week":"Ø§Ø¨Ø¯Ø£ Ø¨Ø­Ø±ÙƒØ§Øª ØªÙØªØ­ Ø§Ù„Ù†ÙØ³ ÙˆØªØ¨Ù†ÙŠ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹. Ø²ÙØ¯ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø­Ø±ÙƒØ© ÙˆÙÙ‚ Ø¥Ø­Ø³Ø§Ø³Ùƒ.",
                "progress_markers":"ØªÙ†ÙÙ‘Ø³ Ø£Ù‡Ø¯Ø£ØŒ ØµÙØ§Ø¡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ø±ØºØ¨Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.",
                "difficulty":2,
                "vr_idea":"Ù†Ø³Ø®Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø®ÙÙŠÙØ© ØªÙØ¨Ø±Ø² Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆØ§Ù„ØªØªØ¨Ø¹."
            },
            {
                "scene":"Ù…Ø³Ø§Ø­Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ØªØ³Ù…Ø­ Ø¨Ø­Ø±ÙƒØ© Ù…ØªÙ†Ø§ØºÙ…Ø© Ù„Ù„Ø¬Ø°Ø¹ ÙˆØ§Ù„Ø°Ø±Ø§Ø¹ÙŠÙ†.",
                "inner_sensation":"Ø­Ø±Ø§Ø±Ø© Ù„Ø·ÙŠÙØ© Ù…Ø¹ Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø§Ù„ØªÙ…Ø§Ø³Ùƒ ÙÙŠ Ø§Ù„ÙˆØ³Ø·.",
                "why_you":"ØªØ­Ø¨ ØªÙ‚Ø¯Ù‘Ù… ÙˆØ§Ø¶Ø­ ÙˆÙ‚Ø§Ø¨Ù„ Ù„Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø¯ÙˆÙ† ØªØ¹Ù‚ÙŠØ¯.",
                "first_week":"Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø­Ø±ÙƒØ§Øª ØªÙØ´ØºÙ‘Ù„ Ø§Ù„Ø¬Ø°Ø¹ ÙˆØªÙØ´Ø¹Ø± Ø¨Ø§Ù„Ø«Ø¨Ø§Øª. Ù„Ø§Ø­Ø¸ Ø­Ø§Ù„ØªÙƒ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯.",
                "progress_markers":"Ø¥Ø­Ø³Ø§Ø³ Ø£Ù‚ÙˆÙ‰ Ø¨Ø§Ù„Ø«Ø¨Ø§ØªØŒ Ù†ÙˆÙ… Ø£Ø¹Ù…Ù‚ØŒ Ø·Ø§Ù‚Ø© Ø£Ù‡Ø¯Ø£ Ø®Ù„Ø§Ù„ Ø§Ù„ÙŠÙˆÙ….",
                "difficulty":3,
                "vr_idea":"Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆØ§Ø²Ù† Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„ØªÙ…Ø±ÙƒØ²."
            },
            {
                "scene":"Ù…ÙƒØ§Ù† Ù‡Ø§Ø¯Ø¦ Ù…Ø¹ Ù…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ© ÙˆØ§Ø³Ø¹ ÙˆØ­Ø±ÙƒØ© ÙˆØ§Ø¹ÙŠØ© Ø¨Ø·ÙŠØ¦Ø©.",
                "inner_sensation":"ØªÙ‡Ø¯Ø¦Ø© Ø¹ØµØ¨ÙŠØ© ÙˆØ¥Ø·Ø§Ù„Ø© Ù…Ø±ÙŠØ­Ø© Ù„Ù„Ù…ÙØ§ØµÙ„.",
                "why_you":"ØªØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ø´Ø¹ÙˆØ±ÙŠ ØªØ±ÙØ¹ ØªÙ‚Ø¨Ù‘Ù„ Ø§Ù„Ø¬Ù‡Ø¯ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§.",
                "first_week":"Ø­Ø±Ù‘Ùƒ Ø¨Ø¨Ø·Ø¡ Ù…Ø¹ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù†ÙØ³ Ø«Ù… Ø£Ø¶Ù ØªÙ…Ø¯ÙŠØ¯Ø§Øª Ù…Ø±Ù†Ø© Ø­Ø³Ø¨ Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨ Ø¬Ø³Ø¯Ùƒ.",
                "progress_markers":"ØªÙˆØªØ± Ø£Ù‚Ù„ ÙÙŠ Ø§Ù„Ø±Ù‚Ø¨Ø©/Ø§Ù„ÙÙƒØŒ ØªØ±ÙƒÙŠØ² Ø£ÙˆØ¶Ø­ØŒ ØªÙˆØ§Ø²Ù† Ø£ÙØ¶Ù„.",
                "difficulty":1,
                "vr_idea":"Ø¬Ù„Ø³Ø© Ø·Ø¨ÙŠØ¹Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø§Ø³ØªØ±Ø®Ø§Ø¡ Ø§Ù„Ø°Ù‡Ù†ÙŠ."
            }
        ]
    else:
        presets = [
            {
                "scene":"Open area with gentle flow and slight surface variation.",
                "inner_sensation":"Warm build-up with calm clarity.",
                "why_you":"You like smooth progress without boredom and value inner control.",
                "first_week":"Use easy movements that open your breath; explore flow by feel.",
                "progress_markers":"Calmer breath, post-session clarity, natural urge to continue.",
                "difficulty":2,
                "vr_idea":"Light rhythm/tracking VR variant."
            },
            {
                "scene":"Simple indoor space allowing rhythmic trunk and arm flow.",
                "inner_sensation":"Gentle heat with a centered core.",
                "why_you":"You want clear, noticeable progress without complexity.",
                "first_week":"Pick movements that engage the core and build stability. Note before/after.",
                "progress_markers":"Stronger stability, deeper sleep, steadier energy.",
                "difficulty":3,
                "vr_idea":"Simple balance VR to reinforce centering."
            },
            {
                "scene":"Quiet space with wide field of view and slow mindful motion.",
                "inner_sensation":"Neural calm and comfortable decompression.",
                "why_you":"You need a gentle reset that raises tolerance for effort over time.",
                "first_week":"Move slowly while tracking breath; add elastic stretches as feels right.",
                "progress_markers":"Less neck/jaw tension, clearer focus, better balance.",
                "difficulty":1,
                "vr_idea":"Immersive nature-relax session."
            }
        ]
    return presets[i % 3]

def _json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                 personality: Any, lang: str) -> List[Dict[str, str]]:
    bullets = _answers_to_bullets(answers)
    persona = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)

    # (Ø¬Ø¯ÙŠØ¯) Ø­ÙˆØ§ÙØ² Ø§Ù„Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ù…ÙØ´ÙÙ‘ÙŽØ± Ø¥Ù† ÙˆÙØ¬Ø¯
    profile = analysis.get("encoded_profile")
    profile_hints = ""
    if isinstance(profile, dict):
        profile_hints = profile.get("hints_for_prompt", "") or ", ".join(profile.get("preferences", {}).values())

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        sys = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ SportSync AI.\n"
            "- Ø§ÙƒØªØ¨ Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø© Ø¬Ø¯Ù‹Ø§ ÙˆØ¬ÙÙ…Ù„ Ù‚ØµÙŠØ±Ø©.\n"
            "- Ù„Ø§ ØªØ°ÙƒØ± Ø¹Ø¨Ø§Ø±Ø© 'Layer Z' Ù„ÙØ¸ÙŠÙ‹Ø§Ø› Ø§Ø´Ø±Ø­ Ø§Ù„Ø³Ø¨Ø¨ Ø¨Ø¨Ø³Ø§Ø·Ø©.\n"
            "- Ù…Ù…Ù†ÙˆØ¹: Ø§Ù„Ù…ÙƒØ§Ù†/Ø§Ù„Ø²Ù…Ù†/Ø§Ù„ØªÙƒÙ„ÙØ©ØŒ ÙˆÙ…Ù…Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚.\n"
            "- Ø§Ø³ØªØ®Ø¯Ù… Ù‚ÙˆØ§Ø¦Ù… Ù†Ù‚Ø·ÙŠØ© ÙˆØ§Ø¶Ø­Ø©.\n"
            "- Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
        usr = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª.\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\","
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:\n"
            "- 'why_you' Ø³Ø¨Ø¨ ÙˆØ§Ø¶Ø­ ÙˆØ¨Ø³ÙŠØ·.\n"
            "- 'first_week' Ø®Ø·ÙˆØ§Øª Ù†ÙˆØ¹ÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø£Ø±Ù‚Ø§Ù…/Ø¬ÙˆÙ„Ø§Øª/Ø¹Ø¯Ù‘Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚).\n"
            "- 'progress_markers' Ø¹Ù„Ø§Ù…Ø§Øª Ø¥Ø­Ø³Ø§Ø³/Ø³Ù„ÙˆÙƒ Ø¨Ø¯ÙˆÙ† Ø£Ø±Ù‚Ø§Ù… Ø²Ù…Ù†ÙŠØ©.\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{persona}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©:\n" + bullets + "\n\n"
            + ("â€” Ø¥Ø´Ø§Ø±Ø§Øª Ø¨Ø±ÙˆÙØ§ÙŠÙ„:\n" + profile_hints + "\n\n" if profile_hints else "")
            + "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø®Ø§Ø±Ø¬ÙŠ."
        )
    else:
        sys = (
            "You are SportSync AI coach.\n"
            "- Very simple language, short sentences.\n"
            "- Do NOT mention 'Layer Z' explicitly; explain plainly.\n"
            "- FORBIDDEN: place/time/cost and reps/sets/minutes.\n"
            "- Use clear bullets.\n"
            "- Return JSON only."
        )
        usr = (
            "Create THREE movement-identity suggestions (no sport names).\n"
            "Return JSON ONLY with keys:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\","
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Style rules:\n"
            "- 'why_you' plain and specific.\n"
            "- 'first_week' qualitative steps (no numbers/reps/sets/minutes).\n"
            "- 'progress_markers' qualitative cues (no time numbers).\n\n"
            f"â€” Coach persona:\n{persona}\n\n"
            "â€” User analysis:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Bulleted answers:\n" + bullets + "\n\n"
            + ("â€” Profile hints:\n" + profile_hints + "\n\n" if profile_hints else "")
            + "Return JSON only."
        )
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

def _parse_json(text: str) -> Optional[List[Dict[str, Any]]]:
    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return recs
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}", text or "")
    if m:
        try:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return recs
        except Exception:
            pass
    return None

def _to_bullets(text: str, max_items: int = 5) -> List[str]:
    if not text: return []
    raw = re.split(r"[;\n\.ØŒ]+", text)
    items = [i.strip(" -â€¢\t ") for i in raw if i.strip()]
    return items[:max_items]

def _one_liner(*parts: str, max_len: int = 120) -> str:
    s = " â€” ".join([p.strip() for p in parts if p and p.strip()])
    return s[:max_len]

def _format_card(rec: Dict[str, Any], i: int, lang: str) -> str:
    head_ar = ["ðŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© 1","ðŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© 2","ðŸ”® Ø§Ù„ØªÙˆØµÙŠØ© 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ðŸŸ¢ Rec #1","ðŸŒ¿ Rec #2","ðŸ”® Rec #3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[i]

    scene = (rec.get("scene") or "").strip()
    inner = (rec.get("inner_sensation") or "").strip()
    why   = (rec.get("why_you") or "").strip()
    week  = _to_bullets(rec.get("first_week") or "")
    prog  = _to_bullets(rec.get("progress_markers") or "", max_items=4)
    diff  = rec.get("difficulty", 3)
    vr    = (rec.get("vr_idea") or "").strip()

    intro = _one_liner(scene, inner)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        out = [head, ""]
        if intro: out += ["*ÙˆØ´ Ù‡ÙŠØŸ*", f"- {intro}", ""]
        if why:
            out += ["*Ù„ÙŠØ´ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ*"]
            for b in _to_bullets(why, 3) or [why]:
                out.append(f"- {b}")
            out.append("")
        if week:
            out += ["*Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ Ø£ÙˆÙ„ (Ù†ÙˆØ¹ÙŠØ©)*"]
            for b in week: out.append(f"- {b}")
            out.append("")
        if prog:
            out += ["*Ø¹Ù„Ø§Ù…Ø§Øª ØªÙ‚Ø¯Ù‘Ù…*"]
            for b in prog: out.append(f"- {b}")
            out.append("")
        out.append(f"*Ø§Ù„ØµØ¹ÙˆØ¨Ø©:* {diff}/5")
        if vr: out.append(f"*VR (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):* {vr}")
        return "\n".join(out)
    else:
        out = [head, ""]
        if intro: out += ["*What is it?*", f"- {intro}", ""]
        if why:
            out += ["*Why you*"]
            for b in _to_bullets(why, 3) or [why]:
                out.append(f"- {b}")
            out.append("")
        if week:
            out += ["*First week (qualitative)*"]
            for b in week: out.append(f"- {b}")
            out.append("")
        if prog:
            out += ["*Progress markers*"]
            for b in prog: out.append(f"- {b}")
            out.append("")
        out.append(f"*Difficulty:* {diff}/5")
        if vr: out.append(f"*VR (optional):* {vr}")
        return "\n".join(out)

def _sanitize_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        # mask names + remove forbidden numerics/place/time/cost + drop practical_fit
        r = _sanitize_record(r)

        # quality gate
        blob = " ".join([
            r.get("scene",""), r.get("inner_sensation",""),
            r.get("why_you",""), r.get("first_week",""),
            r.get("progress_markers","")
        ])
        if _too_generic(blob) or not _has_sensory(blob) or not _is_meaningful(r):
            r = _fallback_identity(i, lang)
        out.append(r)
    return out

# ========= PUBLIC API =========
def generate_sport_recommendation(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", user_id: str = "N/A") -> List[str]:
    if OpenAI_CLIENT is None:
        return ["âŒ OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù€ Quiz.", "â€”", "â€”"]

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + Ø·Ø¨Ù‚Ø© Z
    analysis = analyze_user_from_answers(answers)
    silent = analyze_silent_drivers(answers, lang=lang) or []
    analysis["silent_drivers"] = silent

    # (Ø¬Ø¯ÙŠØ¯) Ø§Ù„ØªÙ‚Ø§Ø· Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù† ÙˆÙØ¬Ø¯ (Ø£Ùˆ ØªÙˆÙ„ÙŠØ¯Ù‡)
    profile = _extract_profile(answers, lang)
    if profile:
        analysis["encoded_profile"] = profile
        if "axes" in profile:
            analysis["z_axes"] = profile["axes"]
        if "scores" in profile:
            analysis["z_scores"] = profile["scores"]

    # Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
    persona = get_cached_personality(analysis, lang=lang)
    if not persona:
        persona = {"name":"SportSync Coach","tone":"Ø­Ø§Ø²Ù…-Ù‡Ø§Ø¯Ø¦","style":"Ø­Ø³Ù‘ÙŠ ÙˆØ§Ù‚Ø¹ÙŠ","philosophy":"Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡"}
        try:
            save_cached_personality(analysis, persona, lang=lang)
        except Exception:
            pass

    # === Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    msgs = _json_prompt(analysis, answers, persona, lang)
    try:
        resp = OpenAI_CLIENT.chat.completions.create(
            model=CHAT_MODEL, messages=msgs, temperature=0.9, max_tokens=1200
        )
        raw1 = (resp.choices[0].message.content or "").strip()
        print(f"[AI] model={CHAT_MODEL} len={len(raw1)} raw[:120]={raw1[:120]!r}")
    except Exception as e:
        return [f"âŒ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}", "â€”", "â€”"]

    # Sanitization pass-1
    if _violates(raw1): raw1 = _mask_names(raw1)
    parsed = _parse_json(raw1) or []
    cleaned = _sanitize_fill(parsed, lang)

    # ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ø«Ø§Ù†ÙŠØ©
    need_repair = any(_too_generic(" ".join([c.get("scene",""), c.get("why_you","")])) for c in cleaned)
    if need_repair:
        repair_prompt = {
            "role":"user",
            "content":(
                "Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø¬ÙˆØ¯Ø© Ø£Ø¹Ù„Ù‰ (Ø¨Ø¯ÙˆÙ† Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª): "
                "Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… Ø°ÙƒØ± Ø§Ù„Ù…ÙƒØ§Ù†/Ø§Ù„Ø²Ù…Ù†/Ø§Ù„ØªÙƒÙ„ÙØ© ÙˆØ¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø±Ù‚Ø§Ù…/Ø¹Ø¯Ù‘Ø§Øª/Ø¬ÙˆÙ„Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚. "
                "Ø§Ù…Ù„Ø£ why_you Ùˆ first_week Ø¨Ø¹Ù†Ø§ØµØ± Ø­Ø³Ù‘ÙŠØ© Ù†ÙˆØ¹ÙŠØ© ÙˆØ§Ø¶Ø­Ø©. "
                "Ø£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ù†ÙØ³ Ø§Ù„Ø¨Ù†ÙŠØ©."
            )
        }
        try:
            resp2 = OpenAI_CLIENT.chat.completions.create(
                model=CHAT_MODEL,
                messages=msgs + [{"role":"assistant","content":raw1}, repair_prompt],
                temperature=0.85, max_tokens=1200
            )
            raw2 = (resp2.choices[0].message.content or "").strip()
            if _violates(raw2): raw2 = _mask_names(raw2)
            parsed2 = _parse_json(raw2) or []
            cleaned2 = _sanitize_fill(parsed2, lang)

            # Ø§Ø®ØªØ± Ø§Ù„Ø£ÙØ¶Ù„ Ø¨Ø­ÙØ³Ù‘ÙŠØ© Ø£Ø·ÙˆÙ„
            def score(r: Dict[str,Any]) -> int:
                txt = " ".join([
                    r.get("scene",""),
                    r.get("inner_sensation",""),
                    r.get("why_you",""),
                    r.get("first_week","")
                ])
                return len(txt)

            if sum(map(score, cleaned2)) > sum(map(score, cleaned)):
                cleaned = cleaned2
        except Exception:
            pass

    cards = [_format_card(cleaned[i], i, lang) for i in range(3)]

    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang,
                "answers": {k: v for k, v in answers.items() if k != "profile"},
                "analysis": analysis,
                "silent_drivers": silent,
                "encoded_profile": profile,
                "recommendations": cleaned
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    return cards
