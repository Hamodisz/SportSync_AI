# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
ØªÙˆØµÙŠØ§Øª "Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡":
- 3 ØªÙˆØµÙŠØ§Øª Ø¨ÙˆØµÙ Ø­Ø³Ù‘ÙŠ + ØªØ¨Ø±ÙŠØ± Layer Z + Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ Ø£ÙˆÙ„ ÙˆÙ…Ø¤Ø´Ø±Ø§Øª ØªÙ‚Ø¯Ù….
- Ù…Ø®Ø±Ø¬Ø§Øª Ù…Ù†Ø¸Ù‘Ù…Ø© (JSON Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… ÙÙˆÙ„Ø¨Ø§Ùƒ).
- ÙÙ„ØªØ± Ù„Ù…Ù†Ø¹/ØªÙ…ÙˆÙŠÙ‡ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø§Øª + ØªØ¹Ø¨Ø¦Ø© fallback Ø¹Ù†Ø¯ Ø§Ù„Ù†Ù‚Øµ.
- ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆÙŠØ³Ø¬Ù‘Ù„ ÙÙŠ user_logger.
"""

from _future_ import annotations

import os
import json
import re
from typing import Any, Dict, List, Optional

# ========== OpenAI client ==========
try:
    import openai
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¶Ø§ÙØ© Ø­Ø²Ù…Ø© OpenAI ÙÙŠ requirements: openai>=1.6.1,<2") from e

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OpenAI_CLIENT = None
else:
    OpenAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o")  # ØºÙŠÙ‘Ø±Ù‡Ø§ Ø¥Ù„Ù‰ gpt-4o-mini Ù„Ù„ØªÙƒÙ„ÙØ©

# ========== Project imports (Ù…Ø¹ ÙÙˆÙ„Ø¨Ø§ÙƒØ§Øª Ø¢Ù…Ù†Ø©) ==========
try:
    from core.shared_utils import build_main_prompt  # Ù„Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¥Ù† Ø§Ø­ØªØ¬ØªÙ‡ Ù„Ø§Ø­Ù‚Ù‹Ø§
except Exception:
    build_main_prompt = None

try:
    from core.shared_utils import generate_main_prompt  # Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª (Ù…Ø´Ø¯Ù‘Ø¯ Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡)
except Exception:
    generate_main_prompt = None

try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: keys={list(content.keys())}")

try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(user_analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(user_analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(user_analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(user_analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

try:
    from core.user_analysis import analyze_user_from_answers
except Exception:
    def analyze_user_from_answers(answers: Dict[str, Any]) -> Dict[str, Any]:
        return {"quick_profile": "fallback", "raw_answers": answers}

try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
        return ["Ø§Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù…ÙŠÙˆÙ„ ÙØ±Ø¯ÙŠØ©", "Ø­Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù…Ù„Ù„"]


# ========== Block/Guard helpers ==========
# Blocklist Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø§Øª (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ) â€“ ÙˆØ³Ù‘Ø¹Ù‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_GENERIC_AVOID = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]

_SENSORY_HINTS = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªÙ‘Ø±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

def _violates_no_name_policy(text: str) -> bool:
    return bool(_name_re.search(text or ""))

def _mask_names(text: str) -> str:
    return _name_re.sub("â€”", text or "")

def _has_enough_sensory(text: str, min_hits: int = 4) -> bool:
    hits = sum(1 for w in _SENSORY_HINTS if w in (text or ""))
    return hits >= min_hits

def _too_generic(text: str, min_chars: int = 380) -> bool:
    t = (text or "").strip()
    return len(t) < min_chars or any(p in t for p in _GENERIC_AVOID)

def _is_meaningful(rec: Dict[str, Any]) -> bool:
    # Ù„Ø§Ø²Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù…Ø´Ù‡Ø¯ + Ù„Ù…Ø§Ø°Ø§ Ø£Ù†Øª Ø£Ùˆ Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹
    text = " ".join([
        (rec.get("scene") or ""),
        (rec.get("why_you") or ""),
        (rec.get("first_week") or "")
    ]).strip()
    return len(text) >= 40

def _fallback_identity(idx: int, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, Any]:
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        presets = [
            {
                "scene": "Ù…Ø³Ø§Ø± Ø®Ø§Ø±Ø¬ÙŠ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØºÙŠÙ‘Ø±ØŒ Ø³Ø·Ø­ Ù…Ø±Ù† ÙˆØ¥ÙŠÙ‚Ø§Ø¹ Ù…ØªÙˆØ³Ø· Ù…Ø¹ ØªÙ†ÙÙ‘Ø³ ÙŠÙØªØ­ Ø§Ù„ØµØ¯Ø±.",
                "inner_sensation": "ØªØ¯ÙÙ‘Ù‚ Ø¯Ø§ÙØ¦ ÙÙŠ Ø§Ù„Ø£Ø·Ø±Ø§Ù Ù…Ø¹ ØµÙØ§Ø¡ ØªØ¯Ø±ÙŠØ¬ÙŠ Ù„Ù„Ø°Ù‡Ù†.",
                "why_you": "ØªÙ…ÙŠÙ„ Ù„Ø¥ÙŠÙ‚Ø§Ø¹ Ù…ØªÙƒØ±Ø± ÙŠØ°ÙŠØ¨ ÙˆØ¹ÙŠÙƒ ÙˆÙŠÙ…Ù†Ø­Ùƒ Ø­Ø±ÙŠØ© Ø¯Ø§Ø®Ù„ÙŠØ© (Layer Z).",
                "practical_fit": "20â€“30 Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø±Ø¨ Ø§Ù„Ù…Ù†Ø²Ù„ØŒ ØªÙƒÙ„ÙØ© ØµÙØ±ØŒ Ø£Ù…Ø§Ù† Ø¹Ø§Ù„Ù.",
                "first_week": "Ù£ Ø¬Ù„Ø³Ø§Øª Ù‚ØµÙŠØ±Ø©ØŒ Ø¥Ø­Ù…Ø§Ø¡ Ù¥ Ø¯Ù‚Ø§Ø¦Ù‚ØŒ ØªØªØ¨Ù‘Ø¹ Ø§Ù„Ù†ÙØ³ØŒ ØªØ¯ÙˆÙŠÙ† Ø¥Ø­Ø³Ø§Ø³ Ù…Ø§ Ø¨Ø¹Ø¯.",
                "progress_markers": "Ø§Ù†ØªØ¸Ø§Ù… Ø§Ù„Ù†ÙØ³ØŒ Ø±ØºØ¨Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¯Ø©ØŒ ØµÙØ§Ø¡ Ø°Ù‡Ù†ÙŠ Ø£Ø·ÙˆÙ„.",
                "difficulty": 2,
                "vr_idea": ""
            },
            {
                "scene": "Ù…Ø³Ø§Ø­Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ø³ÙŠØ·Ø©ØŒ Ù…Ù‚Ø§ÙˆÙ…Ø© Ù„Ù„Ø¬Ø³Ù… Ø¨Ø­Ø±ÙƒØ© Ù…ØªÙ†Ø§ØºÙ…Ø© Ù„Ù„ÙŠØ¯ÙŠÙ† ÙˆØ§Ù„Ø¬Ø°Ø¹.",
                "inner_sensation": "Ø­Ø±Ø§Ø±Ø© Ù„Ø·ÙŠÙØ© ÙˆØªÙ…Ø±ÙƒØ² ÙÙŠ Ø§Ù„ÙˆØ³Ø· Ù…Ø¹ Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø§Ù„Ø«Ø¨Ø§Øª.",
                "why_you": "ØªØ¨Ø­Ø« Ø¹Ù† Ø¥Ù†Ø¬Ø§Ø² Ø³Ø±ÙŠØ¹ ÙˆÙˆØ§Ø¶Ø­ Ø¨Ø¯ÙˆÙ† ØªØ¹Ù‚ÙŠØ¯ (Layer Z).",
                "practical_fit": "15â€“20 Ø¯Ù‚ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ù…Ù†Ø²Ù„ØŒ Ø£Ø¯ÙˆØ§Øª Ø¨Ø³ÙŠØ·Ø© Ø¥Ù† Ù„Ø²Ù….",
                "first_week": "Ù£ Ø¬Ù„Ø³Ø§ØªØŒ Ù¦ Ø­Ø±ÙƒØ§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ã— Ø¬ÙˆÙ„ØªÙŠÙ†ØŒ ØªØ³Ø¬ÙŠÙ„ Ø´Ø¯Ø© Ø§Ù„Ø¬Ù‡Ø¯.",
                "progress_markers": "ØªØ­ÙƒÙ‘Ù… Ø£ÙØ¶Ù„ Ø¨Ø§Ù„Ø¬Ø°Ø¹ØŒ Ù†ÙˆÙ… Ø£Ø¹Ù…Ù‚ØŒ Ø·Ø§Ù‚Ø© ÙŠÙˆÙ…ÙŠØ© Ø£Ø¹Ù„Ù‰.",
                "difficulty": 3,
                "vr_idea": ""
            },
            {
                "scene": "Ø£Ø±Ø¶ÙŠØ© Ø«Ø§Ø¨ØªØ© ÙˆÙ…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ© ÙˆØ§Ø³Ø¹ØŒ Ø­Ø±ÙƒØ© Ø¨Ø·ÙŠØ¦Ø© ÙˆØ§Ø¹ÙŠØ© Ù…Ø¹ ØªÙ…Ø¯Ù‘Ø¯ Ù…ØªÙ†Ø§ØºÙ….",
                "inner_sensation": "Ù‡Ø¯ÙˆØ¡ Ø¹ØµØ¨ÙŠÙ‘ ÙˆØ¥Ø·Ø§Ù„Ø© Ù„Ù„Ù…ÙØ§ØµÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©.",
                "why_you": "ØªØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø¹ØµØ¨ÙŠ-Ø¹Ø§Ø·ÙÙŠ ÙŠÙˆØ§Ø²Ù† Ø§Ù†Ø¯ÙØ§Ø¹ Ø§Ù„Ø°Ù‡Ù† (Layer Z).",
                "practical_fit": "10â€“15 Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØºØ±ÙˆØ¨ØŒ Ù…Ø³Ø§Ø­Ø© ØµØºÙŠØ±Ø©.",
                "first_week": "Ø­Ø±ÙƒØ© ÙˆØ§Ø¹ÙŠØ© + Ù£ Ø¯ÙˆØ±Ø§Øª ØªÙ†ÙÙ‘Ø³ØŒ ØªØ¯ÙˆÙŠÙ† Ø¥Ø­Ø³Ø§Ø³ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯.",
                "progress_markers": "Ø§Ù†Ø®ÙØ§Ø¶ ØªÙˆØªØ± Ø§Ù„Ø±Ù‚Ø¨Ø©/Ø§Ù„ÙÙƒØŒ ÙˆØ¶ÙˆØ­ Ø°Ù‡Ù†ÙŠØŒ ØªÙ‚Ø¨Ù‘Ù„ Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø¬Ù‡Ø¯ Ø§Ù„Ù‡ÙˆØ§Ø¦ÙŠ.",
                "difficulty": 1,
                "vr_idea": ""
            }
        ]
    else:
        presets = [
            {
                "scene": "Outdoor path with forgiving surface; medium rhythm; open-chest breathing.",
                "inner_sensation": "Warm flow in limbs; gently clearing mind.",
                "why_you": "You sync with repetitive rhythms that dissolve awareness (Layer Z).",
                "practical_fit": "20â€“30 min near home; zero cost; high safety.",
                "first_week": "3 short sessions; 5-min warm-up; breath tracking; post-note.",
                "progress_markers": "Steadier breath; urge to go longer; mental clarity.",
                "difficulty": 2,
                "vr_idea": ""
            },
            {
                "scene": "Simple indoor space; body-weight resistance with rhythmic arm-torso flow.",
                "inner_sensation": "Gentle heat and centered stability.",
                "why_you": "You want quick, tangible progress without complexity (Layer Z).",
                "practical_fit": "15â€“20 min at home; minimal tools if any.",
                "first_week": "3 sessions; 6 basics Ã— 2 rounds; record RPE.",
                "progress_markers": "Core control improves; deeper sleep; higher daily energy.",
                "difficulty": 3,
                "vr_idea": ""
            },
            {
                "scene": "Stable floor and wide field of view; slow aware movement with elastic stretches.",
                "inner_sensation": "Deep nervous calm and joint decompression.",
                "why_you": "You need a neuro-emotional reset to balance mental drive (Layer Z).",
                "practical_fit": "10â€“15 min at dusk; tiny square of space.",
                "first_week": "Mindful mobility + 3 breath cycles; log before/after.",
                "progress_markers": "Less neck/jaw tension; clearer thinking; better cardio tolerance.",
                "difficulty": 1,
                "vr_idea": ""
            }
        ]
    return presets[idx % 3]

def _answers_to_bullets(answers: Dict[str, Any], lang: str) -> str:
    try:
        items = []
        for k, v in (answers or {}).items():
            if isinstance(v, dict):
                q = v.get("question", k)
                a = v.get("answer", "")
            else:
                q = str(k); a = str(v)
            if isinstance(a, list):
                a_txt = ", ".join(map(str, a))
            else:
                a_txt = str(a)
            items.append(f"- {q}: {a_txt}")
        return "\n".join(items)
    except Exception:
        return json.dumps(answers, ensure_ascii=False)

def _build_json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                       personality: str, lang: str) -> List[Dict[str, str]]:
    """
    Ø¨Ø±ÙˆÙ…Ø¨Øª â€œÙ‡ÙˆÙŠØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡â€ + JSON Ù…Ù†Ø¸Ù‘Ù….
    Keys Ù„ÙƒÙ„ ØªÙˆØµÙŠØ©:
      scene, inner_sensation, why_you, practical_fit, first_week, progress_markers, difficulty(1-5), vr_idea?
    """
    bullets = _answers_to_bullets(answers, lang)
    silent = analysis.get("silent_drivers", [])
    personality_str = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        system_txt = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­ØªØ±Ù Ù…Ù† SportSync AI. Ø§Ù…Ù†Ø¹ Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø§Øª ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø´Ù‡ÙŠØ±Ø© Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§. "
            "Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø­Ø³Ù‘ÙŠØ© ØºÙ†ÙŠØ©ØŒ ÙˆØ§Ø±Ø¨Ø· ÙƒÙ„ ØªÙˆØµÙŠØ© Ø¨Ø¯ÙˆØ§ÙØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø·Ø¨Ù‚Ø© Z) Ù„ØªÙƒÙˆÙ† Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°."
        )
        user_txt = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ø¯ÙˆÙ† Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª Ù…Ø·Ù„Ù‚Ù‹Ø§.\n"
            "Ø£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ø´ÙƒÙ„:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\",\"practical_fit\":\"...\",\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Ø¥Ø°Ø§ Ø¸Ù‡Ø± Ø§Ø³Ù… Ø±ÙŠØ§Ø¶Ø© ÙØ§Ø³ØªØ¨Ø¯Ù„Ù‡ ÙÙˆØ±Ù‹Ø§ Ø¨Ø´Ø±Ø·Ø© Ø·ÙˆÙŠÙ„Ø© \"â€”\" Ù…Ø¹ ÙˆØµÙ Ø­Ø³Ù‘ÙŠ Ø¨Ø¯ÙŠÙ„.\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{personality_str}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØªØµØ±Ø©:\n" + bullets + "\n\n"
            "â€” Ø·Ø¨Ù‚Ø© Z (Ø§Ø±Ø¨Ø· Ø¨Ù‡Ø§ ÙÙ‚Ø±Ø© Ù„Ù…Ø§Ø°Ø§ Ø£Ù†Øª):\n" + ", ".join(silent) + "\n\n"
            "Ù‚ÙŠÙˆØ¯ ØµØ§Ø±Ù…Ø©:\n"
            "- Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª ÙÙ‚Ø·.\n"
            "- Ù„ØºØ© Ø­Ø³Ù‘ÙŠØ©: Ø§Ù„Ù…ÙƒØ§Ù†/Ø§Ù„Ø³Ø·Ø­/Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹/Ø§Ù„ØªÙ†ÙÙ‘Ø³/Ù†ÙˆØ¹ Ø§Ù„Ø¬Ù‡Ø¯.\n"
            "- Ù„ÙƒÙ„ ØªÙˆØµÙŠØ©: scene, inner_sensation, why_you (Layer Z), practical_fit (Ø²Ù…Ù†/Ù…ÙƒØ§Ù†/ØªÙƒÙ„ÙØ©/Ø£Ù…Ø§Ù†), first_week (3 Ø®Ø·ÙˆØ§Øª), progress_markers (Ø¨Ø¹Ø¯ 2â€“4 Ø£Ø³Ø§Ø¨ÙŠØ¹), difficultyØŒ Ùˆ vr_idea Ø¥Ù† Ù„Ø²Ù….\n"
            "- JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø®Ø§Ø±Ø¬ÙŠ."
        )
    else:
        system_txt = (
            "You are SportSync AI coach. Never name sports or brand tools. "
            "Use rich sensory language and tie each suggestion to Layer-Z; make it actionable."
        )
        user_txt = (
            "Produce THREE movement-identity suggestions without naming any sports.\n"
            "Return JSON ONLY with:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\",\"practical_fit\":\"...\",\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "If a sport name appears, replace it with \"â€”\" and provide a sensory substitute.\n\n"
            f"â€” Coach personality:\n{personality_str}\n\n"
            "â€” User analysis:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Bulleted answers:\n" + bullets + "\n\n"
            "â€” Layer-Z drivers:\n" + ", ".join(silent) + "\n\n"
            "Constraints:\n"
            "- Exactly three suggestions.\n"
            "- Sensory language (setting/surface/rhythm/breathing/effort).\n"
            "- Keys: scene, inner_sensation, why_you (Layer-Z), practical_fit (time/place/cost/safety), first_week (3 steps), progress_markers (2â€“4 weeks), difficulty, optional vr_idea.\n"
            "- JSON only."
        )

    return [
        {"role": "system", "content": system_txt},
        {"role": "user", "content": user_txt}
    ]

def _parse_json_or_fallback(text: str, lang: str) -> List[Dict[str, Any]]:
    # Ù…Ø­Ø§ÙˆÙ„Ø© JSON Ù…Ø¨Ø§Ø´Ø±Ø©
    def _normalize(rec: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "scene": rec.get("scene") or rec.get("plan") or "",
            "inner_sensation": rec.get("inner_sensation") or "",
            "why_you": rec.get("why_you") or rec.get("why") or "",
            "practical_fit": rec.get("practical_fit") or "",
            "first_week": rec.get("first_week") or "",
            "progress_markers": rec.get("progress_markers") or "",
            "difficulty": rec.get("difficulty", 3),
            "vr_idea": rec.get("vr_idea", "")
        }

    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return [_normalize(r) for r in recs[:3]]
    except Exception:
        pass

    # Ø£Ù‚Ø±Ø¨ ÙƒØªÙ„Ø© JSON
    try:
        m = re.search(r"\{[\s\S]*\}", text)
        if m:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return [_normalize(r) for r in recs[:3]]
    except Exception:
        pass

    # ÙÙˆÙ„Ø¨Ø§Ùƒ Ù†ØµÙŠ: ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ 3 Ù…Ù‚Ø§Ø·Ø¹
    parts: List[str] = []
    buf: List[str] = []
    for line in (text or "").splitlines():
        if (line.strip().lower().startswith(("1", "1.", "Ù¢", "2", "2.", "Ù£", "3", "3."))) and buf:
            parts.append("\n".join(buf).strip()); buf = [line]
        else:
            buf.append(line)
    if buf: parts.append("\n".join(buf).strip())
    parts = parts[:3] if parts else [text.strip()]

    out = []
    for p in parts[:3]:
        out.append({
            "scene": p,
            "inner_sensation": "",
            "why_you": "",
            "practical_fit": "",
            "first_week": "",
            "progress_markers": "",
            "difficulty": 3,
            "vr_idea": ""
        })
    while len(out) < 3:
        out.append(_fallback_identity(len(out), lang))
    return out[:3]

def _format_card(rec: Dict[str, Any], idx: int, lang: str) -> str:
    num = idx + 1
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        head = ["ğŸŸ¢ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 1", "ğŸŒ¿ Ø§Ù„ØªØ¬Ø±Ø¨Ø© 2", "ğŸ”® Ø§Ù„ØªØ¬Ø±Ø¨Ø© 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"][idx] if idx < 3 else f"ğŸ”¹ ØªØ¬Ø±Ø¨Ø© {num}"
        return (
            f"{head}\n\n"
            f"Ø§Ù„Ù…Ø´Ù‡Ø¯: {rec.get('scene','â€”')}\n\n"
            f"Ø§Ù„Ø¥Ø­Ø³Ø§Ø³ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ: {rec.get('inner_sensation','')}\n\n"
            f"Ù„Ù…Ø§Ø°Ø§ Ø£Ù†Øª (Layer Z): {rec.get('why_you','')}\n\n"
            f"Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: {rec.get('practical_fit','')}\n\n"
            f"Ø£ÙˆÙ„ Ø£Ø³Ø¨ÙˆØ¹: {rec.get('first_week','')}\n\n"
            f"Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù…: {rec.get('progress_markers','')}\n\n"
            f"Ø§Ù„ØµØ¹ÙˆØ¨Ø©: {rec.get('difficulty',3)}/5\n"
            f"ÙÙƒØ±Ø© VR: {rec.get('vr_idea','')}\n"
        )
    else:
        head = ["ğŸŸ¢ Experience #1", "ğŸŒ¿ Experience #2", "ğŸ”® Experience #3 (Creative)"][idx] if idx < 3 else f"ğŸ”¹ Experience {num}"
        return (
            f"{head}\n\n"
            f"Scene: {rec.get('scene','â€”')}\n\n"
            f"Inner sensation: {rec.get('inner_sensation','')}\n\n"
            f"Why you (Layer Z): {rec.get('why_you','')}\n\n"
            f"Practical fit: {rec.get('practical_fit','')}\n\n"
            f"First week: {rec.get('first_week','')}\n\n"
            f"Progress markers: {rec.get('progress_markers','')}\n\n"
            f"Difficulty: {rec.get('difficulty',3)}/5\n"
            f"VR idea: {rec.get('vr_idea','')}\n"
        )

def _sanitize_and_fill(parsed: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    """
    - ÙŠÙ…Ø³Ù‘Ùƒ Ø£ÙŠ Ø£Ø³Ù…Ø§Ø¡ Ù„Ùˆ ØªØ³Ø±Ù‘Ø¨Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù‚ÙˆÙ„ ÙˆÙŠØ³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ø´Ø±Ø·Ø© Ø·ÙˆÙŠÙ„Ø©.
    - ÙŠØ±ÙØ¶ Ø§Ù„Ø³Ø·Ø­ÙŠØ© (Ù‚ØµÙŠØ±/Ø¹Ø§Ù…/Ø­Ø³Ù‘ÙŠ Ø¶Ø¹ÙŠÙ) ÙˆÙŠØ¹Ø·ÙŠ fallback Ø«Ø§Ø¨Øª.
    - ÙŠØ¶Ù…Ù† 3 ØªÙˆØµÙŠØ§Øª Ø¯Ø§Ø¦Ù…Ù‹Ø§.
    """
    out: List[Dict[str, Any]] = []
    for i in range(3):
        rec = parsed[i] if i < len(parsed) else {}
        # ØªÙ…ÙˆÙŠÙ‡ Ø£Ø³Ù…Ø§Ø¡
        for k, v in list(rec.items()):
            if isinstance(v, str) and _violates_no_name_policy(v):
                rec[k] = _mask_names(v)

        # ÙØ­Øµ Ø§Ù„Ø³Ø·Ø­ÙŠØ©/Ø§Ù„Ø­Ø³ÙŠØ©
        text_blob = " ".join([
            rec.get("scene",""), rec.get("inner_sensation",""),
            rec.get("why_you",""), rec.get("practical_fit",""),
            rec.get("first_week",""), rec.get("progress_markers","")
        ])
        if _too_generic(text_blob) or not _has_enough_sensory(text_blob) or not _is_meaningful(rec):
            rec = _fallback_identity(i, lang)

        out.append(rec)
    return out

# ========== Public API ==========
def generate_sport_recommendation(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", user_id: str = "N/A") -> List[str]:
    if OpenAI_CLIENT is None:
        return ["âŒ OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ·. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø­Ø§Ù„ÙŠØ§Ù‹.", "â€”", "â€”"]

    # [1] ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    user_analysis = analyze_user_from_answers(answers)

    # [2] Ø·Ø¨Ù‚Ø© Z
    silent_drivers = analyze_silent_drivers(answers, lang=lang) or []
    user_analysis["silent_drivers"] = silent_drivers

    # [3] Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ (ÙƒØ§Ø´)
    personality = get_cached_personality(user_analysis, lang=lang)
    if not personality:
        # Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ø´Ø®ØµÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ø´ØŒ Ø¨Ù†Ø¨Ù†ÙŠ ÙˆØ­Ø¯Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ (Ø§Ø¹ØªÙ…Ø¯Øª build_main_prompt Ù„Ø¯ÙŠÙƒ)
        personality = {"name": "Sports Sync Coach", "tone": "Ù‡Ø§Ø¯Ø¦ ÙˆØ­Ø§Ø²Ù…", "style": "Ø­Ø³Ù‘ÙŠ/ÙˆØ§Ù‚Ø¹ÙŠ", "philosophy": "Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡"}
        try:
            save_cached_personality(user_analysis, personality, lang=lang)
        except Exception:
            pass

    # [4] Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (JSON Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡)
    messages = _build_json_prompt(user_analysis, answers, personality, lang)

    # [5] Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    try:
        completion = OpenAI_CLIENT.chat.completions.create(
            model=CHAT_MODEL,
            messages=messages,
            temperature=0.85,
            max_tokens=1100
        )
        raw = (completion.choices[0].message.content or "").strip()
    except Exception as e:
        return [f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}", "â€”", "â€”"]

    # [6] ØªÙ…ÙˆÙŠÙ‡ Ø£Ø³Ù…Ø§Ø¡ Ù„Ùˆ Ø¸Ù‡Ø±Øª ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… (Ø§Ø­ØªÙŠØ§Ø·)
    if _violates_no_name_policy(raw):
        raw = _mask_names(raw)

    # [7] ØªÙÙƒÙŠÙƒ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ Ø¹Ù†Ø§ØµØ±
    parsed = _parse_json_or_fallback(raw, lang=lang)

    # [8] ØªÙ†Ø¸ÙŠÙ/ØªØ¹Ø¨Ø¦Ø© ÙˆØ¶Ù…Ø§Ù† 3 ØªÙˆØµÙŠØ§Øª
    parsed_filled = _sanitize_and_fill(parsed, lang)

    # [9] ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø±Ø¶ Ù„Ù„ÙƒØ±ÙˆØª
    cards = [_format_card(rec, i, lang) for i, rec in enumerate(parsed_filled[:3])]

    # [10] ØªØ³Ø¬ÙŠÙ„ Ù„Ù„Ø£Ø«Ø±/Ø§Ù„ØªØ¹Ù„Ù‘Ù…
    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang,
                "answers": answers,
                "user_analysis": user_analysis,
                "personality_used": personality,
                "silent_drivers": silent_drivers,
                "raw_response": raw,
                "parsed": parsed,
                "final_used": parsed_filled
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    return cards
