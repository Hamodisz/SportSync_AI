# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
ØªÙˆØµÙŠØ§Øª "Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡" Ø¨Ø«Ù„Ø§Ø« ÙƒØ±ÙˆØª Ø­Ø³Ù‘ÙŠØ© Ù…Ù†Ø¸Ù…Ø© + Ø·Ø¨Ù‚Ø© Z + Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ ÙˆØ¨Ø¯ÙŠÙ„ VR.
ÙŠØ­Ø§ÙˆÙ„ Ù…Ø±ØªÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ù€ fallback. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/English.
"""

from __future__ import annotations

import os, json, re
from typing import Any, Dict, List, Optional

# ========= OpenAI =========
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø£Ø¶Ù Ø§Ù„Ø­Ø²Ù…Ø© ÙÙŠ requirements: openai>=1.6.1,<2") from e

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OpenAI_CLIENT = None
else:
    OpenAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o")  # Ø¨Ø¯Ù‘Ù„ Ø¥Ù„Ù‰ gpt-4o-mini Ù„ØªÙƒÙ„ÙØ© Ø£Ù‚Ù„

# ========= Project imports (with safe fallbacks) =========
try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: {list(content.keys())}")

try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

try:
    from core.user_analysis import analyze_user_from_answers
except Exception:
    def analyze_user_from_answers(answers: Dict[str, Any]) -> Dict[str, Any]:
        return {"quick_profile": "fallback", "raw_answers": answers}

# Layer Z Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ ÙÙŠ core Ø£Ùˆ analysis
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
            return ["Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±", "ØªÙØ¶ÙŠÙ„ ØªØ­Ø¯Ù‘ÙŠ Ø°Ù‡Ù†ÙŠ"]

# ========= Rules & helpers =========
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_AVOID_GENERIC = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]
_SENSORY = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªÙ‘Ø±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

def _mask_names(t: str) -> str: return _name_re.sub("â€”", t or "")
def _violates(t: str) -> bool:   return bool(_name_re.search(t or ""))

def _answers_to_bullets(answers: Dict[str, Any]) -> str:
    out = []
    for k, v in (answers or {}).items():
        if isinstance(v, dict):
            q, a = v.get("question", k), v.get("answer", "")
        else:
            q, a = str(k), v
        if isinstance(a, list): a = ", ".join(map(str, a))
        out.append(f"- {q}: {a}")
    return "\n".join(out)

def _too_generic(text: str, min_chars: int = 320) -> bool:
    t = (text or "").strip()
    return len(t) < min_chars or any(p in t for p in _AVOID_GENERIC)

def _has_sensory(text: str, min_hits: int = 4) -> bool:
    return sum(1 for w in _SENSORY if w in (text or "")) >= min_hits

def _is_meaningful(rec: Dict[str, Any]) -> bool:
    blob = " ".join([
        rec.get("scene",""), rec.get("inner_sensation",""),
        rec.get("why_you",""), rec.get("practical_fit",""),
        rec.get("first_week",""), rec.get("progress_markers","")
    ]).strip()
    return len(blob) >= 80

def _fallback_identity(i: int, lang: str) -> Dict[str, Any]:
    presets_ar = [
        {
            "scene":"Ø¨ÙŠØ¦Ø© Ù…ØªØºÙŠÙ‘Ø±Ø© Ø§Ù„Ø³Ø·Ø­ Ø¨Ø¥ÙŠÙ‚Ø§Ø¹ Ù…ØªÙˆØ³Ø· ÙˆØ¨ÙˆØ§Ø¨Ø§Øª Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù†ÙØ³ Ø§Ù„Ù…ÙØªÙˆØ­Ø©.",
            "inner_sensation":"ØªØ¯ÙÙ‘Ù‚ Ø¯Ø§ÙØ¦ ÙˆÙˆØ¶ÙˆØ­ Ø°Ù‡Ù†ÙŠ ØªØ¯Ø±ÙŠØ¬ÙŠ.",
            "why_you":"ØªØ­Ø¨ ØªØ­Ø¯Ù‘ÙŠ Ø°Ø§ØªÙƒ Ø¨Ø¯ÙˆÙ† Ø±ØªØ§Ø¨Ø© ÙˆØªØ¨Ø­Ø« Ø¹Ù† Ø¥Ø­ÙƒØ§Ù… Ø¯Ø§Ø®Ù„ÙŠ (Layer Z).",
            "practical_fit":"20â€“30 Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø±Ø¨ Ø§Ù„Ù…Ù†Ø²Ù„ØŒ ØªÙƒÙ„ÙØ© ØµÙØ±ØŒ Ø£Ù…Ø§Ù† Ø¹Ø§Ù„Ù.",
            "first_week":"3 Ø¬Ù„Ø³Ø§ØªØ› 5 Ø¯ Ø¯ÙØ¡Ø› ØªØªØ¨Ù‘Ø¹ Ø§Ù„Ù†ÙØ³Ø› ØªØ¯ÙˆÙŠÙ† Ø¥Ø­Ø³Ø§Ø³ Ù…Ø§ Ø¨Ø¹Ø¯.",
            "progress_markers":"ØªÙ†ÙÙ‘Ø³ Ø£Ù‡Ø¯Ø£ØŒ Ø±ØºØ¨Ø© Ù„Ù„Ø²ÙŠØ§Ø¯Ø©ØŒ ØµÙØ§Ø¡ Ø£Ø·ÙˆÙ„.",
            "difficulty":2,"vr_idea":"Ø·ÙˆØ±Ù‡Ø§ Ø¨ØªØ­Ø¯ÙŠØ§Øª ÙˆØ§Ù‚Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ ØªÙƒØªÙŠÙƒÙŠØ© Ø®ÙÙŠÙØ©."
        },
        {
            "scene":"Ù…Ø³Ø§Ø­Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆØ­Ø±ÙƒØ© Ù…Ù‚Ø§ÙˆÙ…Ø© Ù…ØªÙ†Ø§ØºÙ…Ø© Ù„Ù„ÙŠØ¯ÙŠÙ† ÙˆØ§Ù„Ø¬Ø°Ø¹.",
            "inner_sensation":"Ø­Ø±Ø§Ø±Ø© Ù„Ø·ÙŠÙØ© ÙˆØªÙ…Ø±ÙƒØ² Ø¨Ø§Ù„Ø¬Ø°Ø¹.",
            "why_you":"ØªØ­ØªØ§Ø¬ Ø¥Ù†Ø¬Ø§Ø² Ù…Ù„Ù…ÙˆØ³ Ø³Ø±ÙŠØ¹ Ø¨Ø¹ÙŠØ¯Ù‹Ø§ Ø¹Ù† Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ (Layer Z).",
            "practical_fit":"15â€“20 Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ø§Ù„Ø¨ÙŠØªØŒ Ø£Ø¯ÙˆØ§Øª Ø¨Ø³ÙŠØ·Ø©.",
            "first_week":"3 Ø¬Ù„Ø³Ø§ØªØ› 6 Ø­Ø±ÙƒØ§Øª Ã— Ø¬ÙˆÙ„ØªÙŠÙ†Ø› Ø³Ø¬Ù„ Ø´Ø¯Ø© Ø§Ù„Ø¬Ù‡Ø¯.",
            "progress_markers":"Ø«Ø¨Ø§Øª Ø§Ù„Ù†ÙˆØ§Ø©ØŒ Ù†ÙˆÙ… Ø£Ø¹Ù…Ù‚ØŒ Ø·Ø§Ù‚Ø© Ø£Ø¹Ù„Ù‰.",
            "difficulty":3,"vr_idea":"Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø­Ø§ÙƒÙŠØ§Øª ÙˆØ²Ù†/ØªÙˆØ§Ø²Ù† Ø¯Ø§Ø®Ù„ VR."
        },
        {
            "scene":"Ø£Ø±Ø¶ÙŠØ© Ø«Ø§Ø¨ØªØ© ÙˆÙ…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ© ÙˆØ§Ø³Ø¹ Ù…Ø¹ ØªÙ…Ø¯Ù‘Ø¯ ÙˆØ§Ø¹Ù Ø¨Ø·ÙŠØ¡.",
            "inner_sensation":"Ù‡Ø¯ÙˆØ¡ Ø¹ØµØ¨ÙŠ ÙˆØªØ®ÙÙŠÙ Ø´Ø¯Ù‘ Ø§Ù„Ù…ÙØ§ØµÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©.",
            "why_you":"ØªØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø¹ØµØ¨ÙŠ-Ø¹Ø§Ø·ÙÙŠ ØªØ±ÙØ¹ ØªÙ‚Ø¨Ù‘Ù„ Ø§Ù„Ø¬Ù‡Ø¯ (Layer Z).",
            "practical_fit":"10â€“15 Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù†Ø¯ Ø§Ù„ØºØ±ÙˆØ¨ØŒ Ù…Ø³Ø§Ø­Ø© ØµØºÙŠØ±Ø©.",
            "first_week":"Ø­Ø±ÙƒØ© ÙˆØ§Ø¹ÙŠØ© + 3 Ø¯ÙˆØ±Ø§Øª ØªÙ†ÙÙ‘Ø³Ø› Ù…Ø°ÙƒØ±Ø§Øª Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯.",
            "progress_markers":"ØªÙˆØªØ± Ø±Ù‚Ø¨Ø© Ø£Ù‚Ù„ØŒ ØªÙÙƒÙŠØ± Ø£ØµÙÙ‰ØŒ ØªØ­Ù…Ù‘Ù„ Ø£ÙØ¶Ù„.",
            "difficulty":1,"vr_idea":"Ø¬Ù„Ø³Ø§Øª Ø¥Ø³ØªØ±Ø®Ø§Ø¡ ØªÙØ§Ø¹Ù„ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©."
        }
    ]
    presets_en = [
        {
            "scene":"Variable outdoor surface, medium rhythm, open-chest breathing gates.",
            "inner_sensation":"Warm limb flow; clearing mind.",
            "why_you":"Craves non-repetitive self-challenge with internal mastery (Layer Z).",
            "practical_fit":"20â€“30 min near home; zero cost; safe.",
            "first_week":"3 sessions; 5-min warm-up; breath tracking; post-notes.",
            "progress_markers":"Calmer breath, urge to go longer, clearer focus.",
            "difficulty":2,"vr_idea":"Light tactical VR challenges as variant."
        },
        {
            "scene":"Simple indoor space; rhythmic body-weight resistance (arms + trunk).",
            "inner_sensation":"Gentle heat; centered core stability.",
            "why_you":"Wants quick, tangible progress without complexity (Layer Z).",
            "practical_fit":"15â€“20 min at home; minimal tools.",
            "first_week":"3 sessions; 6 basics Ã— 2 rounds; log RPE.",
            "progress_markers":"Core control, deeper sleep, higher energy.",
            "difficulty":3,"vr_idea":"Balance/weight simulations in VR."
        },
        {
            "scene":"Stable floor, wide FoV; slow aware movement with elastic stretches.",
            "inner_sensation":"Deep nervous calm; joint decompression.",
            "why_you":"Needs neuro-emotional reset to boost cardio tolerance (Layer Z).",
            "practical_fit":"10â€“15 min at dusk; tiny space.",
            "first_week":"Mindful mobility + 3 breath cycles; before/after log.",
            "progress_markers":"Less neck/jaw tension; clearer thinking.",
            "difficulty":1,"vr_idea":"Immersive nature-relax VR sessions."
        }
    ]
    return (presets_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else presets_en)[i % 3]

def _json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                 personality: Any, lang: str) -> List[Dict[str, str]]:
    bullets = _answers_to_bullets(answers)
    silent = analysis.get("silent_drivers", [])
    persona = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        sys = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ SportSync AI. Ø§Ù…Ù†Ø¹ Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±ÙŠØ§Ø¶Ø§Øª/Ø§Ù„Ø£Ø¯ÙˆØ§Øª. "
            "Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø­Ø³Ù‘ÙŠØ© ÙˆØ±Ø¨Ø· Layer-Z. Ø£Ø®Ø±Ø¬ JSON ÙÙ‚Ø·."
        )
        usr = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª.\n"
            "Return JSON ONLY:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\",\"practical_fit\":\"...\","
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Ù„Ùˆ Ø¸Ù‡Ø± Ø§Ø³Ù… Ø±ÙŠØ§Ø¶Ø© Ø§Ø³ØªØ¨Ø¯Ù„Ù‡ Ø¨Ù€ \"â€”\" Ù…Ø¹ Ø¨Ø¯ÙŠÙ„ Ø­Ø³Ù‘ÙŠ.\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{persona}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©:\n" + bullets + "\n\n"
            "â€” Ù…Ø­Ø±ÙƒØ§Øª Z:\n" + ", ".join(silent) + "\n\n"
            "Ù‚ÙŠÙˆØ¯: 3 ØªÙˆØµÙŠØ§Øª Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŒ Ù…Ø´Ù‡Ø¯/Ø¥Ø­Ø³Ø§Ø³/Ù„Ù…Ø§Ø°Ø§ Ø£Ù†Øª/Ù…Ù„Ø§Ø¡Ù…Ø©/Ø£Ø³Ø¨ÙˆØ¹ Ø£ÙˆÙ„/Ù…Ø¤Ø´Ø±Ø§Øª/ØµØ¹ÙˆØ¨Ø©/ÙÙƒØ±Ø© VR."
        )
    else:
        sys = (
            "You are SportSync AI coach. Never name sports. Use sensory language + Layer-Z. JSON only."
        )
        usr = (
            "Create THREE movement-identity suggestions with NO sports names.\n"
            "Return JSON ONLY with keys: scene, inner_sensation, why_you, practical_fit, first_week, progress_markers, difficulty(1-5), vr_idea.\n"
            "If a sport name appears, replace with 'â€”' and add a sensory substitute.\n\n"
            f"â€” Coach persona:\n{persona}\n\n"
            "â€” User analysis:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Bulleted answers:\n" + bullets + "\n\n"
            "â€” Layer-Z drivers:\n" + ", ".join(silent)
        )
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

def _parse_json(text: str) -> Optional[List[Dict[str, Any]]]:
    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return recs
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}", text or "")
    if m:
        try:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return recs
        except Exception:
            pass
    return None

def _format_card(rec: Dict[str, Any], i: int, lang: str) -> str:
    head_ar = ["ðŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1","ðŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2","ðŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ðŸŸ¢ Recommendation #1","ðŸŒ¿ Recommendation #2","ðŸ”® Recommendation #3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[i]
    return (
        f"{head}\n\n"
        f"{'Ø§Ù„Ù…Ø´Ù‡Ø¯' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Scene'}: {rec.get('scene','â€”')}\n\n"
        f"{'Ø§Ù„Ø¥Ø­Ø³Ø§Ø³ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Inner sensation'}: {rec.get('inner_sensation','')}\n\n"
        f"{'Ù„Ù…Ø§Ø°Ø§ Ø£Ù†Øª (Layer Z)' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Why you (Layer-Z)'}: {rec.get('why_you','')}\n\n"
        f"{'Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Practical fit'}: {rec.get('practical_fit','')}\n\n"
        f"{'Ø£ÙˆÙ„ Ø£Ø³Ø¨ÙˆØ¹' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'First week'}: {rec.get('first_week','')}\n\n"
        f"{'Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù…' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Progress markers'}: {rec.get('progress_markers','')}\n\n"
        f"{'Ø§Ù„ØµØ¹ÙˆØ¨Ø©' if lang=='Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Difficulty'}: {rec.get('difficulty',3)}/5\n"
        f"VR: {rec.get('vr_idea','')}\n"
    )

def _sanitize_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        # mask names
        for k, v in list(r.items()):
            if isinstance(v, str) and _violates(v):
                r[k] = _mask_names(v)
        # quality gate
        blob = " ".join([
            r.get("scene",""), r.get("inner_sensation",""),
            r.get("why_you",""), r.get("practical_fit",""),
            r.get("first_week",""), r.get("progress_markers","")
        ])
        if _too_generic(blob) or not _has_sensory(blob) or not _is_meaningful(r):
            r = _fallback_identity(i, lang)
        out.append(r)
    return out

# ========= PUBLIC API =========
def generate_sport_recommendation(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", user_id: str = "N/A") -> List[str]:
    if OpenAI_CLIENT is None:
        return ["âŒ OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù€ Quiz.", "â€”", "â€”"]

    analysis = analyze_user_from_answers(answers)
    silent = analyze_silent_drivers(answers, lang=lang) or []
    analysis["silent_drivers"] = silent

    persona = get_cached_personality(analysis, lang=lang)
    if not persona:
        persona = {"name":"SportSync Coach","tone":"Ø­Ø§Ø²Ù…-Ù‡Ø§Ø¯Ø¦","style":"Ø­Ø³Ù‘ÙŠ ÙˆØ§Ù‚Ø¹ÙŠ","philosophy":"Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡"}
        try: save_cached_personality(analysis, persona, lang=lang)
        except Exception: pass

    # === Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    msgs = _json_prompt(analysis, answers, persona, lang)
    try:
        resp = OpenAI_CLIENT.chat.completions.create(
            model=CHAT_MODEL, messages=msgs, temperature=0.9, max_tokens=1200
        )
        raw1 = (resp.choices[0].message.content or "").strip()
        print(f"[AI] model={CHAT_MODEL} len={len(raw1)} raw[:120]={raw1[:120]!r}")
    except Exception as e:
        return [f"âŒ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}", "â€”", "â€”"]

    if _violates(raw1): raw1 = _mask_names(raw1)
    parsed = _parse_json(raw1) or []
    cleaned = _sanitize_fill(parsed, lang)

    # Ù‡Ù„ Ù…Ø±Ù‘ Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©ØŸ (Ù„Ùˆ Ø£ÙŠ ÙˆØ§Ø­Ø¯Ø© Ø³Ù‚Ø·Øª Ù„Ù„ÙÙˆÙ„Ø¨Ø§Ùƒ Ù†Ø­Ø§ÙˆÙ„ ØªØ­Ø³ÙŠÙ† Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©)
    need_repair = any(_too_generic(" ".join([c.get("scene",""),c.get("why_you","")])) for c in cleaned)
    if need_repair:
        repair_prompt = {
            "role":"user",
            "content":(
                "Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø¬ÙˆØ¯Ø© Ø£Ø¹Ù„Ù‰ (Ø¨Ø¯ÙˆÙ† Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª): "
                "Ø§Ù…Ù„Ø£ ÙØ¬ÙˆØ§Øª why_you/first_week Ø¨Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø­Ø³ÙŠØ© ÙˆØ§Ù„Ø±Ø¨Ø· Ø¨Ù€ Layer-Z. "
                "Ø£Ø¹Ø¯ JSON ÙÙ‚Ø· Ø¨Ù†ÙØ³ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©."
            )
        }
        try:
            resp2 = OpenAI_CLIENT.chat.completions.create(
                model=CHAT_MODEL, messages=msgs+[{"role":"assistant","content":raw1}, repair_prompt],
                temperature=0.85, max_tokens=1200
            )
            raw2 = (resp2.choices[0].message.content or "").strip()
            if _violates(raw2): raw2 = _mask_names(raw2)
            parsed2 = _parse_json(raw2) or []
            cleaned2 = _sanitize_fill(parsed2, lang)
            # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£ÙØ¶Ù„ (Ø§Ù„Ø£Ø·ÙˆÙ„ Ø­Ø³Ù‘ÙŠÙ‹Ø§)
            def score(r: Dict[str,Any]) -> int:
                txt = " ".join([r.get("scene",""), r.get("inner_sensation",""), r.get("why_you",""), r.get("first_week","")])
                return len(txt)
            if sum(map(score, cleaned2)) > sum(map(score, cleaned)):
                cleaned = cleaned2
        except Exception:
            pass

    cards = [_format_card(cleaned[i], i, lang) for i in range(3)]

    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang, "answers": answers, "analysis": analysis,
                "silent_drivers": silent, "recommendations": cleaned
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    return cards
