# -- coding: utf-8 --
import os, json, math, random, time
from typing import Dict, Any, List, Tuple

try:
    from core.llm_client import make_llm_client, pick_models, chat_once
except Exception:
    make_llm_client = lambda: None
    pick_models = lambda: ("", "")
    chat_once = None  # type: ignore

try:
    from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"):
        return ["Ù…Ø­ÙÙ‘Ø² ØªÙƒØªÙŠÙƒÙŠ", "Ø§Ø³ØªÙƒØ´Ø§Ù Ø­Ø³ÙŠ", "Ù…ØªØ¹Ø© ØªØ­Ø¯Ù‘ÙŠ Ø³Ø±ÙŠØ¹Ø©"]

def _flags():
    def _t(x): return str(os.getenv(x, "")).strip().lower() in ("1","true","yes","on")
    return {
        "FORCE_LOCAL_FALLBACK": _t("FORCE_LOCAL_FALLBACK"),
        "DISABLE_LLM": _t("DISABLE_LLM"),
        "CHAT_MODEL": os.getenv("CHAT_MODEL", ""),
        "OPENAI_BASE_URL": os.getenv("OPENAI_BASE_URL", ""),
        "GROQ_API_KEY_set": bool(os.getenv("GROQ_API_KEY")),
        "OPENAI_API_KEY_set": bool(os.getenv("OPENAI_API_KEY")),
        "OPENROUTER_API_KEY_set": bool(os.getenv("OPENROUTER_API_KEY")),
    }

def _should_use_local(client):
    f = _flags()
    if f["FORCE_LOCAL_FALLBACK"] or f["DISABLE_LLM"]:
        return True, "env_flag"
    if client is None:
        return True, "no_client"
    return False, "llm_available"

def _diagnose():
    client = make_llm_client() if callable(make_llm_client) else None
    use_local, reason = _should_use_local(client)
    try: main, fb = pick_models()
    except Exception: main, fb = ("","")
    return {"mode": "local" if use_local else "llm", "reason": reason, "env": _flags(), "models":{"main":main,"fallback":fb}, "ts": time.time()}

def _pull(answers: Dict[str, Any], key: str):
    cell = answers.get(key, {})
    val = cell.get("answer", cell) if isinstance(cell, dict) else cell
    out = []
    if isinstance(val, str): out = [val.strip()]
    elif isinstance(val, list): out = [str(x).strip() for x in val if str(x).strip()]
    return [x.lower() for x in out if x]

def _score_axis(answers: Dict[str, Any]):
    intent = set(_pull(answers, "intent") + _pull(answers, "q_1") + _pull(answers, "goal"))
    likes  = set(_pull(answers, "likes") + _pull(answers, "q_2"))
    hates  = set(_pull(answers, "hates") + _pull(answers, "q_3"))
    txt = (" ".join(list(intent | likes)) + " ").lower()
    novelty_seek   = 0.2 + 0.6*any(k in txt for k in ["Ø¬Ø¯ÙŠØ¯","ØºØ§Ù…Ø±","vr","ØªÙ‚Ù†ÙŠØ©","ØªØ¬Ø±Ø¨Ø©","ØºÙŠØ± ØªÙ‚Ù„ÙŠØ¯ÙŠ","Ù…Ù‡Ù…Ø§Øª","missions","stealth","parkour"])
    sensory_depth  = 0.2 + 0.6*any(k in txt for k in ["Ø¥Ø­Ø³Ø§Ø³","ØµÙˆØª","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙ†ÙÙ‘Ø³","ØªØ£Ù…Ù‘Ù„","mindful","Ø­Ø³ÙŠ","flow"])
    tactical_drive = 0.2 + 0.6*any(k in txt for k in ["Ù‚Ø±Ø§Ø±","ØªÙƒØªÙŠÙƒ","Ù…Ù†Ø§ÙˆØ±Ø©","Ø¶ØºØ·","Ù‚ØªØ§Ù„","combat","Ù…Ù‡Ù…Ø§Øª"])
    flow_pref      = 0.2 + 0.6*any(k in txt for k in ["Ù‡Ø¯ÙˆØ¡","Ø§Ù†Ø³Ø¬Ø§Ù…","flow","ØªÙ†ÙÙ‘Ø³","ÙŠÙˆØºØ§","Ø¨ÙŠÙ„Ø§ØªØ³","ØªØ£Ù…Ù‘Ù„"])
    pace           = 3.0 + (1.0 if "Ø³Ø±ÙŠØ¹" in txt or "hiit" in txt else 0.0) - (1.0 if "Ù‡Ø§Ø¯Ø¦" in txt or "Ø®ÙÙŠÙ" in txt else 0.0)
    pace           = max(1.0, min(5.0, pace))
    social = 0.0
    if any(k in txt for k in ["ÙØ±ÙŠÙ‚","Ø¬Ù…Ø§Ø¹ÙŠ","team","Ø®Ù…Ø§Ø³ÙŠØ©","Ø³Ù„Ø©"]): social += 0.8
    if any(k in txt for k in ["ÙˆØ­Ø¯ÙŠ","ÙØ±Ø¯ÙŠ","solo"]):                   social -= 0.8
    social = max(-1.0, min(1.0, social))
    io = 0.0
    if any(k in txt for k in ["Ù‡ÙˆØ§Ø¡ Ø·Ù„Ù‚","outdoor","Ø­Ø¯ÙŠÙ‚Ø©","Ù…Ù…Ø´Ù‰"]): io += 0.7
    if any(k in txt for k in ["ØµØ§Ù„Ø§Øª","indoor","Ù†Ø§Ø¯ÙŠ"]):             io -= 0.7
    io = max(-1.0, min(1.0, io))
    if any(k in hates for k in ["Ù…Ù„Ù„","Ø±ÙˆØªÙŠÙ†","ØªÙƒØ±Ø§Ø±"]): novelty_seek = max(novelty_seek, 0.7)
    if any(k in hates for k in ["Ø§Ø²Ø¯Ø­Ø§Ù…","Ø²Ø­Ù…Ø©"]): social = min(social, 0.0)
    return {k: float(round(v,2)) for k,v in dict(novelty_seek=novelty_seek, sensory_depth=sensory_depth, tactical_drive=tactical_drive, flow_pref=flow_pref, pace=pace, social=social, indoor_outdoor=io).items()}

def _compose_cards(ax, z_axes, lang):
    is_ar = (lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    def _name1():
        if ax["tactical_drive"]>0.6 and ax["novelty_seek"]>0.6: return "Ù‚ØªØ§Ù„ ØªÙƒØªÙŠÙƒÙŠ ØºØ§Ù…Ø±" if is_ar else "Tactical Immersive Combat"
        if ax["flow_pref"]>0.6 and ax["sensory_depth"]>0.6:     return "Ù…Ù‡Ù…Ø§Øª ØªØ¯ÙÙ‘Ù‚ Ø®ÙÙŠ" if is_ar else "Stealth-Flow Missions"
        return "Ø¹Ø¨ÙˆØ± Ù…ÙŠØ¯Ø§Ù†ÙŠ Ø¥ÙŠÙ‚Ø§Ø¹ÙŠ" if is_ar else "Rhythmic Field Traverse"
    def _name2():
        return ("Ø­Ù„Ù‚Ø© Ø¨Ø§Ø±ÙƒÙˆØ± Ø­Ø¶Ø±ÙŠØ©" if is_ar else "Urban Parkour Loop") if ax["indoor_outdoor"]>=0.4 else ("Ø¯Ø§Ø¦Ø±Ø© Ù…Ø±ÙˆÙ†Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø§Ø³ØªÙˆØ¯ÙŠÙˆ" if is_ar else "Studio Mobility Circuit")
    def _name3():
        return ("Ù…Ø®ØªØ¨Ø± Ø­Ø³Ù‘ÙŠ Ø¨Ø§Ù„ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ (Ø¨Ø¯ÙˆÙ† Ù‚ØªØ§Ù„)" if is_ar else "VR Sense-Lab (no-combat)") if ax["novelty_seek"]>0.5 else ("Ù…Ø²ÙŠØ¬ Ø®ÙÙ‘Ø© Ø°Ù‡Ù†ÙŠ" if is_ar else "Mindful Agility Blend")
    def blurb(title):
        if is_ar:
            L=[f"â€¢ Ù„Ù…Ø§Ø°Ø§ {title}: Ù…ÙˆØ§Ø¡Ù…Ø© Ù„Ù…Ø­ÙˆØ±ÙŠ Z: {'ØŒ '.join(z_axes[:2])}.",
               f"â€¢ Ø§Ù„Ø³Ø±Ø¹Ø©: {int(round(ax['pace']))}/5 â€” {'Ù‡ÙˆØ§Ø¡ Ø·Ù„Ù‚' if ax['indoor_outdoor']>0 else 'Ø¯Ø§Ø®Ù„ Ø§Ù„ØµØ§Ù„Ø§Øª'}.",
               f"â€¢ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ: {'ÙØ±ÙŠÙ‚/Ø§Ø²Ø¯ÙˆØ§Ø¬' if ax['social']>0.3 else ('ÙØ±Ø¯ÙŠ' if ax['social']<-0.3 else 'Ù…Ø®ØªÙ„Ø·')}.",
               "â€¢ Ù…Ø¤Ø´Ø±Ø§Øª Ø­Ø³ÙŠØ©: ØªÙ†ÙÙ‘Ø³/ØµÙˆØª/Ù„Ù…Ø³ Ù…Ø¶Ø¨ÙˆØ·Ø© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ¹Ø©."]
            return "\n".join(L)
        else:
            L=[f"â€¢ Why {title}: maps to your Z-axes: {', '.join(z_axes[:2])}.",
               f"â€¢ Pace: {int(round(ax['pace']))}/5 â€” {'outdoor' if ax['indoor_outdoor']>0 else 'indoor'}.",
               f"â€¢ Social: {'team/duo' if ax['social']>0.3 else ('solo' if ax['social']<-0.3 else 'hybrid')}.",
               "â€¢ Sensory cues tuned for sustained enjoyment."]
            return "\n".join(L)
    titles=[_name1(),_name2(),_name3()]
    headers_ar=["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1","ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2","ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    headers_en=["ğŸŸ¢ Recommendation #1","ğŸŒ¿ Recommendation #2","ğŸ”® Recommendation #3 (Creative)"]
    cards=[]
    for i,t in enumerate(titles,1):
        hdr=headers_ar[i-1] if is_ar else headers_en[i-1]
        body=blurb(t)
        plan="â€¢ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ù„Ø³Ø©: 25â€“35 Ø¯Ù‚ÙŠÙ‚Ø©ØŒ 3 Ù…Ø±Ø§Øª/Ø£Ø³Ø¨ÙˆØ¹. ÙØªØ±Ø§Øª 3â€“6 Ø¯Ù‚Ø§Ø¦Ù‚ ÙŠÙ„ÙŠÙ‡Ø§ Ø¯Ù‚ÙŠÙ‚Ø© ØªÙ‡Ø¯Ø¦Ø© Ø­Ø³Ù‘ÙŠØ©." if is_ar else "â€¢ Session: 25â€“35 min, 3Ã—/week. 3â€“6 min bouts + 1-min sensory downshift."
        cards.append(f"{hdr}\n\n{t}\n\n{body}\n{plan}\nâ€” Sports Sync")
    return cards

def _local_generate(answers, lang):
    ax=_score_axis(answers)
    z=analyze_silent_drivers(answers, lang=lang) or []
    random.seed(json.dumps(ax, sort_keys=True))
    return _compose_cards(ax, z, lang)[:3]

def generate_sport_recommendation(answers, lang="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"):
    client = make_llm_client() if callable(make_llm_client) else None
    use_local, reason = _should_use_local(client)
    if use_local or not callable(chat_once):
        return _local_generate(answers, lang)
    try:
        main_chain, fb = pick_models()
    except Exception:
        main_chain, fb = "gpt-4o", "gpt-4o-mini"
    msgs=[{"role":"system","content":"You are SportSync recommender. Avoid weight/time/money. Use psycho-metric axes. Return 3 cards."},
          {"role":"user","content":json.dumps({"answers":answers,"lang":lang}, ensure_ascii=False)}]
    try:
        text=chat_once(client, msgs, model=main_chain, temperature=0.7, max_tokens=900)
        parts=[p.strip() for p in text.split("\n\n") if p.strip()]
        if len(parts)<3: return _local_generate(answers, lang)
        return parts[:3]
    except Exception:
        return _local_generate(answers, lang)

def quick_diagnose():
    d=_diagnose()
    d["sample_axes"]=_score_axis({"intent":{"answer":["sample"]}})
    return d
