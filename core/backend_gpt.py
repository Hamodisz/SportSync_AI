# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
ØªÙˆØµÙŠØ§Øª "Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ©" Ø¨Ø«Ù„Ø§Ø« ÙƒØ±ÙˆØª Ø­Ø³Ù‘ÙŠØ© Ù…Ù†Ø¸Ù…Ø© + Layer-Z + Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ (Ù†ÙˆØ¹ÙŠØ© ÙÙ‚Ø·) + ÙÙƒØ±Ø© VR.
- Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ± (Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±).
- ÙŠÙØ³Ù…Ø­ Ø¨Ø°ÙƒØ± "Ø§Ø³Ù… Ø±ÙŠØ§Ø¶Ø©/Ù†Ù…Ø·" Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¶ÙˆØ­ (ÙÙƒÙ‘ Ø§Ù„Ø­Ø¸Ø± Ø§Ù„Ø°ÙƒÙŠ).
- ÙŠØ­Ø§ÙˆÙ„ Ù…Ø±ØªÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ù€ fallback. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/English.
- ÙŠÙØ±Ø¶ Ø­Ù‚ÙˆÙ„ Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØºÙ…ÙˆØ¶ Ø¥Ù„Ù‰ Ø±ÙŠØ§Ø¶Ø© ÙˆØ§Ø¶Ø­Ø©:
  sport_label, what_it_looks_like, win_condition, core_skills, mode, variant_vr, variant_no_vr
- Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù‡ÙˆÙŠØ© Ù…Ù†Ø¹Ù‹Ø§ Ù‚Ø§Ø·Ø¹Ù‹Ø§ (Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù„Ø³Ø© + Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ Ø¹Ø¨Ø± data/blacklist.json) Ù…Ø¹ ÙØ­Øµ ØªØ´Ø§Ø¨Ù‡ Ø¯Ù„Ø§Ù„ÙŠ.
- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Z-intent (ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ÙŠØ§) Ù…Ø¹ fallback Ù„ØºÙˆÙŠ Ø¥Ø°Ø§ ØªØ¹Ø°Ø±.
- Ù‚Ø¨Ù„ Ø£ÙŠ ØªÙˆÙ„ÙŠØ¯: Evidence Gate â€” Ù„Ø§ ØªÙˆØµÙŠØ§Øª Ø¨Ø¯ÙˆÙ† Ø£Ø¯Ù„Ø© ÙƒØ§ÙÙŠØ© (Ø­Ù„ Ø¬Ø°Ø±ÙŠ).
- Ø£Ù…Ø§Ù†: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ØºÙŠØ± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø© Ø¨Ø­Ø³Ø¨ CFG.security.
- ØªÙ„ÙŠÙ…ØªØ±ÙŠ: Ø¥Ø±Ø³Ø§Ù„ Ø£Ø­Ø¯Ø§Ø« Ø¥Ù„Ù‰ DataPipe (Zapier/Ù…Ù„Ù Ù…Ø­Ù„ÙŠ).
"""

from __future__ import annotations

import os, json, re, hashlib, importlib
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
from datetime import datetime

# ========= OpenAI =========
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø£Ø¶Ù Ø§Ù„Ø­Ø²Ù…Ø© ÙÙŠ requirements: openai>=1.6.1,<2") from e

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OpenAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ========= App Config =========
try:
    from core.app_config import get_config
    CFG = get_config()
except Exception:
    CFG = {}

CHAT_MODEL = (CFG.get("llm") or {}).get("model", os.getenv("CHAT_MODEL", "gpt-4o"))
ALLOW_SPORT_NAMES = (CFG.get("recommendations") or {}).get("allow_sport_names", True)

REC_RULES = CFG.get("recommendations") or {}
_MIN_CHARS = int(REC_RULES.get("min_chars", 220))
_REQUIRE_WIN = bool(REC_RULES.get("require_win_condition", True))
_MIN_CORE_SKILLS = int(REC_RULES.get("min_core_skills", 3))

# Evidence Gate thresholds (defaults if not provided)
EGCFG = (CFG.get("analysis") or {}).get("egate", {}) if isinstance(CFG.get("analysis"), dict) else {}
_EG_MIN_ANSWERS = int(EGCFG.get("min_answered", 3))
_EG_MIN_TOTAL_CHARS = int(EGCFG.get("min_total_chars", 120))
_EG_REQUIRED_KEYS = list(EGCFG.get("required_keys", []))  # Ù…Ø«Ø§Ù„: ["goal","injury_history"]

# ========= Project imports (with safe fallbacks) =========
try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: {list(content.keys())}")

# DataPipe (Zapier/Webhook/Disk)
try:
    from core.data_pipe import get_pipe
    _PIPE = get_pipe()
except Exception:
    _PIPE = None

# Security scrubber
try:
    from core.security import scrub_unknown_urls
except Exception:
    def scrub_unknown_urls(text_or_card: str, cfg: Dict[str, Any]) -> str:
        return text_or_card

# Evidence Gate (external) + fallback Ø¯Ø§Ø®Ù„ÙŠ
try:
    from core.evidence_gate import evaluate as egate_evaluate
except Exception:
    egate_evaluate = None  # Ø³Ù†Ø³ØªØ®Ø¯Ù… fallback Ø£Ø¯Ù†Ø§Ù‡

try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

# ========= Paths / Data =========
try:
    HERE = Path(_file_).resolve().parent
except NameError:
    HERE = Path.cwd()
ROOT = HERE.parent if HERE.name == "core" else HERE
DATA_DIR = (ROOT / "data").resolve()
DATA_DIR.mkdir(parents=True, exist_ok=True)

BL_PATH = DATA_DIR / "blacklist.json"
KB_PATH = DATA_DIR / "sportsync_knowledge.json"
AL_PATH = DATA_DIR / "labels_aliases.json"

# ========= Helpers: Files =========
def _load_json_safe(p: Path) -> dict:
    try:
        with p.open("r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def _save_json_atomic(p: Path, payload: dict) -> None:
    tmp = p.with_suffix(".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    tmp.replace(p)

# ========= Helpers: Arabic normalization =========
_AR_DIAC = r"[ÙÙ‹ÙÙŒÙÙÙ’Ù‘Ù€]"
def _normalize_ar(t: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ù…Ø¨Ø³Ù‘Ø· Ù„Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©/Ø§Ù„Ù…Ù†Ø¹."""
    if not t: return ""
    t = re.sub(_AR_DIAC, "", t)
    t = t.replace("Ø£","Ø§").replace("Ø¥","Ø§").replace("Ø¢","Ø§")
    t = t.replace("Ø¤","Ùˆ").replace("Ø¦","ÙŠ")
    t = t.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    t = re.sub(r"\s+", " ", t).strip()
    return t

# ========= Analysis import (user traits) =========
def _call_analyze_user_from_answers(user_id: str, answers: Dict[str, Any], lang: str) -> Dict[str, Any]:
    """ÙŠØ­Ø§ÙˆÙ„ Ø£ÙƒØ«Ø± Ù…Ù† ØªÙˆÙ‚ÙŠØ¹/Ù…Ø³Ø§Ø± Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
    try:
        from analysis.user_analysis import analyze_user_from_answers as _ana
        try:
            out = _ana(user_id=user_id, answers=answers, lang=lang)
        except TypeError:
            out = _ana(answers)
        return {"traits": out} if isinstance(out, list) else (out or {})
    except Exception:
        try:
            from core.user_analysis import analyze_user_from_answers as _ana2
            try:
                out = _ana2(user_id=user_id, answers=answers, lang=lang)
            except TypeError:
                out = _ana2(answers)
            return {"traits": out} if isinstance(out, list) else (out or {})
        except Exception:
            return {"quick_profile": "fallback", "raw_answers": answers}

# ========= Layer Z (silent drivers) =========
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
            return ["Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±", "ØªÙØ¶ÙŠÙ„ ØªØ­Ø¯Ù‘ÙŠ Ø°Ù‡Ù†ÙŠ"]

# ========= Intent (Z-intent) =========
def _call_analyze_intent(answers: Dict[str, Any], lang: str="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
    """
    ÙŠØ­Ø§ÙˆÙ„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ø­Ù„Ù‘Ù„ Ù†ÙˆØ§ÙŠØ§ Ù…Ù† Ù…Ø´Ø±ÙˆØ¹ÙƒØ› ÙˆØ¥Ù„Ø§ ÙŠØ³ØªØ®Ø¯Ù… fallback Ù„ØºÙˆÙŠ Ø¨Ø³ÙŠØ·.
    """
    for modpath in ("core.layer_z_engine", "analysis.layer_z_engine"):
        try:
            mod = importlib.import_module(modpath)
            if hasattr(mod, "analyze_user_intent"):
                return list(mod.analyze_user_intent(answers, lang=lang) or [])
        except Exception:
            pass

    # Fallback Ù„ØºÙˆÙŠ Ø¨Ø³ÙŠØ·
    intents = set()
    blob = " ".join(
        (v["answer"] if isinstance(v, dict) and "answer" in v else str(v))
        for v in (answers or {}).values()
    ).lower()
    blob_ar = _normalize_ar(blob)

    def any_of(words: List[str]) -> bool:
        return any(w in blob or w in blob_ar for w in words)

    if any_of(["vr","ÙˆØ§Ù‚Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ","Ù†Ø¸Ø§Ø±Ù‡","Ø§ÙØªØ±Ø§Ø¶ÙŠ"]): intents.add("VR")
    if any_of(["ØªÙƒØªÙŠÙƒ","ØªÙƒØªÙŠÙƒÙŠ","tactic","ambush","ÙƒÙ…ÙŠÙ†"]): intents.add("ØªÙƒØªÙŠÙƒÙŠ")
    if any_of(["Ù‚ØªØ§Ù„","Ù…Ø¨Ø§Ø±Ø²Ù‡","Ø§Ø´ØªØ¨Ø§Ùƒ","combat"]): intents.add("Ù‚ØªØ§Ù„ÙŠ")
    if any_of(["Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙØ³","ØªÙ†ÙÙ‘Ø³","ØªØ±ÙƒÙŠØ²","ØµÙØ§Ø¡","calm","breath"]): intents.add("Ù‡Ø¯ÙˆØ¡/ØªÙ†ÙÙ‘Ø³")
    if any_of(["Ø³Ø±Ø¹Ù‡","Ø§Ù†Ø¯ÙØ§Ø¹","Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†","Ø§Ù†Ù‚Ø¶Ø§Ø¶","strike","fast"]): intents.add("Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†")
    if any_of(["ÙØ±Ø¯ÙŠ","Ù„ÙˆØ­Ø¯ÙŠ","solo","ÙˆØ­ÙŠØ¯"]): intents.add("ÙØ±Ø¯ÙŠ")
    if any_of(["ÙØ±ÙŠÙ‚","Ø¬Ù…Ø§Ø¹ÙŠ","team","group"]): intents.add("Ø¬Ù…Ø§Ø¹ÙŠ")
    if any_of(["Ù„ØºØ²","Ø§Ù„ØºØ§Ø²","puzzle","Ø®Ø¯Ø¹Ù‡ Ø¨ØµØ±ÙŠÙ‡"]): intents.add("Ø£Ù„ØºØ§Ø²/Ø®Ø¯Ø§Ø¹")
    if any_of(["Ø¯Ù‚Ù‡","ØªØµÙˆÙŠØ¨","Ù†Ø´Ø§Ù†","precision","mark"]): intents.add("Ø¯Ù‚Ø©/ØªØµÙˆÙŠØ¨")
    if any_of(["ØªØ®ÙÙŠ","stealth","Ø¸Ù„"]): intents.add("ØªØ®ÙÙ‘ÙŠ")
    if any_of(["ØªÙˆØ§Ø²Ù†","Ù‚Ø¨Ø¶Ù‡","grip","balance","ØªØ³Ù„Ù‚","climb"]): intents.add("Ù‚Ø¨Ø¶Ø©/ØªÙˆØ§Ø²Ù†")
    return list(intents)

# ========= (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù…ÙØ´ÙÙ‘ÙØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª =========
def _extract_profile(answers: Dict[str, Any], lang: str) -> Optional[Dict[str, Any]]:
    prof = answers.get("profile") if isinstance(answers, dict) else None
    if isinstance(prof, dict):
        return prof
    encode_answers = None
    try:
        from core.answers_encoder import encode_answers as _enc
        encode_answers = _enc
    except Exception:
        try:
            from analysis.answers_encoder import encode_answers as _enc
            encode_answers = _enc
        except Exception:
            encode_answers = None
    if encode_answers is None:
        return None
    try:
        enc = encode_answers(answers, lang=lang)
        preferences = enc.get("prefs", enc.get("preferences", {}))
        z_markers = enc.get("z_markers", [])
        signals   = enc.get("signals", [])
        hints = " | ".join([*z_markers, *signals])[:1000]
        return {
            "scores": enc.get("scores", {}),
            "axes": enc.get("axes", {}),
            "preferences": preferences,
            "hints_for_prompt": hints,
            "vr_inclination": enc.get("vr_inclination", 0),
            "confidence": enc.get("confidence", 0.0),
            "signals": signals,
            "z_markers": z_markers
        }
    except Exception:
        return None

# ========= Evidence Gate (fallback) =========
def _norm_answer_value(v: Any) -> str:
    if v is None: return ""
    if isinstance(v, dict):
        if "answer" in v: return str(v.get("answer") or "")
        if "value" in v: return str(v.get("value") or "")
        return json.dumps(v, ensure_ascii=False)
    if isinstance(v, list):
        return ", ".join(map(str, v))
    return str(v)

def _egate_fallback(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, Any]:
    """ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ù„Ø© Ø¨Ø³ÙŠØ· Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± core/evidence_gate.py."""
    if not isinstance(answers, dict) or not answers:
        status = "fail"
        total_chars = 0
        answered = 0
    else:
        vals = [_norm_answer_value(v) for v in answers.values() if str(v).strip()]
        total_chars = sum(len(s.strip()) for s in vals)
        answered = sum(1 for s in vals if len(s.strip()) >= 3)

        # required keys Ø¥Ù† ÙˆÙØ¬Ø¯Øª
        if _EG_REQUIRED_KEYS:
            if any(not _norm_answer_value(answers.get(k, "")).strip() for k in _EG_REQUIRED_KEYS):
                status = "fail"
            else:
                status = "pass" if (answered >= _EG_MIN_ANSWERS and total_chars >= _EG_MIN_TOTAL_CHARS) else "borderline"
        else:
            if answered == 0 or total_chars < 40:
                status = "fail"
            elif answered < _EG_MIN_ANSWERS or total_chars < _EG_MIN_TOTAL_CHARS:
                status = "borderline"
            else:
                status = "pass"

    # followups (Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©)
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        followups = [
            "ØªÙØ¶Ù‘Ù„ Ø§Ù„Ù„Ø¹Ø¨: ÙØ±Ø¯ÙŠ Ø£Ù… Ø¬Ù…Ø§Ø¹ÙŠØŸ ÙˆÙ„Ù…Ø§Ø°Ø§ Ø¨Ø´ä¸€å¥.",
            "ØªÙ…ÙŠÙ„ Ù„Ù‡Ø¯ÙˆØ¡ ÙˆØ§Ù†Ø³ÙŠØ§Ø¨ Ø£Ù… Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ† ÙˆÙ‚Ø±Ø§Ø±Ø§Øª Ø®Ø§Ø·ÙØ©ØŸ",
            "Ù‡Ù„ ØªØ­Ø¨ Ø¯Ù‚Ù‘Ø©/ØªØµÙˆÙŠØ¨ Ø£Ù… Ø£Ù„ØºØ§Ø²/Ø®Ø¯Ø§Ø¹ Ø¨ØµØ±ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©ØŸ"
        ]
    else:
        followups = [
            "Do you prefer solo or team play â€” and why, in one short line?",
            "Do you want calm/flow or adrenaline/snap decisions?",
            "Are you more into precision/aim or puzzles/visual feints in motion?"
        ]

    return {
        "status": "fail" if answered == 0 or total_chars < 40 else status,
        "answered": int(answered),
        "total_chars": int(total_chars),
        "required_missing": [k for k in _EG_REQUIRED_KEYS if not _norm_answer_value((answers or {}).get(k, "")).strip()],
        "followup_questions": followups[:3]
    }

def _run_egate(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Dict[str, Any]:
    if callable(egate_evaluate):
        try:
            res = egate_evaluate(answers=answers, lang=lang, cfg=EGCFG)
            if isinstance(res, dict) and "status" in res:
                return res
        except Exception:
            pass
    return _egate_fallback(answers, lang=lang)

def _format_followup_card(followups: List[str], lang: str) -> str:
    head = "ğŸ§­ Ù†Ø­ØªØ§Ø¬ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù‚ØµÙŠØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªÙˆØµÙŠØ©" if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "ğŸ§­ I need a few quick answers first"
    tips = "Ø§ÙƒØªØ¨ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„." if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "One short line per question."
    lines = [head, "", tips, ""]
    for q in followups:
        lines.append(f"- {q}")
    lines.append("")
    lines.append("Ø£Ø±Ø³Ù„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ ÙˆØ³Ù†Ù‚ØªØ±Ø­ Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙÙˆØ±Ù‹Ø§." if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                 else "Send your answers and Iâ€™ll propose a clear sport-identity right away.")
    return "\n".join(lines)

# ========= Rules & helpers =========
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_AVOID_GENERIC = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]
_SENSORY = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªØ±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

# Ø£Ø³Ù…Ø§Ø¡/Ø£Ù†Ù…Ø§Ø· Ø¹Ø§Ù…Ø© Ù†Ù…Ù†Ø¹Ù‡Ø§ Ù„Ø£Ù†Ù‡Ø§ Ø±ÙƒÙŠÙƒØ©
_GENERIC_LABELS = {
    "impressive compact", "impressive-compact", "generic sport", "sport identity",
    "movement flow", "basic flow", "simple flow", "body flow"
}

_FORBIDDEN_SENT = re.compile(
    r"(\b\d+(\.\d+)?\s*(?:min|mins|minute|minutes|second|seconds|hour|hours|Ø¯Ù‚ÙŠÙ‚Ø©|Ø¯Ù‚Ø§Ø¦Ù‚|Ø«Ø§Ù†ÙŠØ©|Ø«ÙˆØ§Ù†ÙŠ|Ø³Ø§Ø¹Ø©|Ø³Ø§Ø¹Ø§Øª)\b|"
    r"(?:rep|reps|set|sets|ØªÙƒØ±Ø§Ø±|Ø¹Ø¯Ø©|Ø¹Ø¯Ø§Øª|Ø¬ÙˆÙ„Ø©|Ø¬ÙˆÙ„Ø§Øª|Ã—)|"
    r"(?:ØªÙƒÙ„ÙØ©|Ù…ÙŠØ²Ø§Ù†ÙŠØ©|cost|budget|Ø±ÙŠØ§Ù„|Ø¯ÙˆÙ„Ø§Ø±|\$|â‚¬)|"
    r"(?:Ø¨Ø§Ù„Ø¨ÙŠØª|ÙÙŠ\s*Ø§Ù„Ø¨ÙŠØª|Ù‚Ø±Ø¨\s*Ø§Ù„Ù…Ù†Ø²Ù„|Ø¨Ø§Ù„Ù…Ù†Ø²Ù„|ÙÙŠ\s*Ø§Ù„Ù†Ø§Ø¯ÙŠ|ÙÙŠ\s*Ø§Ù„Ø¬ÙŠÙ…|ØµØ§Ù„Ø©|Ù†Ø§Ø¯ÙŠ|Ø¬ÙŠÙ…|ØºØ±ÙØ©|Ø³Ø§Ø­Ø©|Ù…Ù„Ø¹Ø¨|Ø­Ø¯ÙŠÙ‚Ø©|Ø´Ø§Ø·Ø¦|"
    r"Ø·Ø¨ÙŠØ¹Ø©|Ø®Ø§Ø±Ø¬ÙŠ(?:Ø©)?|Ø¯Ø§Ø®Ù„(?:ÙŠ|ÙŠØ©)?|outdoor|indoor|park|beach|gym|studio))",
    re.IGNORECASE
)

def _contains_blocked_name(t: str) -> bool:
    if not t: return False
    return bool(_name_re.search(t)) or bool(_name_re.search(_normalize_ar(t)))

def _mask_names(t: str) -> str:
    if ALLOW_SPORT_NAMES:
        return t or ""
    s = t or ""
    s = _name_re.sub("â€”", s)
    if s == (t or "") and _contains_blocked_name(t):
        s = "â€”"
    return s

def _split_sentences(text: str) -> List[str]:
    if not text: return []
    return [s.strip() for s in re.split(r"(?<=[\.\!\?ØŸ])\s+|[\nØŒ]+", text) if s.strip()]

def _scrub_forbidden(text: str) -> str:
    kept = [s for s in _split_sentences(text) if not _FORBIDDEN_SENT.search(_normalize_ar(s))]
    return "ØŒ ".join(kept).strip(" .ØŒ")

def _answers_to_bullets(answers: Dict[str, Any]) -> str:
    out = []
    for k, v in (answers or {}).items():
        if k == "profile":
            continue
        if isinstance(v, dict):
            q, a = v.get("question", k), v.get("answer", "")
        else:
            q, a = str(k), v
        if isinstance(a, list):
            a = ", ".join(map(str, a))
        out.append(f"- {q}: {a}")
    return "\n".join(out)

def _too_generic(text: str, min_chars: int = 280) -> bool:
    t = (text or "").strip()
    return len(t) < min_chars or any(p in t for p in _AVOID_GENERIC)

def _has_sensory(text: str, min_hits: int = 3) -> bool:
    return sum(1 for w in _SENSORY if w in (text or "")) >= min_hits

def _is_meaningful(rec: Dict[str, Any]) -> bool:
    blob = " ".join([
        rec.get("sport_label",""), rec.get("what_it_looks_like",""),
        rec.get("why_you",""), rec.get("first_week",""),
        rec.get("progress_markers",""), rec.get("win_condition","")
    ]).strip()
    return len(blob) >= 120

# ========= Alignment with Z-axes =========
_AR_TOK = {
    "calm": ["Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙÙ‘Ø³","Ø¨Ø·ÙŠØ¡","Ø§Ø³ØªØ±Ø®Ø§Ø¡","ØµÙØ§Ø¡","Ø³ÙƒÙˆÙ†"],
    "adren": ["Ø§Ù†Ø¯ÙØ§Ø¹","ÙƒÙ…ÙŠÙ†","Ø³Ø±ÙŠØ¹","Ø§Ù†Ù‚Ø¶Ø§Ø¶","Ø¥Ø«Ø§Ø±Ø©","Ù‚Ø±Ø§Ø± Ø®Ø§Ø·Ù"],
    "solo": ["ÙØ±Ø¯ÙŠ","Ù„ÙˆØ­Ø¯Ùƒ","Ø°Ø§ØªÙŠØ©"],
    "group": ["Ø¬Ù…Ø§Ø¹Ø©","Ø´Ø±ÙŠÙƒ","ÙØ±ÙŠÙ‚","ØªØ¹Ø§ÙˆÙ†"],
    "tech": ["ØªÙ‚Ù†ÙŠØ©","ØªÙØ§ØµÙŠÙ„","ØµÙ‚Ù„","Ø¯Ù‚Ø©","Ø¶Ø¨Ø·"],
    "intu": ["Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø³Ø§Ø³","Ø­Ø¯Ø³","ØªÙ„Ù‚Ø§Ø¦ÙŠØ©","ØªØ¯ÙÙ‘Ù‚"]
}
_EN_TOK = {
    "calm": ["calm","breath","slow","relax","settle"],
    "adren": ["burst","fast","risk","strike","adrenaline"],
    "solo": ["solo","alone","individual"],
    "group": ["team","partner","group","co-op"],
    "tech": ["technique","detail","precision","drill","refine"],
    "intu": ["by feel","intuitive","flow","improvise"]
}

def _axes_expectations(axes: Dict[str, float], lang: str) -> Dict[str, List[str]]:
    tok = _AR_TOK if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else _EN_TOK
    out: Dict[str, List[str]] = {}
    if not isinstance(axes, dict): return out
    ca = axes.get("calm_adrenaline")
    if isinstance(ca, (int, float)):
        out["calm_adrenaline"] = tok["adren"] if ca >= 0.5 else tok["calm"] if ca <= -0.5 else []
    sg = axes.get("solo_group")
    if isinstance(sg, (int, float)):
        out["solo_group"] = tok["group"] if sg >= 0.5 else tok["solo"] if sg <= -0.5 else []
    ti = axes.get("tech_intuition")
    if isinstance(ti, (int, float)):
        out["tech_intuition"] = tok["intu"] if ti >= 0.5 else tok["tech"] if ti <= -0.5 else []
    return out

def _mismatch_with_axes(rec: Dict[str, Any], axes: Dict[str, float], lang: str) -> bool:
    exp = _axes_expectations(axes or {}, lang)
    if not exp: return False
    blob = " ".join(str(rec.get(k,"")) for k in ("what_it_looks_like","inner_sensation","why_you","first_week"))
    blob_l = blob.lower()
    for _, words in exp.items():
        if words and not any(w.lower() in blob_l for w in words):
            return True
    return False

# ========= Label normalization / similarity =========
def _canonical_label(label: str) -> str:
    if not label: return ""
    lab = re.sub(r"\s+", " ", label).strip(" -â€”:ØŒ").lower()
    lab = _normalize_ar(lab)
    return lab

def _label_is_generic(label: str) -> bool:
    lab = _canonical_label(label)
    return (lab in _GENERIC_LABELS) or (len(lab) <= 3)

def _tokenize(text: str) -> List[str]:
    if not text: return []
    t = _normalize_ar(text.lower())
    toks = re.split(r"[^a-zA-Z0-9\u0600-\u06FF]+", t)
    return [w for w in toks if w and len(w) > 2]

def _sig_for_rec(r: Dict[str, Any]) -> set:
    core = r.get("core_skills") or []
    core_txt = " ".join(core) if isinstance(core, list) else str(core)
    toks = set(_tokenize(r.get("sport_label","")) + _tokenize(core_txt))
    return toks

def _jaccard(a: set, b: set) -> float:
    if not a and not b: return 1.0
    inter = len(a & b)
    union = len(a | b) or 1
    return inter / union

# ========= Sanitizers / Fallbacks =========
def _sanitize_record(r: Dict[str, Any]) -> Dict[str, Any]:
    r = dict(r or {})
    r.pop("practical_fit", None)
    for k in ("sport_label","scene","what_it_looks_like","inner_sensation","why_you",
              "first_week","progress_markers","win_condition","core_skills","variant_vr","variant_no_vr","vr_idea","mode"):
        if isinstance(r.get(k), str):
            r[k] = _scrub_forbidden(_mask_names(r[k].strip()))
    if isinstance(r.get("core_skills"), str):
        parts = [p.strip(" -â€¢\t") for p in re.split(r"[,\nØŒ]+", r["core_skills"]) if p.strip()]
        r["core_skills"] = parts[:6]
    if not isinstance(r.get("core_skills"), list):
        r["core_skills"] = []
    try:
        d = int(r.get("difficulty", 3))
        r["difficulty"] = max(1, min(5, d))
    except Exception:
        r["difficulty"] = 3
    if r.get("mode") not in ("Solo","Team","Solo/Team","ÙØ±Ø¯ÙŠ","Ø¬Ù…Ø§Ø¹ÙŠ","ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ"):
        r["mode"] = r.get("mode","Solo")
    return r

def _fallback_identity(i: int, lang: str) -> Dict[str, Any]:
    """ÙÙˆÙ„Ø¨Ø§Ùƒ Ù‚ÙˆÙŠ ÙŠØ¹Ø·ÙŠ Ø±ÙŠØ§Ø¶Ø© ÙˆØ§Ø¶Ø­Ø© Ø¨Ø¯ÙˆÙ† Ø£Ø±Ù‚Ø§Ù…/Ø£Ù…Ø§ÙƒÙ†."""
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        presets = [
            {
                "sport_label":"Tactical Immersive Combat",
                "what_it_looks_like":"Ø³Ø§Ø­Ø© Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ØµØ±ÙŠØ© Ø£Ùˆ VR: ØªØªØ¨Ù‘Ø¹ØŒ ÙƒÙ…ÙŠÙ†ØŒ Ù‚Ø±Ø§Ø± Ø®Ø§Ø·ÙØŒ Ø§Ù‚ØªØ±Ø§Ø¨ Ù…Ø­Ø³ÙˆØ¨ØŒ Ø§Ù†Ø³Ø­Ø§Ø¨ Ø¢Ù…Ù†.",
                "inner_sensation":"Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø°Ù‡Ù†ÙŠ Ù…Ø¹ ÙŠÙ‚Ø¸Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ«Ù‚Ø© Ù‡Ø§Ø¯Ø¦Ø©.",
                "why_you":"ØªÙƒØ±Ù‡ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØªÙØ¶Ù‘Ù„ ØµØ±Ø§Ø¹Ù‹Ø§ ØªÙƒØªÙŠÙƒÙŠÙ‹Ø§ ÙŠØ®ØªØ¨Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„Ø£Ø¹ØµØ§Ø¨.",
                "first_week":"Ø§Ø¨Ø¯Ø£ Ø¨Ø¬ÙˆÙ„Ø© Ø­Ø³Ù‘ÙŠØ©: ØªØ¹Ø±Ù‘Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ØŒ Ø¬Ø±Ù‘Ø¨ Ø§Ù‚ØªØ±Ø§Ø¨/Ø§Ù†Ø³Ø­Ø§Ø¨ØŒ ÙˆØ«Ø¨Ù‘Øª ØªÙ†ÙÙ‘Ø³Ùƒ Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ø±Ø§Ø±.",
                "progress_markers":"Ù‚Ø±Ø§Ø±Ø§Øª Ø£Ø³Ø±Ø¹ØŒ Ù‡Ø¯ÙˆØ¡ ØªØ­Øª Ø§Ù„Ø¶ØºØ·ØŒ Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø³ÙŠØ·Ø±Ø© Ø£Ø¹Ù„Ù‰.",
                "win_condition":"Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù‡Ø¯Ù Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù Ø£Ùˆ ØªØ¹Ø·ÙŠÙ„ 'Ø§Ù„Ø®ØµÙ…' Ø¨Ù‚Ø±Ø§Ø± Ø®Ø§Ø·Ù.",
                "core_skills":["ØªØªØ¨Ù‘Ø¹ Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø±Ø¤ÙŠØ©","ØªØºÙŠÙŠØ± Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹","Ø«Ø¨Ø§Øª Ø§Ù„ØªÙˆØ§Ø²Ù†","ØªÙ†ÙÙ‘Ø³ Ù‡Ø§Ø¯Ø¦"],
                "mode":"Solo/Team",
                "variant_vr":"Ù…Ø¨Ø§Ø±Ø²Ø§Øª ØªÙƒØªÙŠÙƒÙŠØ© ÙÙŠ VR Ù…Ø¹ ØªØªØ¨Ø¹ Ù…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ© Ø§Ù„Ø®ØµÙ….",
                "variant_no_vr":"Ø¹Ù‚Ø¨Ø§Øª Ø®ÙÙŠÙØ© Ù…Ø¹ Ù…Ù…Ø±Ø§Øª Ø¸Ù„Ù‘.",
                "difficulty":3
            },
            {
                "sport_label":"Stealth-Flow Missions",
                "what_it_looks_like":"Ù…Ø³Ø§Ø± ØµØ§Ù…Øª Ù…ØªØ¯Ø±Ù‘Ø¬: Ø§Ø®ØªØ¨Ø§Ø¡ Ù‚ØµÙŠØ±ØŒ Ø¸Ù‡ÙˆØ± Ù…Ø­Ø³ÙˆØ¨ØŒ Ù„Ù…Ø³ 'Ø¹Ù„Ø§Ù…Ø©' Ø«Ù… Ø§Ø®ØªÙØ§Ø¡.",
                "inner_sensation":"ØªØ±ÙƒÙŠØ² Ø¹Ù…ÙŠÙ‚ ÙˆØªÙ†Ø¸ÙŠÙ… Ù„Ù„Ù†ÙØ³ Ù…Ø¹ Ø­Ø±ÙƒØ© Ù†Ø§Ø¹Ù…Ø©.",
                "why_you":"ØªØ¨ØºÙ‰ ØªÙ‚Ø¯Ù‘Ù… Ù…Ù„Ù…ÙˆØ³ Ø¨Ø¯ÙˆÙ† Ø¶Ø¬ÙŠØ¬ ÙˆØªØ­Ø¨ Ø§Ù„Ø¥ØªÙ‚Ø§Ù† Ø§Ù„Ù‡Ø§Ø¯Ø¦.",
                "first_week":"Ø¯Ø±Ù‘Ø¨ ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±Ø¹Ø§Øª Ø¨Ø³Ù„Ø§Ø³Ø© ÙˆÙ…Ù„Ø§Ø­Ø¸Ø© Ø§Ù„Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¢Ù…Ù†Ø©.",
                "progress_markers":"ØªÙˆØªØ± Ø£Ù‚Ù„ØŒ Ù†Ø¹ÙˆÙ…Ø© Ø­Ø±ÙƒØ©ØŒ Ù‚Ø±Ø§Ø±Ø§Øª Ø£ÙˆØ¶Ø­.",
                "win_condition":"Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù.",
                "core_skills":["ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¸Ù‡ÙˆØ±","Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­ÙˆØ§Ø¬Ø²","ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙ†ÙÙ‘Ø³ ØµØ§Ù…Øª","ØªÙˆØ§Ø²Ù†"],
                "mode":"Solo",
                "variant_vr":"ØªØ³Ù„Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ø¹ Ù…Ø¤Ø´Ù‘Ø± Ø§Ù†ÙƒØ´Ø§Ù Ø¨ØµØ±ÙŠ.",
                "variant_no_vr":"Ø¹ÙˆØ§Ø¦Ù‚ Ø®ÙÙŠÙØ© ÙˆØ£Ø´Ø±Ø·Ø© Ø¸Ù„.",
                "difficulty":2
            },
            {
                "sport_label":"Mind-Trap Puzzles in Motion",
                "what_it_looks_like":"Ø£Ù„ØºØ§Ø² Ù‚Ø±Ø§Ø± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©: ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±ØŒ Ø®Ø¯Ø¹Ø© Ø¨ØµØ±ÙŠØ©ØŒ Ø­Ø±ÙƒØ© Ù…Ø¶Ø§Ø¯Ø© Ù„Ø­Ø±ÙƒØ© 'Ø®ØµÙ…' Ø§ÙØªØ±Ø§Ø¶ÙŠ.",
                "inner_sensation":"ÙØ¶ÙˆÙ„ Ø°Ù‡Ù†ÙŠ Ù…Ø¹ Ù„Ø°Ù‘Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù.",
                "why_you":"ØªØ­Ø¨ Ø§Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆÙ…Ø¨Ø§Ø±Ø²Ø© Ø§Ù„Ù‡ÙˆÙŠØ© Ø°Ù‡Ù†ÙŠÙ‹Ø§ Ù‚Ø¨Ù„ Ø¬Ø³Ø¯ÙŠÙ‹Ø§.",
                "first_week":"Ø­Ù„ Ù„ØºØ² Ø­Ø±ÙƒÙŠ Ø¨Ø³ÙŠØ· Ù…Ø¹ ØªØªØ¨Ù‘Ø¹ Ø§Ù„Ù†ÙØ³ØŒ Ø«Ù… Ø£Ø¶Ù Ø®Ø¯Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©.",
                "progress_markers":"ÙˆØ¶ÙˆØ­ ØªØ±ÙƒÙŠØ²ØŒ Ø«Ù‚Ø© Ù‚Ø±Ø§Ø±ØŒ ØªÙ†Ø§ØºÙ… Ø­Ø±ÙƒØ©/ÙÙƒØ±.",
                "win_condition":"Ø­Ù„ Ø§Ù„Ù„ØºØ² Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØªØ§Ù„ÙŠØ©.",
                "core_skills":["Ø®Ø¯Ø§Ø¹ Ø¨ØµØ±ÙŠ","ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø±","ØªØ«Ø¨ÙŠØª Ù†Ø¸Ø±Ø©","Ù‚Ø±Ø§Ø± Ø¨Ø¯ÙŠÙ‡ÙŠ","Ù‡Ø¯ÙˆØ¡ ØªØ­Øª Ø¶ØºØ·"],
                "mode":"Solo",
                "variant_vr":"Ø£ÙØ®Ø§Ø® Ø¨ØµØ±ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©.",
                "variant_no_vr":"Ù…Ø³Ø§Ø±Ø§Øª Ø£Ø±Ø¶ÙŠØ© Ø°Ø§Øª Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø®ÙÙŠØ©.",
                "difficulty":2
            },
            {
                "sport_label":"Range Precision Circuit",
                "what_it_looks_like":"Ø¯Ù‚Ø© ØªØµÙˆÙŠØ¨ Ù‡Ø§Ø¯Ø¦Ø© Ù…Ø¹ Ø²ÙˆØ§ÙŠØ§ Ø«Ø§Ø¨ØªØ© ÙˆØ§Ù†ØªÙ‚Ø§Ù„ Ù…Ù†Ø¸Ù‘Ù… Ø¨ÙŠÙ† Ø£Ù‡Ø¯Ø§Ù.",
                "inner_sensation":"Ù‡Ø¯ÙˆØ¡ Ù…ØªÙ…Ø±ÙƒØ² ÙˆÙ†Ø¨Ø¶ Ù…Ø³ØªÙ‚Ø±.",
                "why_you":"ØªÙ…ÙŠÙ„ Ù„ØªÙ‡Ø°ÙŠØ¨ Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø§ØªÙ‚Ø§Ù† Ø§Ù„ØµØ§Ù…Øª.",
                "first_week":"Ø«Ø¨Ù‘Øª Ø§Ù„Ù†Ø¸Ø±Ø©ØŒ Ø§Ø¶Ø¨Ø· Ø§Ù„Ù†ÙØ³ØŒ Ø¨Ø¯Ù‘Ù„ Ø²ÙˆØ§ÙŠØ§Ùƒ Ø¨Ø³Ù„Ø§Ø³Ø©.",
                "progress_markers":"Ø«Ø¨Ø§Øª ÙŠØ¯ØŒ Ù‚Ø±Ø§Ø± Ø£ÙˆØ¶Ø­ØŒ ØªÙˆØªØ± Ø£Ù‚Ù„.",
                "win_condition":"ØªØ­Ù‚ÙŠÙ‚ Ø¯Ù‚Ø© Ø«Ø§Ø¨ØªØ© Ø¹Ø¨Ø± Ø³Ù„Ø³Ù„Ø© Ø£Ù‡Ø¯Ø§Ù Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØªØ§Ù„ÙŠØ©.",
                "core_skills":["ØªØ«Ø¨ÙŠØª Ù†Ø¸Ø±Ø©","Ø¶Ø¨Ø· Ù†ÙØ³","Ø§Ù†ØªÙ‚Ø§Ù„ Ø²ÙˆØ§ÙŠØ§","ØªØ­ÙƒÙ‘Ù… Ø¯Ù‚ÙŠÙ‚"],
                "mode":"Solo",
                "variant_vr":"ØªØµÙˆÙŠØ¨ Ø§ÙØªØ±Ø§Ø¶ÙŠ ØªÙØ§Ø¹Ù„ÙŠ.",
                "variant_no_vr":"Ù„ÙˆØ­Ø§Øª Ø£Ù‡Ø¯Ø§Ù Ø¥Ø³ÙÙ†Ø¬ÙŠØ© Ø¢Ù…Ù†Ø©.",
                "difficulty":2
            },
            {
                "sport_label":"Grip & Balance Ascent",
                "what_it_looks_like":"Ù…Ø³Ø§Ø± Ù‚Ø¨Ø¶Ø§Øª ÙˆØªÙˆØ§Ø²Ù† ØªØ¯Ø±ÙŠØ¬ÙŠØŒ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³ÙƒØŒ ØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù† Ù‡Ø§Ø¯Ø¦.",
                "inner_sensation":"ØªÙ…Ø§Ø³Ùƒ Ø¯Ø§Ø®Ù„ÙŠ ÙˆØ«Ù‚Ø© Ø­Ø±ÙƒØ©.",
                "why_you":"ØªØ­Ø¨ ØªØ­Ø¯Ù‘ÙŠ ØªØ­ÙƒÙ‘Ù… Ø§Ù„Ø¬Ø³Ø¯ Ø¨Ø¯ÙˆÙ† Ø¶Ø¬ÙŠØ¬.",
                "first_week":"Ø§Ù‚Ø±Ø£ Ù…ÙˆØ¶Ø¹ Ø§Ù„Ù‚Ø¨Ø¶Ø©ØŒ ÙˆØ²Ù‘Ù† Ø§Ù„Ø­Ù…Ù„ØŒ ØªØ­Ø±Ù‘Ùƒ Ø¨Ø¨Ø·Ø¡ ØµØ§Ø¹Ø¯.",
                "progress_markers":"ØªØ¹Ø¨ Ø£Ù‚Ù„ ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø¯ØŒ Ø§ØªØ²Ø§Ù† Ø£ÙˆØ¶Ø­.",
                "win_condition":"Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© Ø¯ÙˆÙ† Ø¥ÙÙ„Ø§Øª.",
                "core_skills":["Ù‚Ø¨Ø¶Ø©","ØªØ­ÙˆÙŠÙ„ ÙˆØ²Ù†","ØªÙˆØ§Ø²Ù†","Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³Ø§Ø±"],
                "mode":"Solo",
                "variant_vr":"Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø¨Ø¶Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.",
                "variant_no_vØ±":"Ø¹Ù†Ø§ØµØ± Ù‚Ø¨Ø¶Ø© Ø¢Ù…Ù†Ø© Ø®ÙÙŠÙØ©.",
                "difficulty":2
            }
        ]
    else:
        presets = [
            {
                "sport_label":"Tactical Immersive Combat",
                "what_it_looks_like":"Arena/VR with tracking, ambush, snap decisions, calculated approach and safe exit.",
                "inner_sensation":"Locked-in focus with calm confidence.",
                "why_you":"You dislike repetition and enjoy tactical mind-body duels.",
                "first_week":"Feel the rhythm, practice approach/retreat, anchor breath before decisions.",
                "progress_markers":"Faster decisions, calmer under pressure, stronger control.",
                "win_condition":"Reach objective unseen or neutralize threat via snap decision.",
                "core_skills":["angle tracking","tempo shifts","fast decision","balance","quiet breath"],
                "mode":"Solo/Team",
                "variant_vr":"Tactical VR duels with FOV tracking.",
                "variant_no_vr":"Foam obstacles with shadow lanes.",
                "difficulty":3
            },
            {
                "sport_label":"Stealth-Flow Missions",
                "what_it_looks_like":"Silent path: brief hide, measured reveal, tag and vanish.",
                "inner_sensation":"Deep focus with smooth breathing.",
                "why_you":"You want tangible progress without noise and love quiet mastery.",
                "first_week":"Practice smooth tempo shifts and safe angles.",
                "progress_markers":"Lower tension, smoother movement, clearer decisions.",
                "win_condition":"Complete the mission without detection.",
                "core_skills":["timed reveal","reading cover","tempo control","silent breath","balance"],
                "mode":"Solo",
                "variant_vr":"Stealth VR with exposure indicator.",
                "variant_no_vr":"Light obstacles and shadow tapes.",
                "difficulty":2
            },
            {
                "sport_label":"Mind-Trap Puzzles in Motion",
                "what_it_looks_like":"Decision puzzles in motion: route switch, visual feint, counter-move.",
                "inner_sensation":"Curious mind with discovery joy.",
                "why_you":"You enjoy deep understanding and identity duelsâ€”mind first.",
                "first_week":"Solve a simple motion puzzle with breath tracking; add one feint.",
                "progress_markers":"Sharper focus, steadier decisions, mindâ€“body sync.",
                "win_condition":"Solve without consecutive errors.",
                "core_skills":["visual feint","path switch","gaze hold","intuitive decision","calm under stress"],
                "mode":"Solo",
                "variant_vr":"Interactive visual traps.",
                "variant_no_vr":"Floor cues with hidden hints.",
                "difficulty":2
            }
        ]
    return presets[i % len(presets)]

def _fill_defaults(r: Dict[str, Any], lang: str) -> Dict[str, Any]:
    r = dict(r or {})
    if not r.get("win_condition"):
        r["win_condition"] = ("Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯ÙˆÙ† Ø§Ù†ÙƒØ´Ø§Ù." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                              else "Complete the mission without being detected.")
    if not r.get("core_skills"):
        r["core_skills"] = ["ØªØªØ¨Ù‘Ø¹ Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø±Ø¤ÙŠØ©","ØªØºÙŠÙŠØ± Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹","Ù‚Ø±Ø§Ø± Ø³Ø±ÙŠØ¹"] if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" \
                           else ["angle tracking","tempo shifts","fast decision"]
    if not r.get("mode"):
        r["mode"] = "Solo/Team"
    if not r.get("variant_vr"):
        r["variant_vr"] = ("Ù…Ø¨Ø§Ø±Ø²Ø§Øª ØªÙƒØªÙŠÙƒÙŠØ© ÙÙŠ VR Ù…Ø¹ Ù…Ø¤Ø´Ù‘Ø± Ù…Ø¬Ø§Ù„ Ø±Ø¤ÙŠØ©." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                           else "Tactical VR duels with FOV indicator.")
    if not r.get("variant_no_vr"):
        r["variant_no_vr"] = ("Ø¹Ù‚Ø¨Ø§Øª Ø®ÙÙŠÙØ© Ù…Ø¹ Ù…Ù…Ø±Ø§Øª Ø¸Ù„." if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                              else "Light obstacle arena with shadow lanes.")
    return r

# ======== HARD DEDUPE (no repeats, no near-duplicates) ========
def _hard_dedupe_and_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    used_labels = set()
    used_sigs: List[set] = []

    def pick_unique_fallback(idx: int) -> Dict[str, Any]:
        for j in range(idx, idx+6):
            fb = _fallback_identity(j, lang)
            lab = _canonical_label(fb.get("sport_label",""))
            sig = _sig_for_rec(fb)
            if lab and (lab not in used_labels) and all(_jaccard(sig, s) <= 0.6 for s in used_sigs):
                return fb
        fb = _fallback_identity(idx, lang)
        fb["sport_label"] = (fb.get("sport_label","") + " â€” Alt")
        return fb

    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        r = _fill_defaults(_sanitize_record(r), lang)

        lab = _canonical_label(r.get("sport_label",""))
        if not lab or _label_is_generic(lab):
            r = pick_unique_fallback(i)
            lab = _canonical_label(r.get("sport_label",""))

        if lab in used_labels:
            r = pick_unique_fallback(i)
            lab = _canonical_label(r.get("sport_label",""))

        sig = _sig_for_rec(r)
        if any(_jaccard(sig, s) > 0.6 for s in used_sigs):
            r = pick_unique_fallback(i)
            lab = _canonical_label(r.get("sport_label",""))
            sig = _sig_for_rec(r)

        out.append(r)
        used_labels.add(lab)
        used_sigs.append(sig)

    return out

# ========= Prompt Builder =========
def _style_seed(user_id: str, profile: Optional[Dict[str, Any]]) -> int:
    base = user_id or "anon"
    axes = profile.get("axes", {}) if isinstance(profile, dict) else {}
    s = f"{base}:{json.dumps(axes, sort_keys=True, ensure_ascii=False)}"
    h = hashlib.sha256(s.encode("utf-8")).hexdigest()
    return int(h[:8], 16)

def _json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                 personality: Any, lang: str, style_seed: int) -> List[Dict[str, str]]:
    bullets = _answers_to_bullets(answers)
    persona = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)
    profile = analysis.get("encoded_profile") or {}
    axes = profile.get("axes", {})
    exp = _axes_expectations(axes, lang)
    exp_lines = []
    if exp:
        title = {"calm_adrenaline":"Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†","solo_group":"ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ","tech_intuition":"ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ"} \
                if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else \
                {"calm_adrenaline":"Calm/Adrenaline","solo_group":"Solo/Group","tech_intuition":"Technical/Intuitive"}
        for k, words in exp.items():
            if words:
                exp_lines.append(f"{title[k]}: {', '.join(words)}")
    axis_hint = ("\n".join(exp_lines)) if exp_lines else ""

    # Ù†ÙˆØ§ÙŠØ§ Z (Intent)
    z_intent = analysis.get("z_intent", [])
    intent_hint = ("ØŒ ".join(z_intent) if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else ", ".join(z_intent)) if z_intent else ""

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        sys = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ SportSync AI Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ù„Ø·ÙŠÙØ© (ØµØ¯ÙŠÙ‚ Ù…Ø­ØªØ±Ù).\n"
            "Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ± (Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±).\n"
            "Ø³ÙÙ…Ù‘Ù 'Ù‡ÙˆÙŠØ©/Ø±ÙŠØ§Ø¶Ø©' ÙˆØ§Ø¶Ø­Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© (Ù…Ø«Ø§Ù„: Tactical Immersive Combat).\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
        usr = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Â«Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ§Ø¶Ø­Ø©Â». "
            "Ø£Ø¹ÙØ¯ JSON Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­: "
            "{\"recommendations\":[{"
            "\"sport_label\":\"...\","
            "\"what_it_looks_like\":\"...\","
            "\"inner_sensation\":\"...\","
            "\"why_you\":\"...\","
            "\"first_week\":\"...\","
            "\"progress_markers\":\"...\","
            "\"win_condition\":\"...\","
            "\"core_skills\":[\"...\",\"...\"],"
            "\"mode\":\"Solo/Team\","
            "\"variant_vr\":\"...\","
            "\"variant_no_vr\":\"...\","
            "\"difficulty\":1-5"
            "}]} "
            "Ù‚ÙˆØ§Ø¹Ø¯ Ø¥Ù„Ø²Ø§Ù…ÙŠØ©: Ø§Ø°ÙƒØ± win_condition Ùˆ 3â€“5 core_skills Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. "
            "Ø­Ø§Ø°Ù Z-axes Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù† Ø£Ù…ÙƒÙ†:\n" + axis_hint +
            ("\n\nâ€” Ù†ÙˆØ§ÙŠØ§ Z Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: " + intent_hint if intent_hint else "") + "\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{persona}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©:\n" + bullets + "\n\n"
            f"â€” style_seed: {style_seed}\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
    else:
        sys = (
            "You are a warm, human SportSync coach. "
            "No time/cost/reps/sets/minutes/place. "
            "Name the sport/identity if clarity needs it. Return JSON only."
        )
        usr = (
            "Create THREE clear sport-like identities with required keys: "
            "{\"recommendations\":[{\"sport_label\":\"...\",\"what_it_looks_like\":\"...\",\"inner_sensation\":\"...\","
            "\"why_you\":\"...\",\"first_week\":\"...\",\"progress_markers\":\"...\",\"win_condition\":\"...\","
            "\"core_skills\":[\"...\"],\"mode\":\"Solo/Team\",\"variant_vr\":\"...\",\"variant_no_vr\":\"...\",\"difficulty\":1-5}]} "
            "Align with Z-axes using words:\n" + axis_hint +
            ( "\n\nâ€” Z intents: " + intent_hint if intent_hint else "" ) + "\n\n"
            f"â€” Coach persona:\n{persona}\nâ€” User analysis:\n" + json.dumps(analysis, ensure_ascii=False) + "\n"
            "â€” Bulleted answers:\n" + bullets + f"\nâ€” style_seed: {style_seed}\nJSON only."
        )
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

def _parse_json(text: str) -> Optional[List[Dict[str, Any]]]:
    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return recs
    except Exception:
        pass
    # Ø¥ØµÙ„Ø§Ø­ Ø±ÙŠØ¬ÙƒØ³: \s ÙˆÙ„ÙŠØ³ "Ø³"
    m = re.search(r"\{[\s\S]*\}", text or "")
    if m:
        try:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return recs
        except Exception:
            pass
    return None

def _to_bullets(text: str, max_items: int = 6) -> List[str]:
    if not text: return []
    raw = re.split(r"[;\n\.ØŒ]+", text)
    items = [i.strip(" -â€¢\t ") for i in raw if i.strip()]
    return items[:max_items]

def _one_liner(*parts: str, max_len: int = 140) -> str:
    s = " â€” ".join([p.strip() for p in parts if p and p.strip()])
    return s[:max_len]

def _format_card(rec: Dict[str, Any], i: int, lang: str) -> str:
    head_ar = ["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 1","ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 2","ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© Ø±Ù‚Ù… 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ğŸŸ¢ Recommendation 1","ğŸŒ¿ Recommendation 2","ğŸ”® Recommendation 3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[i]

    label = (rec.get("sport_label") or "").strip()
    scene = (rec.get("what_it_looks_like") or rec.get("scene") or "").strip()
    inner = (rec.get("inner_sensation") or "").strip()
    why   = (rec.get("why_you") or "").strip()
    week  = _to_bullets(rec.get("first_week") or "")
    prog  = _to_bullets(rec.get("progress_markers") or "", max_items=4)
    win   = (rec.get("win_condition") or "").strip()
    skills= rec.get("core_skills") or []
    diff  = rec.get("difficulty", 3)
    mode  = (rec.get("mode") or "Solo").strip()
    vr    = (rec.get("variant_vr") or rec.get("vr_idea") or "").strip()
    novr  = (rec.get("variant_no_vr") or "").strip()

    intro = _one_liner(scene, inner)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ùƒ: {label}")
        if intro: out += ["\nğŸ’¡ Ù…Ø§ Ù‡ÙŠØŸ", f"- {intro}"]
        if why:
            out += ["\nğŸ® Ù„ÙŠÙ‡ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ"]
            for b in _to_bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Ù…Ù‡Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©:"]
            for s in skills[:5]: out.append(f"- {s}")
        if win: out += ["\nğŸ ÙƒÙŠÙ ØªÙÙˆØ²ØŸ", f"- {win}"]
        if week:
            out += ["\nğŸš€ Ø£ÙˆÙ„ Ø£Ø³Ø¨ÙˆØ¹ (Ù†ÙˆØ¹ÙŠ):"]
            for b in week: out.append(f"- {b}")
        if prog:
            out += ["\nâœ… Ø¹Ù„Ø§Ù…Ø§Øª ØªÙ‚Ø¯Ù… Ù…Ø­Ø³ÙˆØ³Ø©:"]
            for b in prog: out.append(f"- {b}")
        notes = []
        if mode: notes.append(("ÙˆØ¶Ø¹ Ø§Ù„Ù„Ø¹Ø¨: " + mode))
        if novr: notes.append("Ø¨Ø¯ÙˆÙ† VR: " + novr)
        if vr: notes.append("VR (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): " + vr)
        if notes:
            out += ["\nğŸ‘â€ğŸ—¨ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:", f"- " + "\n- ".join(notes)]
        out.append(f"\nØ§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: {diff}/5")
        return "\n".join(out)
    else:
        out = [head, ""]
        if label: out.append(f"ğŸ¯ Ideal identity: {label}")
        if intro: out += ["\nğŸ’¡ What is it?", f"- {intro}"]
        if why:
            out += ["\nğŸ® Why you"]
            for b in _to_bullets(why, 4) or [why]: out.append(f"- {b}")
        if skills:
            out += ["\nğŸ§© Core skills:"]
            for s in skills[:5]: out.append(f"- {s}")
        if win: out += ["\nğŸ Win condition", f"- {win}"]
        if week:
            out += ["\nğŸš€ First week (qualitative)"]
            for b in week: out.append(f"- {b}")
        if prog:
            out += ["\nâœ… Progress cues"]
            for b in prog: out.append(f"- {b}")
        notes = []
        if mode: notes.append(("Mode: " + mode))
        if novr: notes.append("No-VR: " + novr)
        if vr: notes.append("VR (optional): " + vr)
        if notes:
            out += ["\nğŸ‘â€ğŸ—¨ Notes:", f"- " + "\n- ".join(notes)]
        out.append(f"\nApprox level: {diff}/5")
        return "\n".join(out)

def _sanitize_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    temp: List[Dict[str, Any]] = []
    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        r = _fill_defaults(_sanitize_record(r), lang)
        blob = " ".join([
            r.get("sport_label",""), r.get("what_it_looks_like",""),
            r.get("why_you",""), r.get("first_week",""),
            r.get("progress_markers",""), r.get("win_condition","")
        ])
        if _too_generic(blob, _MIN_CHARS) or not _has_sensory(blob) or not _is_meaningful(r) \
           or (_REQUIRE_WIN and not r.get("win_condition")) \
           or len(r.get("core_skills") or []) < _MIN_CORE_SKILLS \
           or _label_is_generic(r.get("sport_label","")):
            r = _fallback_identity(i, lang)
        temp.append(r)
    return _hard_dedupe_and_fill(temp, lang)

# ====== Blacklist (persistent, JSON) =========================================
def _load_blacklist() -> dict:
    bl = _load_json_safe(BL_PATH)
    if not isinstance(bl.get("labels"), dict):
        bl["labels"] = {}
    bl.setdefault("version", "1.0")
    return bl

# â€” aliases/canonicalization helpers
KB = _load_json_safe(KB_PATH)
_ALIAS_MAP = {}
if isinstance(KB.get("label_aliases"), dict):
    for canon, alist in KB["label_aliases"].items():
        for a in alist:
            _ALIAS_MAP[_normalize_ar(a).lower()] = canon
AL2 = _load_json_safe(AL_PATH)
if isinstance(AL2.get("canonical"), dict):
    for a, canon in AL2["canonical"].items():
        _ALIAS_MAP[_normalize_ar(a).lower()] = canon

_FORBIDDEN_GENERIC = set(
    KB.get("guards", {}).get("forbidden_generic_labels", [])
) | set(AL2.get("forbidden_generic", []) or [])

def _canon_label(label: str) -> str:
    lab = _normalize_ar(label or "").lower().strip(" -â€”:ØŒ")
    if not lab:
        return ""
    if lab in _ALIAS_MAP:
        return _ALIAS_MAP[lab]
    lab = re.sub(r"[^a-z0-9\u0600-\u06FF]+", " ", lab)
    lab = re.sub(r"\s+", " ", lab).strip()
    return lab

def _is_forbidden_generic(label: str) -> bool:
    base = _normalize_ar((label or "")).lower()
    return any(g in base for g in _FORBIDDEN_GENERIC)

def _bl_has(bl: dict, label: str) -> bool:
    c = _canon_label(label)
    return bool(c and c in bl["labels"])

def _bl_add(bl: dict, label: str, alias: str = "") -> None:
    c = _canon_label(label)
    if not c:
        return
    rec = bl["labels"].get(c, {"aliases": [], "count": 0, "first_seen": None})
    if alias and alias not in rec["aliases"]:
        rec["aliases"].append(alias)
    rec["count"] = int(rec.get("count", 0)) + 1
    if not rec.get("first_seen"):
        rec["first_seen"] = datetime.utcnow().isoformat() + "Z"
    rec["last_used"] = datetime.utcnow().isoformat() + "Z"
    bl["labels"][c] = rec

_AR_VARIANTS = [
    "Ù†Ø³Ø®Ø© Ø¸Ù„Ù‘ÙŠØ©", "Ù†Ù…Ø· Ù…Ø±Ø§ÙˆØºØ©", "Ø®Ø· ØªØ­ÙƒÙ‘Ù… Ù‡Ø§Ø¯Ø¦", "Ù†Ø³Ø®Ø© ØªÙÙƒÙŠÙƒ ØªÙƒØªÙŠÙƒÙŠ",
    "Ù…Ù†Ø§ÙˆØ±Ø© Ø¹ÙƒØ³ÙŠØ©", "Ø²Ø§ÙˆÙŠØ© ØµØ§Ù…ØªØ©", "Ø·ÙŠÙ Ø§Ù„ØªØªØ¨Ø¹", "ØªØ¯ÙÙ‚ Ø®ÙÙŠ"
]
_EN_VARIANTS = [
    "Shadow Variant", "Evasive Pattern", "Calm-Control Line", "Tactical Deconstruction",
    "Counter-Maneuver", "Silent Angle", "Tracking Flux", "Stealth Flow"
]

def _generate_variant_label(base: str, lang: str, salt: int = 0) -> str:
    base = (base or "").strip(" -â€”:ØŒ")
    pool = _AR_VARIANTS if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else _EN_VARIANTS
    joiner = " â€” "
    idx = abs(hash(_normalize_ar(base) + str(salt))) % len(pool)
    return f"{base}{joiner}{pool[idx]}"

def _perturb_phrasing(rec: Dict[str, Any], lang: str) -> Dict[str, Any]:
    r = dict(rec)
    tacky_add_ar = " Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø²ÙˆØ§ÙŠØ§ Ø¨Ø¯Ù„ Ù…Ø·Ø§Ø±Ø¯Ø© Ø§Ù„Ø­Ø±ÙƒØ©. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù‚Ø±Ø§Ø± ÙŠØ¸Ù‡Ø± ÙØ¬Ø£Ø© Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙ‡Ø¯Ø£ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹."
    tacky_add_en = " Emphasize reading angles over chasing motion; let decisions snap when the rhythm calms."
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        r["what_it_looks_like"] = (r.get("what_it_looks_like","") + tacky_add_ar).strip()
        r["why_you"] = (r.get("why_you","") + " ØªØ­Ø¨ Ø§Ù„Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ø°ÙƒÙŠ ÙˆØ¥Ø®ÙØ§Ø¡ Ù†ÙˆØ§ÙŠØ§Ùƒ Ø­ØªÙ‰ Ø§Ù„Ù„Ø­Ø¸Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.").strip()
    else:
        r["what_it_looks_like"] = (r.get("what_it_looks_like","") + tacky_add_en).strip()
        r["why_you"] = (r.get("why_you","") + " You like smart brevity and hiding intent until the decisive beat.").strip()
    return r

def _ensure_unique_labels_v_global(recs: List[Dict[str, Any]], lang: str, bl: dict) -> List[Dict[str, Any]]:
    used_now = set()
    out = []
    for i, r in enumerate(recs):
        r = dict(r or {})
        label = r.get("sport_label") or ""
        if _is_forbidden_generic(label) or not label.strip():
            hint = "ØªÙƒØªÙŠÙƒÙŠ ØªØ®ÙÙ‘ÙŠ" if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Tactical Stealth"
            label = hint
            r["sport_label"] = label

        salt = 0
        while _bl_has(bl, label) or _canon_label(label) in used_now:
            label = _generate_variant_label(label, lang, salt=salt)
            r = _perturb_phrasing(r, lang)
            salt += 1
        used_now.add(_canon_label(label))
        r["sport_label"] = label
        out.append(r)
    return out

def _persist_blacklist(recs: List[Dict[str, Any]], bl: dict) -> None:
    for r in recs:
        lab = r.get("sport_label") or ""
        if lab.strip():
            _bl_add(bl, lab, alias=lab)
    _save_json_atomic(BL_PATH, bl)

# ========= PUBLIC API =========
def generate_sport_recommendation(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", user_id: str = "N/A") -> List[str]:
    # Evidence Gate Ø£ÙˆÙ„Ù‹Ø§ â€” Ù„Ø§ ØªÙˆØµÙŠØ§Øª Ø¨Ø¯ÙˆÙ† Ø£Ø¯Ù„Ø© ÙƒØ§ÙÙŠØ©
    eg = _run_egate(answers or {}, lang=lang)
    if _PIPE:
        try:
            _PIPE.send(
                event_type="egate_decision",
                payload={"status": eg.get("status"), "answered": eg.get("answered"), "total_chars": eg.get("total_chars"),
                         "required_missing": eg.get("required_missing", [])},
                user_id=user_id, lang=("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "English"),
                model=CHAT_MODEL
            )
        except Exception:
            pass

    if eg.get("status") != "pass":
        # Ù†Ø±Ø¬Ø¹ Ø¨Ø·Ø§Ù‚Ø© Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØªÙˆØµÙŠØ§Øª)
        card = _format_followup_card(eg.get("followup_questions", []), lang=lang)
        # ÙÙ„ØªØ±Ø© Ø±ÙˆØ§Ø¨Ø· (Ù„Ùˆ Ø£ÙŠ Ù†Øµ ÙÙŠÙ‡ Ø±ÙˆØ§Ø¨Ø·)
        card = scrub_unknown_urls(card, CFG)
        return [card, "â€”", "â€”"]

    if OpenAI_CLIENT is None:
        return ["âŒ OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù€ Quiz.", "â€”", "â€”"]

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + Ø·Ø¨Ù‚Ø© Z + Intent
    analysis = _call_analyze_user_from_answers(user_id, answers, lang)

    silent = []
    try:
        silent = analyze_silent_drivers(answers, lang=lang) or []
    except Exception:
        pass
    analysis["silent_drivers"] = silent

    try:
        z_intent = _call_analyze_intent(answers, lang=lang)
    except Exception:
        z_intent = []
    if z_intent:
        analysis["z_intent"] = z_intent

    # Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ù…ÙØ±Ù…Ù‘Ø² (Ø¥Ù† ÙˆÙØ¬Ø¯)
    profile = _extract_profile(answers, lang)
    if profile:
        analysis["encoded_profile"] = profile
        if "axes" in profile: analysis["z_axes"] = profile["axes"]
        if "scores" in profile: analysis["z_scores"] = profile["scores"]

    # Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
    persona = get_cached_personality(analysis, lang=lang)
    if not persona:
        persona = {"name":"SportSync Coach","tone":"Ø­Ø§Ø²Ù…-Ù‡Ø§Ø¯Ø¦","style":"Ø­Ø³Ù‘ÙŠ ÙˆØ§Ù‚Ø¹ÙŠ Ø¥Ù†Ø³Ø§Ù†ÙŠ","philosophy":"Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø¹ ÙˆØ¶ÙˆØ­ Ù‡ÙˆÙŠÙ‘Ø©"}
        try:
            save_cached_personality(analysis, persona, lang=lang)
        except Exception:
            pass

    # === Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    seed = _style_seed(user_id, profile or {})
    msgs = _json_prompt(analysis, answers, persona, lang, seed)
    try:
        resp = OpenAI_CLIENT.chat.completions.create(
            model=CHAT_MODEL,
            messages=msgs,
            temperature=0.5,           # â†“ Ø«Ø¨Ø§Øª Ø£Ø¹Ù„Ù‰
            top_p=0.9,
            presence_penalty=0.15,
            frequency_penalty=0.1,
            max_tokens=1400
        )
        raw1 = (resp.choices[0].message.content or "").strip()
        print(f"[AI] model={CHAT_MODEL} len={len(raw1)} raw[:140]={raw1[:140]!r}")
    except Exception as e:
        err = f"âŒ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}"
        if _PIPE:
            try:
                _PIPE.send("model_error", {"error": str(e)}, user_id=user_id, lang=lang, model=CHAT_MODEL)
            except Exception:
                pass
        return [err, "â€”", "â€”"]

    # Parsing + Sanitize
    if not ALLOW_SPORT_NAMES and _contains_blocked_name(raw1):
        raw1 = _mask_names(raw1)
    parsed = _parse_json(raw1) or []
    cleaned = _sanitize_fill(parsed, lang)

    # ===== Ù…Ø­Ø§Ø°Ø§Ø© Z-axes + Ø¥ØµÙ„Ø§Ø­ Ø«Ø§Ù†Ù Ø¥Ø°Ø§ Ù„Ø²Ù… =====
    axes = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}
    mismatch_axes = any(_mismatch_with_axes(rec, axes, lang) for rec in cleaned)
    need_repair_generic = any(_too_generic(" ".join([c.get("what_it_looks_like",""), c.get("why_you","")]), _MIN_CHARS) for c in cleaned)
    missing_fields = any(((_REQUIRE_WIN and not c.get("win_condition")) or len(c.get("core_skills") or []) < _MIN_CORE_SKILLS) for c in cleaned)
    need_repair = mismatch_axes or need_repair_generic or missing_fields

    if need_repair:
        exp = _axes_expectations(axes or {}, lang)
        align_hint = ""
        if exp:
            if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                align_hint = (
                    "Ø­Ø§Ø°Ù Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù…Ø¹ Ù…Ø­Ø§ÙˆØ± Z:\n"
                    f"- Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ†: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ: {', '.join(exp.get('solo_group', []))}\n"
                    f"- ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ: {', '.join(exp.get('tech_intuition', []))}\n"
                )
            else:
                align_hint = (
                    "Align with Z-axes:\n"
                    f"- Calm/Adrenaline: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- Solo/Group: {', '.join(exp.get('solo_group', []))}\n"
                    f"- Technical/Intuitive: {', '.join(exp.get('tech_intuition', []))}\n"
                )
        repair_prompt = {
            "role":"user",
            "content":(
                ("Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© ÙˆÙˆØ§Ø¶Ø­Ø© (Ø§Ø³Ù… Ø±ÙŠØ§Ø¶Ø© Ù…Ø³Ù…ÙˆØ­). " if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                 else "Rewrite with a warm, human tone (sport names allowed). ") +
                "ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯: sport_label, what_it_looks_like, win_condition, 3â€“5 core_skills, mode, variant_vr, variant_no_vr. "
                "Ù…Ù…Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚Øª/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª/Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚/Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø´Ø±. "
                "Ø­Ø³Ù‘Ù† Ù…Ø­Ø§Ø°Ø§Ø© Z-axes. JSON ÙÙ‚Ø·.\n\n" + align_hint
            )
        }
        try:
            resp2 = OpenAI_CLIENT.chat.completions.create(
                model=CHAT_MODEL,
                messages=msgs + [{"role":"assistant","content":raw1}, repair_prompt],
                temperature=0.55,
                top_p=0.9,
                presence_penalty=0.15,
                frequency_penalty=0.1,
                max_tokens=1400
            )
            raw2 = (resp2.choices[0].message.content or "").strip()
            if not ALLOW_SPORT_NAMES and _contains_blocked_name(raw2):
                raw2 = _mask_names(raw2)
            parsed2 = _parse_json(raw2) or []
            cleaned2 = _sanitize_fill(parsed2, lang)

            def score(r: Dict[str,Any]) -> int:
                txt = " ".join([
                    r.get("sport_label",""), r.get("what_it_looks_like",""),
                    r.get("inner_sensation",""), r.get("why_you",""),
                    r.get("first_week",""), r.get("win_condition","")
                ])
                bonus = 5*len(r.get("core_skills") or [])
                return len(txt) + bonus

            if sum(map(score, cleaned2)) > sum(map(score, cleaned)):
                cleaned = cleaned2
        except Exception:
            pass

    # ===== ØªØ£ÙƒÙŠØ¯ Ø¹Ø¯Ù… Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ + ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ùƒ Ù„ÙŠØ³Øª =====
    bl = _load_blacklist()
    cleaned = _ensure_unique_labels_v_global(cleaned, lang, bl)
    _persist_blacklist(cleaned, bl)

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙƒØ±ÙˆØª
    cards = [_format_card(cleaned[i], i, lang) for i in range(3)]

    # Ø£Ù…Ø§Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø­Ø³Ø¨ CFG.security
    try:
        cards = [scrub_unknown_urls(c, CFG) for c in cards]
    except Exception:
        pass

    # Ù„ÙˆÙ‚ Ù…Ø¹ Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¬ÙˆØ¯Ø© + ØªÙ„ÙŠÙ…ØªØ±ÙŠ
    quality_flags = {
        "generic": any(_too_generic(" ".join([c.get("what_it_looks_like",""), c.get("why_you","")]), _MIN_CHARS) for c in cleaned),
        "low_sensory": any(not _has_sensory(" ".join([c.get("what_it_looks_like",""), c.get("inner_sensation","")])) for c in cleaned),
        "mismatch_axes": any(_mismatch_with_axes(c, axes, lang) for c in cleaned),
        "missing_fields": any(((_REQUIRE_WIN and not c.get("win_condition")) or len(c.get("core_skills") or []) < _MIN_CORE_SKILLS) for c in cleaned)
    }

    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang,
                "answers": {k: v for k, v in (answers or {}).items() if k != "profile"},
                "analysis": analysis,
                "silent_drivers": silent,
                "encoded_profile": profile,
                "recommendations": cleaned,
                "quality_flags": quality_flags,
                "seed": seed
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    if _PIPE:
        try:
            _PIPE.send(
                event_type="recommendation_emitted",
                payload={"quality_flags": quality_flags, "labels": [c.get("sport_label","") for c in cleaned]},
                user_id=user_id, lang=("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "English"),
                model=CHAT_MODEL
            )
        except Exception:
            pass

    return cards
