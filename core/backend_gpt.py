# -- coding: utf-8 --
"""
core/backend_gpt.py
-------------------
ØªÙˆØµÙŠØ§Øª "Ù‡ÙˆÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡" Ø¨Ø«Ù„Ø§Ø« ÙƒØ±ÙˆØª Ø­Ø³Ù‘ÙŠØ© Ù…Ù†Ø¸Ù…Ø© + Ø·Ø¨Ù‚Ø© Z + Ø®Ø·Ø© Ø£Ø³Ø¨ÙˆØ¹ (Ù†ÙˆØ¹ÙŠØ© ÙÙ‚Ø·) + ÙÙƒØ±Ø© VR.
- Ù„Ø§ Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ© ÙˆÙ„Ø§ Ø¹Ø¯Ù‘Ø§Øª/Ø¬ÙˆÙ„Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.
- ÙŠØ­Ø§ÙˆÙ„ Ù…Ø±ØªÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ù€ fallback. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/English.
"""

from _future_ import annotations

import os, json, re
from typing import Any, Dict, List, Optional

# ========= OpenAI =========
try:
    from openai import OpenAI
except Exception as e:
    raise RuntimeError("Ø£Ø¶Ù Ø§Ù„Ø­Ø²Ù…Ø© ÙÙŠ requirements: openai>=1.6.1,<2") from e

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OpenAI_CLIENT = None
else:
    OpenAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o")  # Ø¨Ø¯Ù‘Ù„ Ø¥Ù„Ù‰ gpt-4o-mini Ù„ØªÙƒÙ„ÙØ© Ø£Ù‚Ù„

# ========= Project imports (with safe fallbacks) =========
try:
    from core.user_logger import log_user_insight
except Exception:
    def log_user_insight(user_id: str, content: Dict[str, Any], event_type: str = "event") -> None:
        print(f"[LOG:{event_type}] {user_id}: {list(content.keys())}")

try:
    from core.memory_cache import get_cached_personality, save_cached_personality
except Exception:
    _PERS_CACHE: Dict[str, str] = {}
    def get_cached_personality(analysis: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> Optional[str]:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        return _PERS_CACHE.get(key)
    def save_cached_personality(analysis: Dict[str, Any], personality: str, lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> None:
        key = f"{lang}:{hash(json.dumps(analysis, ensure_ascii=False, sort_keys=True))}"
        _PERS_CACHE[key] = personality

try:
    from core.user_analysis import analyze_user_from_answers
except Exception:
    def analyze_user_from_answers(answers: Dict[str, Any]) -> Dict[str, Any]:
        return {"quick_profile": "fallback", "raw_answers": answers}

# Layer Z Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ ÙÙŠ core Ø£Ùˆ analysis
try:
    from core.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
except Exception:
    try:
        from analysis.layer_z_engine import analyze_silent_drivers_combined as analyze_silent_drivers
    except Exception:
        def analyze_silent_drivers(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©") -> List[str]:
            return ["Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ù‚ØµÙŠØ±Ø©", "Ù†ÙÙˆØ± Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±", "ØªÙØ¶ÙŠÙ„ ØªØ­Ø¯Ù‘ÙŠ Ø°Ù‡Ù†ÙŠ"]

# ========= (Ø¬Ø¯ÙŠØ¯) Ù…ÙØ´ÙÙ‘ÙØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) =========
def _extract_profile(answers: Dict[str, Any], lang: str) -> Optional[Dict[str, Any]]:
    """
    ÙŠØ¹ÙŠØ¯ Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ù…ÙØ´ÙÙ‘ÙØ± Ø¥Ù† ÙˆÙØ¬Ø¯ ÙÙŠ answers ØªØ­Øª Ø§Ù„Ù…ÙØªØ§Ø­ "profile"ØŒ
    Ø£Ùˆ ÙŠØ­Ø§ÙˆÙ„ ØªÙˆÙ„ÙŠØ¯Ù‡ Ø¹Ø¨Ø± core.answers_encoder.encode_answers (Ø¥Ù† ØªÙˆÙÙ‘Ø±).
    ÙŠÙØ±Ø¬ÙØ¹ None Ù„Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­.
    """
    prof = answers.get("profile")
    if isinstance(prof, dict):
        return prof

    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙˆÙ„ÙŠØ¯ Ø³Ø±ÙŠØ¹
    encode_answers = None
    try:
        from core.answers_encoder import encode_answers as _enc
        encode_answers = _enc
    except Exception:
        try:
            from analysis.answers_encoder import encode_answers as _enc
            encode_answers = _enc
        except Exception:
            encode_answers = None

    if encode_answers is None:
        return None

    try:
        enc = encode_answers(answers, lang=lang)
        preferences = enc.get("prefs", enc.get("preferences", {}))
        z_markers = enc.get("z_markers", [])
        signals   = enc.get("signals", [])
        hints = " | ".join([*z_markers, *signals])[:1000]  # Ù†Øµ Ù…ÙˆØ¬Ø² Ù„Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª

        return {
            "scores": enc.get("scores", {}),
            "axes": enc.get("axes", {}),
            "preferences": preferences,
            "hints_for_prompt": hints,
            "vr_inclination": enc.get("vr_inclination", 0),
            "confidence": enc.get("confidence", 0.0),
        }
    except Exception:
        return None

# ========= Rules & helpers =========
_BLOCKLIST = r"(Ø¬Ø±ÙŠ|Ø±ÙƒØ¶|Ø³Ø¨Ø§Ø­Ø©|ÙƒØ±Ø©|Ù‚Ø¯Ù…|Ø³Ù„Ø©|Ø·Ø§Ø¦Ø±Ø©|ØªÙ†Ø³|Ù…Ù„Ø§ÙƒÙ…Ø©|ÙƒØ§Ø±Ø§ØªÙŠÙ‡|ÙƒÙˆÙ†Øº ÙÙˆ|ÙŠÙˆØ¬Ø§|ÙŠÙˆØºØ§|Ø¨ÙŠÙ„Ø§ØªØ³|Ø±ÙØ¹|Ø£Ø«Ù‚Ø§Ù„|ØªØ²Ù„Ø¬|Ø¯Ø±Ø§Ø¬|Ø¯Ø±Ø§Ø¬Ø©|Ø±ÙƒÙˆØ¨|Ø®ÙŠÙˆÙ„|Ø¨Ø§Ø±ÙƒÙˆØ±|Ø¬ÙˆØ¯Ùˆ|Ø³ÙƒÙˆØ§Ø´|Ø¨Ù„ÙŠØ§Ø±Ø¯Ùˆ|Ø¬ÙˆÙ„Ù|ÙƒØ±Ø© Ø·Ø§Ø¦Ø±Ø©|ÙƒØ±Ø© Ø§Ù„ÙŠØ¯|Ù‡ÙˆÙƒÙŠ|Ø³Ø¨Ø§Ù‚|Ù…Ø§Ø±Ø§Ø«ÙˆÙ†|Ù…ØµØ§Ø±Ø¹Ø©|MMA|Boxing|Karate|Judo|Taekwondo|Soccer|Football|Basketball|Tennis|Swim|Swimming|Running|Run|Cycle|Cycling|Bike|Biking|Yoga|Pilates|Rowing|Row|Skate|Skating|Ski|Skiing|Climb|Climbing|Surf|Surfing|Golf|Volleyball|Handball|Hockey|Parkour|Wrestling)"
_name_re = re.compile(_BLOCKLIST, re.IGNORECASE)

_AVOID_GENERIC = [
    "Ø£ÙŠ Ù†Ø´Ø§Ø· Ø¨Ø¯Ù†ÙŠ Ù…ÙÙŠØ¯","Ø§Ø®ØªØ± Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ","Ø§Ø¨Ø¯Ø£ Ø¨Ø£ÙŠ Ø´ÙŠØ¡","Ø¬Ø±Ù‘Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø®ÙŠØ§Ø±",
    "Ù„Ø§ ÙŠÙ‡Ù… Ø§Ù„Ù†ÙˆØ¹","ØªØ­Ø±Ùƒ ÙÙ‚Ø·","Ù†Ø´Ø§Ø· Ø¹Ø§Ù…","Ø±ÙŠØ§Ø¶Ø© Ø¹Ø§Ù…Ø©","Ø£Ù†Øª ØªØ¹Ø±Ù Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨Ùƒ"
]
_SENSORY = [
    "ØªÙ†ÙÙ‘Ø³","Ø¥ÙŠÙ‚Ø§Ø¹","ØªÙˆØªØ±","Ø§Ø³ØªØ±Ø®Ø§Ø¡","Ø¯ÙØ¡","Ø¨Ø±ÙˆØ¯Ø©","ØªÙˆØ§Ø²Ù†","Ù†Ø¨Ø¶",
    "ØªØ¹Ø±Ù‘Ù‚","Ø´Ø¯Ù‘","Ù…Ø±ÙˆÙ†Ø©","Ù‡Ø¯ÙˆØ¡","ØªØ±ÙƒÙŠØ²","ØªØ¯ÙÙ‘Ù‚","Ø§Ù†Ø³Ø¬Ø§Ù…","Ø«ÙÙ‚Ù„","Ø®ÙÙÙ‘Ø©",
    "Ø¥Ø­Ø³Ø§Ø³","Ø§Ù…ØªØ¯Ø§Ø¯","Ø­Ø±Ù‚ Ù„Ø·ÙŠÙ","ØµÙØ§Ø¡","ØªÙ…Ø§Ø³Ùƒ"
]

# ÙƒÙ„Ù…Ø§Øª/Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¸ÙˆØ±Ø© (Ø£Ø±Ù‚Ø§Ù… Ø²Ù…Ù†/Ø¹Ø¯Ù‘Ø§Øª/ØªÙƒÙ„ÙØ©/Ù…ÙƒØ§Ù† Ù…Ø¨Ø§Ø´Ø±) â€“ Ø´Ù…Ù„Øª ØµÙŠØº Â«Ø¯Ø§Ø®Ù„ÙŠØ©/Ø®Ø§Ø±Ø¬ÙŠØ©Â»
_FORBIDDEN_SENT = re.compile(
    r"(\b\d+(\.\d+)?\s*(?:min|mins|minute|minutes|second|seconds|hour|hours|Ø¯Ù‚ÙŠÙ‚Ø©|Ø¯Ù‚Ø§Ø¦Ù‚|Ø«Ø§Ù†ÙŠØ©|Ø«ÙˆØ§Ù†ÙŠ|Ø³Ø§Ø¹Ø©|Ø³Ø§Ø¹Ø§Øª)\b|"
    r"(?:rep|reps|set|sets|ØªÙƒØ±Ø§Ø±|Ø¹Ø¯Ø©|Ø¹Ø¯Ø§Øª|Ø¬ÙˆÙ„Ø©|Ø¬ÙˆÙ„Ø§Øª|Ã—)|"
    r"(?:ØªÙƒÙ„ÙØ©|Ù…ÙŠØ²Ø§Ù†ÙŠØ©|cost|budget|Ø±ÙŠØ§Ù„|Ø¯ÙˆÙ„Ø§Ø±|\$|â‚¬)|"
    r"(?:Ø¨Ø§Ù„Ø¨ÙŠØª|ÙÙŠ\s*Ø§Ù„Ø¨ÙŠØª|Ù‚Ø±Ø¨\s*Ø§Ù„Ù…Ù†Ø²Ù„|Ø¨Ø§Ù„Ù…Ù†Ø²Ù„|ÙÙŠ\s*Ø§Ù„Ù†Ø§Ø¯ÙŠ|ÙÙŠ\s*Ø§Ù„Ø¬ÙŠÙ…|ØµØ§Ù„Ø©|Ù†Ø§Ø¯ÙŠ|Ø¬ÙŠÙ…|ØºØ±ÙØ©|Ø³Ø§Ø­Ø©|Ù…Ù„Ø¹Ø¨|Ø­Ø¯ÙŠÙ‚Ø©|Ø´Ø§Ø·Ø¦|"
    r"Ø·Ø¨ÙŠØ¹Ø©|Ø®Ø§Ø±Ø¬ÙŠ(?:Ø©)?|Ø¯Ø§Ø®Ù„(?:ÙŠ|ÙŠØ©)?|outdoor|indoor|park|beach|gym|studio))",
    re.IGNORECASE
)

def _mask_names(t: str) -> str: return _name_re.sub("â€”", t or "")
def _violates(t: str) -> bool:   return bool(_name_re.search(t or ""))

def _split_sentences(text: str) -> List[str]:
    if not text: return []
    return [s.strip() for s in re.split(r"(?<=[\.\!\?ØŸ])\s+|[\nØŒ]+", text) if s.strip()]

def _scrub_forbidden(text: str) -> str:
    """ÙŠØ­Ø°Ù Ø£ÙŠ Ø¬Ù…Ù„Ø© ØªØªØ¶Ù…Ù† Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ©/Ø¹Ø¯Ù‘Ø§Øª/Ø¬ÙˆÙ„Ø§Øª Ø¨Ø§Ù„ÙƒØ§Ù…Ù„."""
    kept = [s for s in _split_sentences(text) if not _FORBIDDEN_SENT.search(s)]
    return "ØŒ ".join(kept).strip(" .ØŒ")

def _answers_to_bullets(answers: Dict[str, Any]) -> str:
    out = []
    for k, v in (answers or {}).items():
        if k == "profile":
            continue
        if isinstance(v, dict):
            q, a = v.get("question", k), v.get("answer", "")
        else:
            q, a = str(k), v
        if isinstance(a, list): a = ", ".join(map(str, a))
        out.append(f"- {q}: {a}")
    return "\n".join(out)

def _too_generic(text: str, min_chars: int = 280) -> bool:
    t = (text or "").strip()
    return len(t) < min_chars or any(p in t for p in _AVOID_GENERIC)

def _has_sensory(text: str, min_hits: int = 3) -> bool:
    return sum(1 for w in _SENSORY if w in (text or "")) >= min_hits

def _is_meaningful(rec: Dict[str, Any]) -> bool:
    blob = " ".join([
        rec.get("scene",""), rec.get("inner_sensation",""),
        rec.get("why_you",""), rec.get("first_week",""),
        rec.get("progress_markers","")
    ]).strip()
    return len(blob) >= 80

# ========= Alignment with Z-axes (Ù‡Ø§Ù… Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©) =========
_AR_TOK = {
    "calm": ["Ù‡Ø¯ÙˆØ¡","ØªÙ†ÙÙ‘Ø³","Ø¨Ø·ÙŠØ¡","Ø§Ø³ØªØ±Ø®Ø§Ø¡","ØµÙØ§Ø¡","ÙŠØ±ÙƒÙ‘Ø²","Ø³ÙƒÙˆÙ†"],
    "adren": ["Ø§Ù†Ø¯ÙØ§Ø¹","Ø³Ø±ÙŠØ¹","Ø§Ù†ÙØ¬Ø§Ø±","Ø¥Ø«Ø§Ø±Ø©","Ù…Ø¬Ø§Ø²ÙØ©","Ø§Ø´ØªØ¨Ø§Ùƒ","Ù‚ÙˆØ© Ù„Ø­Ø¸ÙŠØ©"],
    "solo": ["Ù„ÙˆØ­Ø¯Ùƒ","ÙØ±Ø¯ÙŠ","Ù…Ø¹ Ù†ÙØ³Ùƒ","Ø°Ø§ØªÙŠØ©"],
    "group": ["Ù…Ø¹ Ù†Ø§Ø³","Ø¬Ù…Ø§Ø¹Ø©","Ø´Ø±ÙŠÙƒ","ÙØ±ÙŠÙ‚","ØªÙØ§Ø¹Ù„"],
    "tech": ["ØªÙØ§ØµÙŠÙ„","Ø¥ØªÙ‚Ø§Ù†","ØªÙ‚Ù†ÙŠØ©","ØµÙ‚Ù„","Ø¶Ø¨Ø·","ØªÙƒØ±Ø§Ø± ÙˆØ§Ø¹Ù"],
    "intu": ["Ø¥Ø­Ø³Ø§Ø³Ùƒ","Ø­Ø¯Ø³","ØªÙ„Ù‚Ø§Ø¦ÙŠ","Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²Ø§Ø¬","Ø¨Ø¯ÙŠÙ‡Ø©"]
}
_EN_TOK = {
    "calm": ["calm","slow","breath","quiet","settle","soft","mindful"],
    "adren": ["fast","burst","risk","edge","explosive","adrenaline"],
    "solo": ["solo","alone","by yourself","individual"],
    "group": ["with people","partner","team","group","social"],
    "tech": ["detail","technique","repeat to perfect","precise","drill"],
    "intu": ["by feel","intuitive","impulsive","flow with it","go with it"]
}

def _axes_expectations(axes: Dict[str, float], lang: str) -> Dict[str, List[str]]:
    tok = _AR_TOK if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else _EN_TOK
    out: Dict[str, List[str]] = {}
    if not isinstance(axes, dict): return out
    # calm_adrenaline âˆˆ [-1..+1]
    ca = axes.get("calm_adrenaline")
    if isinstance(ca, (int, float)):
        out["calm_adrenaline"] = tok["adren"] if ca >= 0.5 else tok["calm"] if ca <= -0.5 else []
    # solo_group
    sg = axes.get("solo_group")
    if isinstance(sg, (int, float)):
        out["solo_group"] = tok["group"] if sg >= 0.5 else tok["solo"] if sg <= -0.5 else []
    # tech_intuition
    ti = axes.get("tech_intuition")
    if isinstance(ti, (int, float)):
        out["tech_intuition"] = tok["intu"] if ti >= 0.5 else tok["tech"] if ti <= -0.5 else []
    return out

def _mismatch_with_axes(rec: Dict[str, Any], axes: Dict[str, float], lang: str) -> bool:
    exp = _axes_expectations(axes or {}, lang)
    if not exp: return False
    blob = " ".join(str(rec.get(k,"")) for k in ("scene","inner_sensation","why_you","first_week"))
    blob_l = blob.lower()
    # Ø¥Ø°Ø§ ÙÙŠ ØªÙˆÙ‚Ø¹ ÙƒÙ„Ù…Ø§Øª ÙˆÙ„Ù… Ù†Ø¬Ø¯ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…Ù‚Ø§Ø¨Ù„Ø© â†’ ØªØ¹Ø§Ø±Ø¶
    for k, words in exp.items():
        if words and not any(w.lower() in blob_l for w in words):
            return True
    return False

def _sanitize_record(r: Dict[str, Any]) -> Dict[str, Any]:
    """ÙŠÙ†Ø¸Ù‘Ù Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªÙˆØµÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø§Øª ÙˆÙŠØ´ÙŠÙ„ practical_fit Ø¥Ù† ÙˆÙØ¬Ø¯."""
    r = dict(r or {})
    r.pop("practical_fit", None)  # Ø­Ø°Ù Ø§Ù„Ø­Ù‚Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
    for k in ("scene","inner_sensation","why_you","first_week","progress_markers","vr_idea"):
        if isinstance(r.get(k), str):
            r[k] = _scrub_forbidden(_mask_names(r[k].strip()))
    try:
        d = int(r.get("difficulty", 3))
        r["difficulty"] = max(1, min(5, d))
    except Exception:
        r["difficulty"] = 3
    return r

def _fallback_identity(i: int, lang: str) -> Dict[str, Any]:
    """ÙÙˆÙ„Ø¨Ø§Ùƒ Ø¨Ù„Ø§ Ø£Ø±Ù‚Ø§Ù… ÙˆÙ„Ø§ Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ© â€” Ø¨ØµÙŠØ§ØºØ© Ø­Ø³Ù‘ÙŠØ© Ø¥Ù†Ø³Ø§Ù†ÙŠØ©."""
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        presets = [
            {
                "scene":"Ø¥Ø­Ø³Ø§Ø³ Ø§Ù†Ø³ÙŠØ§Ø¨ÙŠ Ø¨Ø¥ÙŠÙ‚Ø§Ø¹ Ù„Ø·ÙŠÙ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§.",
                "inner_sensation":"Ø¯ÙØ¡ Ù‡Ø§Ø¯Ø¦ ÙˆÙˆØ¶ÙˆØ­ Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ±.",
                "why_you":"ØªØ­Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù‘Ù… Ø§Ù„Ø³Ù„Ø³ ÙˆØªÙƒØ±Ù‡ Ø§Ù„Ø±ØªØ§Ø¨Ø©. ØªØ¨ØºÙ‰ Ø³ÙŠØ·Ø±Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªØ¹Ù‚ÙŠØ¯.",
                "first_week":"Ø§Ø¨Ø¯Ø£ Ø¨Ø­Ø±ÙƒØ§Øª ØªÙØªØ­ Ø§Ù„Ù†ÙØ³ Ø¨Ù„Ø·ÙØŒ Ø«Ù… ÙˆØ³Ù‘Ø¹ Ø§Ù„Ù…Ø¯Ù‰ Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø­Ø³Ø§Ø³.",
                "progress_markers":"ØªÙ†ÙÙ‘Ø³ Ø£Ù‡Ø¯Ø£ØŒ ØµÙØ§Ø¡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ø±ØºØ¨Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.",
                "difficulty":2,
                "vr_idea":"Ù†Ø³Ø®Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø®ÙÙŠÙØ© ØªÙØ¨Ø±Ø² Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆØ§Ù„ØªØªØ¨Ù‘Ø¹."
            },
            {
                "scene":"Ø­Ø±ÙƒØ© Ù…ØªÙ†Ø§ØºÙ…Ø© ØªÙØ´ØºÙ‘Ù„ Ø§Ù„Ø¬Ø°Ø¹ ÙˆØ§Ù„Ø°Ø±Ø§Ø¹ÙŠÙ† Ø¨Ø¥Ø­Ø³Ø§Ø³ Ø«Ø§Ø¨Øª.",
                "inner_sensation":"Ø­Ø±Ø§Ø±Ø© Ø®ÙÙŠÙØ© Ù…Ø¹ ØªÙ…Ø§Ø³Ùƒ ÙÙŠ Ø§Ù„ÙˆØ³Ø·.",
                "why_you":"ØªØ¨ØºÙ‰ ØªÙ‚Ø¯Ù‘Ù… ÙˆØ§Ø¶Ø­ ÙˆÙ‚Ø§Ø¨Ù„ Ù„Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø¨Ø¯ÙˆÙ† ÙÙ„Ø³ÙØ© Ø²Ø§ÙŠØ¯Ø©.",
                "first_week":"Ø´ØºÙ‘Ù„ Ø§Ù„Ø¬Ø°Ø¹ Ø¨Ø­Ø±ÙƒØ§Øª Ø¨Ø³ÙŠØ·Ø©ØŒ ÙˆØ§Ø®ØªÙ… Ø¨Ù…Ø±ÙˆÙ†Ø© Ù‡Ø§Ø¯Ø¦Ø©.",
                "progress_markers":"Ø«Ø¨Ø§Øª Ø£Ù‚ÙˆÙ‰ØŒ Ù†ÙˆÙ… Ø£Ø¹Ù…Ù‚ØŒ Ø·Ø§Ù‚Ø© Ø£Ù‡Ø¯Ø£ Ø®Ù„Ø§Ù„ Ø§Ù„ÙŠÙˆÙ….",
                "difficulty":3,
                "vr_idea":"Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆØ§Ø²Ù† Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„ØªÙ…Ø±ÙƒØ²."
            },
            {
                "scene":"Ø¥ÙŠÙ‚Ø§Ø¹ Ù‡Ø§Ø¯Ø¦ ÙŠØ³Ù…Ø­ Ù„Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ø¹ØµØ¨ÙŠ ÙŠÙ‡Ø¯Ø£ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§.",
                "inner_sensation":"ØªÙÙƒÙ‘Ùƒ Ù„Ø·ÙŠÙ Ù„Ù„ØªÙˆØªØ± ÙˆØ¥Ø­Ø³Ø§Ø³ Ø±Ø§ÙŠÙ‚.",
                "why_you":"ØªØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· ØªØ±ÙØ¹ ØªÙ‚Ø¨Ù‘Ù„ Ø§Ù„Ø¬Ù‡Ø¯ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©.",
                "first_week":"ØªØ§Ø¨Ø¹ Ø§Ù„Ù†ÙØ³ØŒ ÙˆØ­Ø±Ù‘Ùƒ Ø¨Ø¨Ø·Ø¡ØŒ ÙˆØ£Ø¶Ù ØªÙ…Ø¯ÙŠØ¯Ø§Øª Ù…Ø±Ù†Ø© Ø¹Ù„Ù‰ Ù…Ø²Ø§Ø¬Ùƒ.",
                "progress_markers":"ØªÙˆØªØ± Ø£Ù‚Ù„ØŒ ØªØ±ÙƒÙŠØ² Ø£ÙˆØ¶Ø­ØŒ ØªÙˆØ§Ø²Ù† Ø£ÙØ¶Ù„.",
                "difficulty":1,
                "vr_idea":"Ø·Ø¨ÙŠØ¹Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø§Ø³ØªØ±Ø®Ø§Ø¡ Ø§Ù„Ø°Ù‡Ù†ÙŠ."
            }
        ]
    else:
        presets = [
            {
                "scene":"A smooth, easy rhythm that opens the breath.",
                "inner_sensation":"Warm calm and simple mental clarity.",
                "why_you":"You like steady progress and dislike boredom.",
                "first_week":"Open the breath gently, then widen range by feel.",
                "progress_markers":"Calmer breath, post-session clarity, natural urge to continue.",
                "difficulty":2,
                "vr_idea":"Light VR emphasizing rhythm and tracking."
            },
            {
                "scene":"Harmonious flow engaging trunk and arms with steadiness.",
                "inner_sensation":"Gentle heat and centered feel.",
                "why_you":"You want noticeable progress without overthinking.",
                "first_week":"Activate the core with simple moves; close with soft mobility.",
                "progress_markers":"Stronger stability, deeper sleep, steadier energy.",
                "difficulty":3,
                "vr_idea":"Simple balance simulation to reinforce centering."
            },
            {
                "scene":"Quiet tempo that lets the nervous system settle.",
                "inner_sensation":"Tension eases; mind feels clear.",
                "why_you":"You need a gentle reset to raise effort tolerance.",
                "first_week":"Track your breath and move slowly; add elastic stretches by feel.",
                "progress_markers":"Less neck/jaw tension, clearer focus, better balance.",
                "difficulty":1,
                "vr_idea":"Immersive nature-relax VR."
            }
        ]
    return presets[i % 3]

def _json_prompt(analysis: Dict[str, Any], answers: Dict[str, Any],
                 personality: Any, lang: str) -> List[Dict[str, str]]:
    bullets = _answers_to_bullets(answers)
    persona = personality if isinstance(personality, str) else json.dumps(personality, ensure_ascii=False)

    # (Ø¬Ø¯ÙŠØ¯) Ø­ÙˆØ§ÙØ² Ø§Ù„Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ù…ÙØ´ÙÙ‘ÙØ± Ø¥Ù† ÙˆÙØ¬Ø¯
    profile = analysis.get("encoded_profile")
    profile_hints = ""
    if isinstance(profile, dict):
        profile_hints = profile.get("hints_for_prompt", "") or ", ".join(profile.get("preferences", {}).values())

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        sys = (
            "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø¨ SportSync AI Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ù„Ø·ÙŠÙØ© (ØµØ¯ÙŠÙ‚ Ù…Ø­ØªØ±Ù). "
            "Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ù…ÙƒØ§Ù†/Ø§Ù„Ø²Ù…Ù†/Ø§Ù„ØªÙƒÙ„ÙØ©/Ø§Ù„Ø¹Ø¯Ù‘Ø§Øª/Ø§Ù„Ø¬ÙˆÙ„Ø§Øª Ø£Ùˆ Ø£ÙŠ Ø£Ø±Ù‚Ø§Ù… Ø¯Ù‚Ø§Ø¦Ù‚. "
            "Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø­Ø³Ù‘ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù‚ØµÙŠØ±Ø©. Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
        usr = (
            "Ø­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« ØªÙˆØµÙŠØ§Øª Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª.\n"
            "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ù…ÙØ§ØªÙŠØ­:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\","
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:\n"
            "- Ù„Ù‡Ø¬Ø© ØµØ¯ÙŠÙ‚ Ù…Ù‡Ù†ÙŠ ÙˆÙ‚ØµÙŠØ±Ø©.\n"
            "- 'why_you' Ø³Ø¨Ø¨ ÙˆØ§Ø¶Ø­ ÙˆØ¨Ø´Ø±ÙŠ.\n"
            "- 'first_week' Ø®Ø·ÙˆØ§Øª Ù†ÙˆØ¹ÙŠØ© Ø¨Ù„Ø§ Ø£Ø±Ù‚Ø§Ù…/Ø¹Ø¯Ù‘Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚.\n"
            "- 'progress_markers' Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ø­Ø³Ø§Ø³/Ø³Ù„ÙˆÙƒ Ø¯ÙˆÙ† Ø£Ø²Ù…Ù†Ø©.\n\n"
            f"â€” Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨:\n{persona}\n\n"
            "â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©:\n" + bullets + "\n\n"
            + ("â€” Ø¥Ø´Ø§Ø±Ø§Øª Ø¨Ø±ÙˆÙØ§ÙŠÙ„:\n" + profile_hints + "\n\n" if profile_hints else "")
            + "Ø£Ø¹ÙØ¯ JSON ÙÙ‚Ø·."
        )
    else:
        sys = (
            "You are a warm, human SportSync coach. "
            "Do NOT mention location/time/cost/reps/sets or minute counts. "
            "Use sensory, concise bullets. Return JSON only."
        )
        usr = (
            "Create THREE nameless movement-identity suggestions.\n"
            "Return JSON ONLY with:\n"
            "{\"recommendations\":[{\"scene\":\"...\",\"inner_sensation\":\"...\",\"why_you\":\"...\","
            "\"first_week\":\"...\",\"progress_markers\":\"...\",\"difficulty\":1-5,\"vr_idea\":\"...\"}]}\n"
            "Style rules: human tone; 'first_week' qualitative (no numbers); no place/time/cost.\n\n"
            f"â€” Coach persona:\n{persona}\n\n"
            "â€” User analysis:\n" + json.dumps(analysis, ensure_ascii=False) + "\n\n"
            "â€” Bulleted answers:\n" + bullets + "\n\n"
            + ("â€” Profile hints:\n" + profile_hints + "\n\n" if profile_hints else "")
            + "JSON only."
        )
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

def _parse_json(text: str) -> Optional[List[Dict[str, Any]]]:
    try:
        obj = json.loads(text)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list) and recs:
            return recs
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}", text or "")
    if m:
        try:
            obj = json.loads(m.group(0))
            recs = obj.get("recommendations", [])
            if isinstance(recs, list) and recs:
                return recs
        except Exception:
            pass
    return None

def _to_bullets(text: str, max_items: int = 5) -> List[str]:
    if not text: return []
    raw = re.split(r"[;\n\.ØŒ]+", text)
    items = [i.strip(" -â€¢\t ") for i in raw if i.strip()]
    return items[:max_items]

def _one_liner(*parts: str, max_len: int = 120) -> str:
    s = " â€” ".join([p.strip() for p in parts if p and p.strip()])
    return s[:max_len]

# ======== (Ø¬Ø¯ÙŠØ¯) Ø§Ø³Ù… Ø§Ù„Ù‡ÙˆÙŠØ© + Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ù†Ø³Ø§Ù†ÙŠØ© ========

def _concept_label(rec: Dict[str, Any], axes: Dict[str, float], lang: str) -> str:
    """Ø§Ø³Ù… ÙˆØµÙÙŠ Ù‚ØµÙŠØ± Ù„Ù„Ù‡ÙˆÙŠØ© Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù…Ø­Ø§ÙˆØ± Z ÙˆÙˆØ¬ÙˆØ¯ VR (Ø¨Ø¯ÙˆÙ† Ø£Ø³Ù…Ø§Ø¡ Ø±ÙŠØ§Ø¶Ø§Øª)."""
    ad = float((axes or {}).get("calm_adrenaline", 0.0) or 0.0)
    ti = float((axes or {}).get("tech_intuition", 0.0) or 0.0)
    has_vr = bool((rec or {}).get("vr_idea"))

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        base = "ØªÙƒØªÙŠÙƒÙŠ" if ad >= 0.5 else "Ø§Ù†Ø³ÙŠØ§Ø¨ÙŠ" if ad <= -0.5 else "Ù…ØªÙˆØ§Ø²Ù†"
        layer = "Ø­Ø¯Ø³ÙŠ" if ti >= 0.5 else "Ø¯Ù‚ÙŠÙ‚" if ti <= -0.5 else "Ù…Ø±Ù†"
        extra = "ØºØ§Ù…Ø±" if has_vr else "Ù…Ø±ÙƒÙ‘Ø²"
        name = f"{base} {extra}"
        if layer in ("Ø­Ø¯Ø³ÙŠ","Ø¯Ù‚ÙŠÙ‚"):
            name = f"{name} {layer}"
        return name
    else:
        base = "Tactical" if ad >= 0.5 else "Fluid" if ad <= -0.5 else "Balanced"
        layer = "Intuitive" if ti >= 0.5 else "Precise" if ti <= -0.5 else "Adaptive"
        extra = "Immersive" if has_vr else "Focused"
        name = f"{base} {extra}"
        if layer in ("Intuitive","Precise"):
            name = f"{name} {layer}"
        return name

def _notes_block(rec: Dict[str, Any], lang: str) -> List[str]:
    """Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ù‚ØµÙŠØ±Ø© (ØªØ¨Ù‚Ù‰ Ø¹Ø§Ù…Ø©Ø› Ø¨Ø¯ÙˆÙ† Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ©)."""
    notes: List[str] = []
    vr = (rec.get("vr_idea") or "").strip()
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        notes.append("Ù‡Ø°Ù‡ Â«Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ©Â» ÙˆØµÙÙŠØ©ØŒ Ù…Ùˆ Ù„Ø§Ø²Ù… ØªØ³Ù…ÙŠÙ‡Ø§ Ø±ÙŠØ§Ø¶Ø©.")
        if vr: notes.append(vr)
        notes.append("ØªØ¨ØºÙ‰ ØªÙØ§ØµÙŠÙ„ Ø£Ø¯ÙˆØ§Øª/Ø£Ù…Ø§ÙƒÙ†ØŸ Ø§Ø³Ø£Ù„Ù†ÙŠ ÙÙŠ Ø§Ù„Ø´Ø§Øª ÙˆÙ†Ø®ØµØµÙ‡Ø§ Ù„Ùƒ.")
    else:
        notes.append("This is a descriptive movement identity, not a sport label.")
        if vr: notes.append(vr)
        notes.append("Want gear/venue specifics? Ask in chat and weâ€™ll tailor it.")
    return notes[:3]

def _format_card(rec: Dict[str, Any], i: int, lang: str) -> str:
    axes_for_title = rec.get("_axes_for_title") or {}
    concept = _concept_label(rec, axes_for_title, lang)

    # Ø±Ø¤ÙˆØ³
    head_ar = ["ğŸŸ¢ Ø§Ù„ØªÙˆØµÙŠØ© 1","ğŸŒ¿ Ø§Ù„ØªÙˆØµÙŠØ© 2","ğŸ”® Ø§Ù„ØªÙˆØµÙŠØ© 3 (Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©)"]
    head_en = ["ğŸŸ¢ Rec #1","ğŸŒ¿ Rec #2","ğŸ”® Rec #3 (Creative)"]
    head = (head_ar if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else head_en)[i]

    # Ø¹Ù†Ø§ØµØ±
    scene = (rec.get("scene") or "").strip()
    inner = (rec.get("inner_sensation") or "").strip()
    why   = (rec.get("why_you") or "").strip()
    week  = _to_bullets(rec.get("first_week") or "")
    prog  = _to_bullets(rec.get("progress_markers") or "", max_items=4)
    diff  = rec.get("difficulty", 3)

    intro = _one_liner(scene, inner)
    notes = _notes_block(rec, lang)

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        out = [head, "", f"ğŸ¯ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ùƒ: {concept}", ""]
        if intro:
            out += ["ğŸ’¡ Ù…Ø§ Ù‡ÙŠØŸ", f"- {intro}", ""]
        if why:
            out += ["ğŸ® Ù„ÙŠÙ‡ ØªÙ†Ø§Ø³Ø¨ÙƒØŸ"]
            for b in _to_bullets(why, 4) or [why]:
                out.append(f"- {b}")
            out.append("")
        if week:
            out += ["ğŸ” Ø´ÙƒÙ„Ù‡Ø§ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ:"]
            for b in week: out.append(f"- {b}")
            out.append("")
        if prog:
            out += ["ğŸ“ˆ Ø¹Ù„Ø§Ù…Ø§Øª ØªÙ‚Ø¯Ù‘Ù… Ù…Ø­Ø³ÙˆØ³Ø©:"]
            for b in prog: out.append(f"- {b}")
            out.append("")
        out.append(f"Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: {diff}/5")
        if notes:
            out += ["", "ğŸ‘â€ğŸ—¨ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:"]
            for n in notes: out.append(f"- {n}")
        return "\n".join(out)
    else:
        out = [head, "", f"ğŸ¯ Ideal identity: {concept}", ""]
        if intro:
            out += ["ğŸ’¡ What is it?", f"- {intro}", ""]
        if why:
            out += ["ğŸ® Why it suits you"]
            for b in _to_bullets(why, 4) or [why]:
                out.append(f"- {b}")
            out.append("")
        if week:
            out += ["ğŸ” Real-world feel:"]
            for b in week: out.append(f"- {b}")
            out.append("")
        if prog:
            out += ["ğŸ“ˆ Progress cues:"]
            for b in prog: out.append(f"- {b}")
            out.append("")
        out.append(f"Approx level: {diff}/5")
        if notes:
            out += ["", "ğŸ‘â€ğŸ—¨ Notes:"]
            for n in notes: out.append(f"- {n}")
        return "\n".join(out)

def _sanitize_fill(recs: List[Dict[str, Any]], lang: str) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for i in range(3):
        r = recs[i] if i < len(recs) else {}
        # mask + scrub + drop practical_fit
        r = _sanitize_record(r)

        # quality gate
        blob = " ".join([
            r.get("scene",""), r.get("inner_sensation",""),
            r.get("why_you",""), r.get("first_week",""),
            r.get("progress_markers","")
        ])
        if _too_generic(blob) or not _has_sensory(blob) or not _is_meaningful(r):
            r = _fallback_identity(i, lang)
        out.append(r)
    return out

# ========= PUBLIC API =========
def generate_sport_recommendation(answers: Dict[str, Any], lang: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", user_id: str = "N/A") -> List[str]:
    if OpenAI_CLIENT is None:
        return ["âŒ OPENAI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ù€ Quiz.", "â€”", "â€”"]

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… + Ø·Ø¨Ù‚Ø© Z
    analysis = analyze_user_from_answers(answers)
    silent = analyze_silent_drivers(answers, lang=lang) or []
    analysis["silent_drivers"] = silent

    # (Ø¬Ø¯ÙŠØ¯) Ø§Ù„ØªÙ‚Ø§Ø· Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù† ÙˆÙØ¬Ø¯ (Ø£Ùˆ ØªÙˆÙ„ÙŠØ¯Ù‡)
    profile = _extract_profile(answers, lang)
    if profile:
        analysis["encoded_profile"] = profile
        if "axes" in profile:
            analysis["z_axes"] = profile["axes"]
        if "scores" in profile:
            analysis["z_scores"] = profile["scores"]

    # Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
    persona = get_cached_personality(analysis, lang=lang)
    if not persona:
        persona = {"name":"SportSync Coach","tone":"Ø­Ø§Ø²Ù…-Ù‡Ø§Ø¯Ø¦","style":"Ø­Ø³Ù‘ÙŠ ÙˆØ§Ù‚Ø¹ÙŠ Ø¥Ù†Ø³Ø§Ù†ÙŠ","philosophy":"Ù‡ÙˆÙŠØ© Ø­Ø±ÙƒØ© Ø¨Ù„Ø§ Ø£Ø³Ù…Ø§Ø¡"}
        try:
            save_cached_personality(analysis, persona, lang=lang)
        except Exception:
            pass

    # === Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    msgs = _json_prompt(analysis, answers, persona, lang)
    try:
        resp = OpenAI_CLIENT.chat.completions.create(
            model=CHAT_MODEL, messages=msgs, temperature=0.9, max_tokens=1200
        )
        raw1 = (resp.choices[0].message.content or "").strip()
        print(f"[AI] model={CHAT_MODEL} len={len(raw1)} raw[:120]={raw1[:120]!r}")
    except Exception as e:
        return [f"âŒ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}", "â€”", "â€”"]

    # Sanitization pass-1
    if _violates(raw1): raw1 = _mask_names(raw1)
    parsed = _parse_json(raw1) or []
    cleaned = _sanitize_fill(parsed, lang)

    # ===== Ø¨ÙˆØ§Ø¨Ø© Ù…Ø­Ø§Ø°Ø§Ø© Z-axes + Ø¥ØµÙ„Ø§Ø­ Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© =====
    axes = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}
    mismatch_axes = any(_mismatch_with_axes(rec, axes, lang) for rec in cleaned)

    # ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ø«Ø§Ù†ÙŠØ©
    need_repair_generic = any(_too_generic(" ".join([c.get("scene",""), c.get("why_you","")])) for c in cleaned)
    need_repair = need_repair_generic or mismatch_axes

    if need_repair:
        # Ù†Ø¨Ù†ÙŠ ØªÙ„Ù…ÙŠØ­Ø§Øª Ù…Ø­Ø§Ø°Ø§Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        exp = _axes_expectations(axes or {}, lang)
        align_hint = ""
        if exp:
            if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                align_hint = (
                    "Ø­Ø§Ø°Ù Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù…Ø¹ Ù…Ø­Ø§ÙˆØ± Z:\n"
                    f"- Ù‡Ø¯ÙˆØ¡/Ø£Ø¯Ø±ÙŠÙ†Ø§Ù„ÙŠÙ† â†’ Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙØ±Ø¯Ø§Øª: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- ÙØ±Ø¯ÙŠ/Ø¬Ù…Ø§Ø¹ÙŠ â†’ Ù…ÙØ±Ø¯Ø§Øª: {', '.join(exp.get('solo_group', []))}\n"
                    f"- ØªÙ‚Ù†ÙŠ/Ø­Ø¯Ø³ÙŠ â†’ Ù…ÙØ±Ø¯Ø§Øª: {', '.join(exp.get('tech_intuition', []))}\n"
                )
            else:
                align_hint = (
                    "Align with Z-axes:\n"
                    f"- Calm/Adrenaline words: {', '.join(exp.get('calm_adrenaline', []))}\n"
                    f"- Solo/Group words: {', '.join(exp.get('solo_group', []))}\n"
                    f"- Technical/Intuitive words: {', '.join(exp.get('tech_intuition', []))}\n"
                )

        repair_prompt = {
            "role":"user",
            "content":(
                ("Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø¨Ø±Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ø­Ø§Ø±Ø© ÙˆÙˆØ§Ø¶Ø­Ø©. " if lang=="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
                 else "Rewrite with a warm, human tone. ") +
                "ØªØ°ÙƒÙŠØ± ØµØ§Ø±Ù…: Ù„Ø§ Ù…ÙƒØ§Ù†/Ø²Ù…Ù†/ØªÙƒÙ„ÙØ© ÙˆÙ„Ø§ Ø£Ø±Ù‚Ø§Ù…/Ø¹Ø¯Ù‘Ø§Øª/Ø¬ÙˆÙ„Ø§Øª/Ø¯Ù‚Ø§Ø¦Ù‚. "
                "Ø§Ù…Ù„Ø£ why_you Ùˆ first_week Ø¨Ø¹Ù†Ø§ØµØ± Ø­Ø³Ù‘ÙŠØ© Ù†ÙˆØ¹ÙŠØ©. JSON ÙÙ‚Ø·.\n\n" +
                align_hint
            )
        }
        try:
            resp2 = OpenAI_CLIENT.chat.completions.create(
                model=CHAT_MODEL,
                messages=msgs + [{"role":"assistant","content":raw1}, repair_prompt],
                temperature=0.85, max_tokens=1200
            )
            raw2 = (resp2.choices[0].message.content or "").strip()
            if _violates(raw2): raw2 = _mask_names(raw2)
            parsed2 = _parse_json(raw2) or []
            cleaned2 = _sanitize_fill(parsed2, lang)

            # Ø§Ø®ØªØ± Ø§Ù„Ø£ÙØ¶Ù„ Ø¨Ø­ÙØ³Ù‘ÙŠØ© Ø£Ø·ÙˆÙ„
            def score(r: Dict[str,Any]) -> int:
                txt = " ".join([
                    r.get("scene",""),
                    r.get("inner_sensation",""),
                    r.get("why_you",""),
                    r.get("first_week","")
                ])
                return len(txt)

            if sum(map(score, cleaned2)) > sum(map(score, cleaned)):
                cleaned = cleaned2
        except Exception:
            pass

    # Ù…Ø±Ù‘Ø± Ù…Ø­Ø§ÙˆØ± Z Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø«Ù… Ø§Ø­Ø°Ù Ø§Ù„Ù…Ø¤Ù‚Øª
    axes_for_title = (analysis.get("z_axes") or {}) if isinstance(analysis, dict) else {}
    for r in cleaned:
        r["_axes_for_title"] = axes_for_title
    cards = [_format_card(cleaned[i], i, lang) for i in range(3)]
    for r in cleaned:
        r.pop("_axes_for_title", None)

    # Ù„ÙˆÙ‚ Ù…Ø¹ Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¬ÙˆØ¯Ø©
    quality_flags = {
        "generic": any(_too_generic(" ".join([c.get("scene",""), c.get("why_you","")])) for c in cleaned),
        "low_sensory": any(not _has_sensory(" ".join([c.get("scene",""), c.get("inner_sensation","")])) for c in cleaned),
        "mismatch_axes": mismatch_axes
    }

    try:
        log_user_insight(
            user_id=user_id,
            content={
                "language": lang,
                "answers": {k: v for k, v in answers.items() if k != "profile"},
                "analysis": analysis,
                "silent_drivers": silent,
                "encoded_profile": profile,
                "recommendations": cleaned,
                "quality_flags": quality_flags
            },
            event_type="initial_recommendation"
        )
    except Exception:
        pass

    return cards
