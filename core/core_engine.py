# -- coding: utf-8 --
from _future_ import annotations

import logging
from pathlib import Path
from typing import Dict, List, Optional

logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s | %(asctime)s | core_engine | %(message)s"
)

# Ù…Ø³Ø§Ø±Ø§Øª Ù‚ÙŠØ§Ø³ÙŠØ©
IMAGES_DIR = Path("content_studio/ai_images/outputs/")
VOICE_PATH = Path("content_studio/ai_voice/voices/final_voice.mp3")
FINAL_VIDS_DIR = Path("content_studio/ai_video/final_videos/")
for p in (IMAGES_DIR, VOICE_PATH.parent, FINAL_VIDS_DIR):
    p.mkdir(parents=True, exist_ok=True)

# --------- Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø±Ù†Ø© ----------
_generate_script_fn = None
try:
    from content_studio.generate_script.script_generator import generate_script as _generate_script_fn
except Exception:
    pass

_generate_images_fn = None
try:
    from content_studio.ai_images.generate_images import generate_images as _generate_images_fn
except Exception:
    pass

_generate_voice_fn = None
try:
    from content_studio.ai_voice.voice_generator import generate_voice_from_script as _generate_voice_fn
except Exception:
    pass

_compose_video_fn = None
try:
    # Ø¥Ù† ÙƒØ§Ù† Ø¹Ù†Ø¯Ùƒ ÙƒÙˆÙ…Ø¨ÙˆØ²Ø± Ù…Ø®ØµØµ
    from content_studio.ai_video.video_composer import compose_video_from_assets as _compose_video_fn
except Exception:
    pass


def _fallback_compose_video(image_duration: int = 4, fps: int = 30, voice: Optional[str] = None) -> str:
    """ØªØµÙ…ÙŠÙ… ÙÙŠØ¯ÙŠÙˆ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¹Ø¨Ø± MoviePy Ù„Ùˆ Ù…Ø§ ÙˆØ¬Ø¯ ÙƒÙˆÙ…Ø¨ÙˆØ²Ø± Ù…Ø®ØµØµ."""
    from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
    images = sorted(list(IMAGES_DIR.glob(".png")) + list(IMAGES_DIR.glob(".jpg")))
    if not images:
        raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.")
    clips = [ImageClip(str(p)).set_duration(image_duration) for p in images]
    video = concatenate_videoclips(clips, method="compose")
    if voice and Path(voice).exists():
        video = video.set_audio(AudioFileClip(str(voice)))
    out = FINAL_VIDS_DIR / "final_video.mp4"
    video.write_videofile(str(out), fps=fps, codec="libx264", audio_codec="aac")
    return str(out)


def _ensure_tools_available() -> List[str]:
    missing: List[str] = []
    if _generate_images_fn is None:
        missing.append("generate_images")
    # Ø§Ù„Ø³ÙƒØ±Ø¨Øª ÙˆØ§Ù„ØµÙˆØª Ø§Ø®ØªÙŠØ§Ø±ÙŠØ§Ù† (Ù„Ø¯ÙŠÙ†Ø§ Ø¨Ø¯Ø§Ø¦Ù„)ØŒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ø¯ÙŠÙ†Ø§ ÙÙˆÙ„Ø¨Ø§Ùƒ Ù…Ø­Ù„ÙŠ
    return missing


def quick_diagnose() -> Dict:
    return {
        "images_dir_exists": IMAGES_DIR.exists(),
        "images_count": len(list(IMAGES_DIR.glob(".png"))) + len(list(IMAGES_DIR.glob(".jpg"))),
        "voice_exists": VOICE_PATH.exists(),
        "voice_size": VOICE_PATH.stat().st_size if VOICE_PATH.exists() else 0,
        "final_videos_dir_exists": FINAL_VIDS_DIR.exists(),
        "tools_missing": _ensure_tools_available(),
    }


def run_full_generation(
    user_data: Dict,
    lang: str = "ar",
    image_duration: int = 4,
    override_script: Optional[str] = None,
    mute_if_no_voice: bool = True,
    skip_cleanup: bool = True,
) -> Dict:
    """ÙŠØ´ØºÙ‘Ù„ Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬: Ø³ÙƒØ±Ø¨Øª -> ØµÙˆØ± -> (ØµÙˆØª) -> ÙÙŠØ¯ÙŠÙˆ."""
    try:
        # ØªÙ†Ø¸ÙŠÙ ØµÙˆØ± Ù‚Ø¯ÙŠÙ…Ø©
        if not skip_cleanup and IMAGES_DIR.exists():
            for f in IMAGES_DIR.glob("*"):
                try:
                    f.unlink()
                except Exception:
                    pass

        # 1) Ø³ÙƒØ±Ø¨Øª
        if override_script and override_script.strip():
            script = override_script.strip()
            logging.info("ğŸ“ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø³ÙƒØ±Ø¨Øª Ø¬Ø§Ù‡Ø² (override_script).")
        else:
            if _generate_script_fn:
                # Ø¹Ø¯Ù‘Ù„ Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø­Ø³Ø¨ Ø¯Ø§Ù„ØªÙƒ Ù„Ùˆ Ø§Ø®ØªÙ„ÙØª
                script = _generate_script_fn(
                    topic=user_data.get("topic", "sports motivation"),
                    tone=user_data.get("traits", {}).get("tone", "emotional"),
                    lang="arabic" if lang == "ar" else "english",
                )
            else:
                # Ù†Øµ Ø¨Ø³ÙŠØ· Ø§Ø­ØªÙŠØ§Ø·ÙŠ
                script = (
                    "Ù…Ø´Ù‡Ø¯ 1: Ø§Ø¨Ø¯Ø£ Ø¨Ø®Ø·ÙˆØ© ØµØºÙŠØ±Ø©.\n\n"
                    "Ù…Ø´Ù‡Ø¯ 2: Ø§Ø³ØªÙ…Ø± Ø­ØªÙ‰ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ùƒ Ø§Ù„Ø¹ÙŠÙ†.\n\n"
                    "Ù…Ø´Ù‡Ø¯ 3: Ø§Ù„Ù†ØªÙŠØ¬Ø© ØªØ£ØªÙŠ Ù„Ù…Ù† Ù„Ù… ÙŠØªÙˆÙ‚Ù."
                )

        # 2) ØµÙˆØ±
        if _generate_images_fn is None:
            raise RuntimeError("Ø¯Ø§Ù„Ø© generate_images ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©.")
        images = _generate_images_fn(script, lang)
        if not images:
            raise RuntimeError("Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±.")

        # 3) ØµÙˆØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        voice_path = None
        if _generate_voice_fn:
            try:
                voice_path = generate_voice_fn(script, lang) if _generate_voice_fn.code_.co_argcount >= 2 else _generate_voice_fn(script)
            except Exception as e:
                logging.warning(f"ØªØ¹Ø°Ù‘Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
                if not mute_if_no_voice:
                    raise

        # 4) ÙÙŠØ¯ÙŠÙˆ
        if _compose_video_fn:
            try:
                # ÙˆÙ‚Ù‘Ø¹ Ø¯Ø§Ù„ØªÙƒ Ø¥Ù† ÙƒØ§Ù† Ù…Ø®ØªÙ„ÙØ§Ù‹
                video_path = _compose_video_fn(image_duration=image_duration, voice_path=voice_path)
            except TypeError:
                video_path = _compose_video_fn(image_duration=image_duration)
        else:
            video_path = _fallback_compose_video(image_duration=image_duration, voice=voice_path)

        return {
            "script": str(script),
            "images": [str(p) for p in IMAGES_DIR.glob("*")],
            "voice": str(voice_path) if voice_path else None,
            "video": str(video_path),
            "error": None,
        }

    except Exception as e:
        logging.error(f"ğŸ”¥ ÙØ´Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„: {e}")
        return {"script": None, "images": [], "voice": None, "video": None, "error": str(e)}
