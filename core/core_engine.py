# coding: utf-8
import os, logging
from pathlib import Path
from typing import Dict, Optional, List

logging.basicConfig(level=logging.INFO, format="%(levelname)s | %(asctime)s | core_engine | %(message)s")

# Ù…Ø³Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
IMAGES_DIR = Path("content_studio/ai_images/outputs/")
VOICE_PATH = Path("content_studio/ai_voice/voices/final_voice.mp3")
FINAL_VIDS_DIR = Path("content_studio/ai_video/final_videos/")
for p in (IMAGES_DIR, VOICE_PATH.parent, FINAL_VIDS_DIR):
    p.mkdir(parents=True, exist_ok=True)

# Ø¶Ø¨Ø· ffmpeg ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù„Ù€ MoviePy
try:
    import imageio_ffmpeg
    os.environ.setdefault("IMAGEIO_FFMPEG_EXE", imageio_ffmpeg.get_ffmpeg_exe())
except Exception:
    pass

# Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø±Ù†Ø©
try:
    from content_studio.generate_script.script_generator import generate_script as _generate_script_fn
except Exception:
    _generate_script_fn = None

try:
    from content_studio.ai_images.generate_images import generate_images as _generate_images_fn
except Exception:
    _generate_images_fn = None

try:
    from content_studio.ai_voice.voice_generator import generate_voice_from_script as _generate_voice_fn
except Exception:
    _generate_voice_fn = None

try:
    # Ø¥Ù† ÙƒØ§Ù† Ø¹Ù†Ø¯Ùƒ ÙƒÙˆÙ…Ø¨ÙˆØ²Ø± Ù…Ø®ØµØµ
    from content_studio.ai_video.video_composer import compose_video_from_assets as _compose_video_fn
except Exception:
    _compose_video_fn = None


def _fallback_compose_video(image_duration: int = 4, fps: int = 30, voice: Optional[str] = None) -> str:
    """ØªØ±ÙƒÙŠØ¨ ÙÙŠØ¯ÙŠÙˆ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¹Ø¨Ø± MoviePy."""
    from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
    images = sorted(list(IMAGES_DIR.glob(".png")) + list(IMAGES_DIR.glob(".jpg")))
    if not images:
        raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.")
    clips = [ImageClip(str(p)).set_duration(image_duration) for p in images]
    video = concatenate_videoclips(clips, method="compose")
    if voice and Path(voice).exists():
        video = video.set_audio(AudioFileClip(str(voice)))
    FINAL_VIDS_DIR.mkdir(parents=True, exist_ok=True)
    out = FINAL_VIDS_DIR / "final_video.mp4"
    video.write_videofile(str(out), fps=fps, codec="libx264", audio_codec="aac")
    return str(out)


def quick_diagnose() -> Dict:
    return {
        "images_dir_exists": IMAGES_DIR.exists(),
        "images_count": len(list(IMAGES_DIR.glob(".png"))) + len(list(IMAGES_DIR.glob(".jpg"))),
        "voice_exists": VOICE_PATH.exists(),
        "voice_size": VOICE_PATH.stat().st_size if VOICE_PATH.exists() else 0,
        "final_videos_dir_exists": FINAL_VIDS_DIR.exists(),
        "tools_missing": [] if _generate_images_fn else ["generate_images"],
    }


def run_full_generation(
    user_data: Dict,
    lang: str = "ar",
    image_duration: int = 4,
    override_script: Optional[str] = None,
    mute_if_no_voice: bool = True,
    skip_cleanup: bool = True,
) -> Dict:
    """ÙŠØ´ØºÙ‘Ù„ Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬: Ø³ÙƒØ±Ø¨Øª -> ØµÙˆØ± -> (ØµÙˆØª Ø§Ø®ØªÙŠØ§Ø±ÙŠ) -> ÙÙŠØ¯ÙŠÙˆ."""
    try:
        # ØªÙ†Ø¸ÙŠÙ ØµÙˆØ± Ù‚Ø¯ÙŠÙ…Ø©
        if not skip_cleanup and IMAGES_DIR.exists():
            for f in IMAGES_DIR.glob("*"):
                try:
                    f.unlink()
                except Exception:
                    pass

        # 1) Ø³ÙƒØ±Ø¨Øª
        if override_script and override_script.strip():
            script = override_script.strip()
            logging.info("ğŸ“ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø³ÙƒØ±Ø¨Øª Ø¬Ø§Ù‡Ø² (override_script).")
        elif _generate_script_fn:
            script = _generate_script_fn(
                topic=user_data.get("topic", "sports motivation"),
                tone=user_data.get("traits", {}).get("tone", "emotional"),
                lang="arabic" if lang == "ar" else "english",
            )
        else:
            script = (
                "Ù…Ø´Ù‡Ø¯ 1: Ø§Ø¨Ø¯Ø£ Ø¨Ø®Ø·ÙˆØ© ØµØºÙŠØ±Ø©.\n\n"
                "Ù…Ø´Ù‡Ø¯ 2: Ø§Ø³ØªÙ…Ø± Ø­ØªÙ‰ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ùƒ Ø§Ù„Ø¹ÙŠÙ†.\n\n"
                "Ù…Ø´Ù‡Ø¯ 3: Ø§Ù„Ù†ØªÙŠØ¬Ø© ØªØ£ØªÙŠ Ù„Ù…Ù† Ù„Ù… ÙŠØªÙˆÙ‚Ù."
            )

        # 2) ØµÙˆØ±
        if _generate_images_fn is None:
            raise RuntimeError("Ø¯Ø§Ù„Ø© generate_images ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©.")
        image_paths = _generate_images_fn(script, lang)
        if not image_paths or not any(Path(p).exists() for p in image_paths):
            raise RuntimeError("Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±.")

        # 3) ØµÙˆØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        voice_path = None
        if _generate_voice_fn is not None:
            try:
                # âœ… Ø§Ù„ØªØµØ­ÙŠØ­ Ù‡Ù†Ø§
                if generate_voice_fn.code_.co_argcount >= 2:
                    voice_path = _generate_voice_fn(script, lang)
                else:
                    voice_path = _generate_voice_fn(script)
            except Exception as e:
                logging.warning(f"ØªØ¹Ø°Ù‘Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
                if not mute_if_no_voice:
                    raise

        # 4) ÙÙŠØ¯ÙŠÙˆ
        if _compose_video_fn:
            try:
                video_path = _compose_video_fn(image_duration=image_duration, voice_path=voice_path)
            except TypeError:
                video_path = _compose_video_fn(image_duration=image_duration)
        else:
            video_path = _fallback_compose_video(image_duration=image_duration, voice=voice_path)

        return {
            "script": str(script),
            "images": image_paths,
            "voice": voice_path,
            "video": video_path,
            "error": None,
        }

    except Exception as e:
        logging.error(f"ğŸ”¥ ÙØ´Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„: {e}")
        return {"script": None, "images": [], "voice": None, "video": None, "error": str(e)}
