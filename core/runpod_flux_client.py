# -*- coding: utf-8 -*-
"""
core/runpod_flux_client.py
--------------------------
Ø¹Ù…ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù€ RunPod Ù…Ø¹ Flux/ComfyUI

Ø§Ù„Ù…ÙŠØ²Ø§Øª:
- ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ù…Ù† Ù†ØµÙˆØµ (text2img)
- Batch generation
- Error recovery
- Progress tracking
- Workflow builder Ù„Ù€ ComfyUI

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    from core.runpod_flux_client import RunPodFluxClient

    client = RunPodFluxClient()
    result = client.generate_image(
        prompt="A serene morning at a running track, cinematic, 8k",
        width=1024,
        height=1920
    )
"""

import os
import json
import time
import base64
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import requests

class RunPodFluxClient:
    """
    Ø¹Ù…ÙŠÙ„ RunPod Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø¹Ø¨Ø± ComfyUI/Flux
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        endpoint_id: Optional[str] = None,
        timeout: int = 300
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„

        Args:
            api_key: RunPod API key (ÙŠÙ‚Ø±Ø£ Ù…Ù† RUNPOD_API_KEY Ø¥Ù† Ù„Ù… ÙŠÙÙ…Ø±Ø±)
            endpoint_id: ComfyUI endpoint ID (ÙŠÙ‚Ø±Ø£ Ù…Ù† RUNPOD_COMFY_ENDPOINT_ID)
            timeout: Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
        """
        self.api_key = api_key or os.getenv("RUNPOD_API_KEY")
        self.endpoint_id = endpoint_id or os.getenv("RUNPOD_COMFY_ENDPOINT_ID")
        self.timeout = timeout

        if not self.api_key:
            raise RuntimeError(
                "âŒ RUNPOD_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. "
                "Ø§Ø¶Ø¨Ø·Ù‡ ÙÙŠ .env Ø£Ùˆ Ù…Ø±Ø±Ù‡ ÙƒÙ…Ø¹Ø§Ù…Ù„."
            )

        if not self.endpoint_id:
            raise RuntimeError(
                "âŒ RUNPOD_COMFY_ENDPOINT_ID ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. "
                "Ø§Ø¶Ø¨Ø·Ù‡ ÙÙŠ .env Ø£Ùˆ Ù…Ø±Ø±Ù‡ ÙƒÙ…Ø¹Ø§Ù…Ù„."
            )

        self.base_url = f"https://api.runpod.ai/v2/{self.endpoint_id}"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def generate_image(
        self,
        prompt: str,
        negative_prompt: str = "blurry, low quality, watermark, text, signature",
        width: int = 1024,
        height: int = 1024,
        steps: int = 25,
        cfg_scale: float = 7.5,
        seed: Optional[int] = None,
        model: str = "flux_dev.safetensors",
        sampler: str = "euler",
        scheduler: str = "normal"
    ) -> Dict:
        """
        ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©

        Args:
            prompt: Ø§Ù„Ù†Øµ Ø§Ù„ÙˆØµÙÙŠ Ù„Ù„ØµÙˆØ±Ø©
            negative_prompt: Ù…Ø§ ØªØ±ÙŠØ¯ ØªØ¬Ù†Ø¨Ù‡
            width: Ø§Ù„Ø¹Ø±Ø¶ Ø¨Ø§Ù„Ø¨ÙƒØ³Ù„
            height: Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø¨Ø§Ù„Ø¨ÙƒØ³Ù„
            steps: Ø¹Ø¯Ø¯ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (Ø£ÙƒØ«Ø± = Ø£ÙØ¶Ù„ + Ø£Ø¨Ø·Ø£)
            cfg_scale: Ù…Ø¯Ù‰ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù€ prompt (1-20)
            seed: seed Ù„Ù„ØªÙƒØ±Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            model: Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ ComfyUI
            sampler: Ù†ÙˆØ¹ Ø§Ù„Ù€ sampler
            scheduler: Ù†ÙˆØ¹ Ø§Ù„Ù€ scheduler

        Returns:
            {
                "success": True/False,
                "image_b64": "..." (base64 encoded),
                "seed": 12345,
                "error": "..." (ÙÙŠ Ø­Ø§Ù„ Ø§Ù„ÙØ´Ù„)
            }
        """
        try:
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ workflow
            workflow = self._build_flux_workflow(
                prompt=prompt,
                negative_prompt=negative_prompt,
                width=width,
                height=height,
                steps=steps,
                cfg_scale=cfg_scale,
                seed=seed,
                model=model,
                sampler=sampler,
                scheduler=scheduler
            )

            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
            payload = {"input": {"workflow": workflow}}

            print(f"ğŸ“¤ Sending request to RunPod...")
            print(f"   Prompt: {prompt[:60]}...")
            print(f"   Size: {width}x{height}, Steps: {steps}")

            response = requests.post(
                f"{self.base_url}/runsync",
                headers=self.headers,
                json=payload,
                timeout=self.timeout
            )

            response.raise_for_status()
            result = response.json()

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
            if result.get("status") == "COMPLETED":
                output = result.get("output", {})

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© (Ù‚Ø¯ ØªÙƒÙˆÙ† ÙÙŠ Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø®ØªÙ„ÙØ©)
                image_data = None
                if isinstance(output, dict):
                    image_data = output.get("image") or output.get("images", [None])[0]
                elif isinstance(output, list) and len(output) > 0:
                    image_data = output[0]

                if not image_data:
                    return {
                        "success": False,
                        "error": "No image data in response"
                    }

                return {
                    "success": True,
                    "image_b64": image_data,
                    "seed": output.get("seed", seed or 0),
                    "prompt": prompt
                }

            else:
                error_msg = result.get("error") or result.get("status", "Unknown error")
                print(f"âŒ RunPod error: {error_msg}")
                return {
                    "success": False,
                    "error": error_msg
                }

        except requests.exceptions.Timeout:
            return {
                "success": False,
                "error": f"Timeout after {self.timeout}s"
            }
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"Request failed: {str(e)}"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Unexpected error: {str(e)}"
            }

    def generate_batch(
        self,
        prompts: List[str],
        delay_between: float = 1.0,
        **kwargs
    ) -> List[Dict]:
        """
        ØªÙˆÙ„ÙŠØ¯ batch Ù…Ù† Ø§Ù„ØµÙˆØ±

        Args:
            prompts: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ÙˆØµÙÙŠØ©
            delay_between: Ø§Ù„ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Ø«ÙˆØ§Ù†ÙŠ)
            **kwargs: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù€ generate_image

        Returns:
            List[Dict]: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        results = []
        total = len(prompts)

        print(f"\nğŸ¨ Starting batch generation: {total} images")
        print("=" * 60)

        for i, prompt in enumerate(prompts, 1):
            print(f"\n[{i}/{total}] Generating...")

            try:
                result = self.generate_image(prompt=prompt, **kwargs)
                results.append(result)

                if result["success"]:
                    print(f"âœ… Success (seed: {result.get('seed', 'N/A')})")
                else:
                    print(f"âŒ Failed: {result.get('error', 'Unknown')}")

                # ØªØ¬Ù†Ø¨ rate limiting
                if i < total:
                    time.sleep(delay_between)

            except KeyboardInterrupt:
                print("\nâš ï¸ Batch interrupted by user")
                break
            except Exception as e:
                print(f"âŒ Exception: {e}")
                results.append({
                    "success": False,
                    "error": str(e),
                    "prompt": prompt
                })

        # Ù…Ù„Ø®Øµ
        success_count = sum(1 for r in results if r.get("success"))
        print("\n" + "=" * 60)
        print(f"ğŸ“Š Batch complete: {success_count}/{total} successful")

        return results

    def save_image(
        self,
        image_b64: str,
        output_path: Path,
        format: str = "PNG"
    ) -> Path:
        """
        Ø­ÙØ¸ ØµÙˆØ±Ø© Ù…Ù† base64

        Args:
            image_b64: Ø§Ù„ØµÙˆØ±Ø© Ø¨ØµÙŠØºØ© base64
            output_path: Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø­ÙØ¸
            format: ØµÙŠØºØ© Ø§Ù„ØµÙˆØ±Ø© (PNG, JPEG, etc.)

        Returns:
            Path: Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸
        """
        from PIL import Image
        import io

        # ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±
        img_data = base64.b64decode(image_b64)
        img = Image.open(io.BytesIO(img_data))

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Ø§Ù„Ø­ÙØ¸
        img.save(output_path, format=format)

        return output_path

    def _build_flux_workflow(
        self,
        prompt: str,
        negative_prompt: str,
        width: int,
        height: int,
        steps: int,
        cfg_scale: float,
        seed: Optional[int],
        model: str,
        sampler: str,
        scheduler: str
    ) -> Dict:
        """
        Ø¨Ù†Ø§Ø¡ workflow Ù„Ù€ ComfyUI/Flux

        Ù‡Ø°Ø§ workflow Ø¨Ø³ÙŠØ· - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø­Ø³Ø¨ setup Ø¹Ù†Ø¯Ùƒ
        """
        # ØªÙˆÙ„ÙŠØ¯ seed Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¥Ù† Ù„Ù… ÙŠÙÙ…Ø±Ø±
        if seed is None:
            seed = int(time.time() * 1000) % (2**32)

        # Workflow structure Ù„Ù€ Flux
        workflow = {
            "1": {
                "class_type": "CheckpointLoaderSimple",
                "inputs": {
                    "ckpt_name": model
                }
            },
            "2": {
                "class_type": "CLIPTextEncode",
                "inputs": {
                    "text": prompt,
                    "clip": ["1", 1]
                }
            },
            "3": {
                "class_type": "CLIPTextEncode",
                "inputs": {
                    "text": negative_prompt,
                    "clip": ["1", 1]
                }
            },
            "4": {
                "class_type": "EmptyLatentImage",
                "inputs": {
                    "width": width,
                    "height": height,
                    "batch_size": 1
                }
            },
            "5": {
                "class_type": "KSampler",
                "inputs": {
                    "seed": seed,
                    "steps": steps,
                    "cfg": cfg_scale,
                    "sampler_name": sampler,
                    "scheduler": scheduler,
                    "denoise": 1.0,
                    "model": ["1", 0],
                    "positive": ["2", 0],
                    "negative": ["3", 0],
                    "latent_image": ["4", 0]
                }
            },
            "6": {
                "class_type": "VAEDecode",
                "inputs": {
                    "samples": ["5", 0],
                    "vae": ["1", 2]
                }
            },
            "7": {
                "class_type": "SaveImage",
                "inputs": {
                    "images": ["6", 0],
                    "filename_prefix": "flux_output"
                }
            }
        }

        return workflow


def enhance_prompt_for_sport(scene_text: str, lang: str = "en") -> str:
    """
    ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø±ÙŠØ§Ø¶ÙŠØ© Ø£ÙØ¶Ù„

    Args:
        scene_text: Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
        lang: Ø§Ù„Ù„ØºØ© (ar Ø£Ùˆ en)

    Returns:
        str: Prompt Ù…Ø­Ø³Ù‘Ù†
    """
    # Ø¥Ø¶Ø§ÙØ§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©
    quality_tags = "cinematic, high quality, professional photography, 8k, detailed"

    # Ø¥Ø¶Ø§ÙØ§Øª Ù„Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ
    sport_style = "athletic, dynamic, motivational"

    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù€ prompt
    if lang.lower().startswith("ar"):
        # Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©: Ù†ØªØ±Ø¬Ù… Ø£Ùˆ Ù†Ø¨Ù‚ÙŠ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        enhanced = f"{scene_text}, {sport_style}, {quality_tags}"
    else:
        enhanced = f"{scene_text}, {sport_style}, {quality_tags}"

    return enhanced
