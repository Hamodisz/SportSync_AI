# app_streamlit.py
# ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© ØªÙˆÙ„Ù‘Ø¯ ØµÙˆØ±/ØµÙˆØª/ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¹ Ø²Ø± ØªÙ†Ø²ÙŠÙ„

from pathlib import Path
import os
import json
import streamlit as st

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ
from core.core_engine import run_full_generation, quick_diagnose

st.set_page_config(page_title="SportSync â€” Quick Video", layout="centered")

st.title("SportSync â€” Video + Personalizer (V1.1)")

# -------- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª --------
lang = st.selectbox("Language", ["en", "ar"], index=0)

DEFAULT_SCRIPT = """Title: Start your sport today

Scene 1: Sunrise over a quiet track â€” "Every beginning is a step."
Scene 2: Shoes hitting the ground â€” "Start with one simple move."
Scene 3: A calm smile â€” "Consistency beats perfection."
Outro: Give it 10 minutes today.
"""

script = st.text_area("Script", DEFAULT_SCRIPT, height=220)

secs = st.slider("Seconds per image", 2, 8, 4)

col1, col2 = st.columns(2)
with col1:
    add_voice = st.checkbox("Add voice-over", value=False)
with col2:
    show_debug = st.checkbox("Show debug (diagnose)", value=True)

# Ø§Ø®ØªÙŠØ§Ø±Ø§Øª ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Ø¨ÙŠØ¦Ø©/Ù…ØªØºÙŠØ±Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø¯ÙˆØ§Ù„)
use_openai = st.checkbox("Use AI images (OpenAI)", value=False)
use_stock  = st.checkbox("Use stock photos (free)", value=True)

st.divider()

# -------- Ø£Ø²Ø±Ø§Ø± --------
c1, c2 = st.columns(2)

def show_diag():
    d = quick_diagnose()
    st.code(json.dumps(d, ensure_ascii=False, indent=2), language="json")

with c2:
    if st.button("Quick diagnose"):
        show_diag()

# -------- ØªÙ†ÙÙŠØ° --------
with c1:
    if st.button("Generate video", use_container_width=True):
        # ØªÙ…Ø±ÙŠØ± Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª Ø¹Ø¨Ø± Ù…ØªØºÙŠØ±Ø§Øª Ø¨ÙŠØ¦ÙŠØ© (ØªØªÙ‚Ø±Ø£ Ø¯Ø§Ø®Ù„ generate_images)
        os.environ["USE_OPENAI_IMAGES"] = "1" if use_openai else "0"
        os.environ["USE_STOCK_IMAGES"]  = "1" if use_stock else "0"

        with st.status("Generating images / voice / video...", expanded=True) as s:
            # user_data Ø¨Ø³ÙŠØ·
            user_data = {"topic": "sports motivation", "traits": {"tone": "emotional"}}

            res = run_full_generation(
                user_data=user_data,
                lang=lang,
                image_duration=int(secs),
                override_script=script,
                mute_if_no_voice=not add_voice,
                skip_cleanup=False,
            )

            if res.get("error"):
                st.error(f"ERROR: {res['error']}")
                if show_debug:
                    show_diag()
                s.update(label="Failed", state="error")
            else:
                # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØµÙ†ÙˆØ¹Ø© (Ø¥Ù† ÙˆØ¬Ø¯Øª)
                images = sorted([str(p) for p in Path("content_studio/ai_images/outputs").glob("*")])
                if images:
                    st.caption("Images used:")
                    st.image(images, use_column_width=True)

                # Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ + Ø²Ø± ØªÙ†Ø²ÙŠÙ„
                video_path = res.get("video")
                if video_path and Path(video_path).exists():
                    st.success("Video is ready ğŸ‰")
                    st.video(str(video_path))

                    # Ø²Ø± ØªÙ†Ø²ÙŠÙ„
                    vb = Path(video_path).read_bytes()
                    st.download_button(
                        "Download MP4",
                        data=vb,
                        file_name=Path(video_path).name,
                        mime="video/mp4",
                        use_container_width=True,
                    )
                else:
                    st.warning("Video file not found after generation.")

                if add_voice and res.get("voice"):
                    st.caption(f"Voice: {res['voice']}")

                if show_debug:
                    show_diag()

                s.update(label="Done", state="complete")
